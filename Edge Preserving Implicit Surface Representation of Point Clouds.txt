# Edge Preserving Implicit Surface Representation of Point Clouds.pdf
# Converted: 2025-07-19 12:45:29
# Method: pymupdf
# Domain: pixel2physics
# Source: ../layer2_completion/Edge Preserving Implicit Surface Representation of Point Clouds.pdf
# Output: ../layer2_completion/txt/Edge Preserving Implicit Surface Representation of Point Clouds.txt


--- Page 1 ---

JOURNAL OF LATEX CLASS FILES, 2019
1
Edge Preserving Implicit Surface
Representation of Point Clouds
Xiaogang Wang, Yuhang Cheng, Liang Wang, Jiangbo Lu, Senior Member, IEEE , Kai Xu, Senior
Member, IEEE , Guoqiang Xiao
Abstract— Learning implicit surface directly from raw data recently has become a very attractive representation method for 3D
reconstruction tasks due to its excellent performance. However, as the raw data quality deteriorates, the implicit functions often lead
to unsatisfactory reconstruction results. To this end, we propose a novel edge-preserving implicit surface reconstruction method, which
mainly consists of a differentiable Laplican regularizer and a dynamic edge sampling strategy. Among them, the differential Laplican
regularizer can effectively alleviate the implicit surface unsmoothness caused by the point cloud quality deteriorates; Meanwhile, in order
to reduce the excessive smoothing at the edge regions of implicit suface, we proposed a dynamic edge extract strategy for sampling near
the sharp edge of point cloud, which can effectively avoid the Laplacian regularizer from smoothing all regions. Finally, we combine them
with a simple regularization term for robust implicit surface reconstruction. Compared with the state-of-the-art methods, experimental
results show that our method signiﬁcantly improves the quality of 3D reconstruction results. Moreover, we demonstrate through several
experiments that our method can be conveniently and effectively applied to some point cloud analysis tasks, including point cloud edge
feature extraction, normal estimation,etc.
Index Terms—Implicit surface representation, Differential Laplacian regularizer, Dynamic edge sampling, Point cloud, Geometric
modeling, Shape analysis.
!
1
INTRODUCTION
Recently, Implicit Neural Representations (INRs) has gained made
great strides in the ﬁeld of 3D reconstruction [1]–[8]. In contrast
to traditional explicit representations such as point clouds
[9],
voxels [10], [11] and mesh
[12]–[15], implicit neural repre-
sentations represent surface function primarily through neural
networks, providing higher quality, ﬂexibility, and ﬁdelity without
discretization errors, and signiﬁcantly save amounts of storage
space to store high-quality results.
However, most of these methods need ground truth data as
supervision [1]–[3], which have difﬁculty in generalizing well to
unseen shapes that are dissimilar to the training samples. Recently,
some methods [16]–[20] have been proposed to reconstruct im-
plicit neural representations directly from raw data (point clouds,
triangle soups, unoriented meshes, etc.). Compared to data-driven
approaches, building implicit neural representations directly from
raw data is obviously more appealing. Generally speaking, the
core idea of such methods is to impose explicit/implicit regularity
constraints to reduce reliance on dataset. SAL [18] proposed a
unsigned regression loss to a given unsigned distance function
to raw data, which can produce signed solutions of implicit
functions. Speciﬁcally, starting from raw data (e.g., point clouds,
real scanned grids, etc.), implicit neural representations learn in a
self-supervised manner and can be trained reliably relying only
on raw input data by minimizing unsigned regression. Subse-
quently, SALD
[17], a generalized version of SAL
[18] was
proposed, which can obtain higher quality reconstruction results
•
Xiaogang Wang, Yuhang Cheng, Liang Wang and Guoqiang Xiao are
with College of Computer and Information Science, Southwest University,
China.
•
Jiangbo Lu is with the SmartMore Co., Ltd.
•
Kai Xu is with the National University of Defense Technology, China.
Fig. 1: Effect of edge preserving differential Laplacian regularizer.
(b) are the optimization results of the edge preserving differential
Laplacian regularizer which is incorporated into the state-of-the-
art methods IGR [19] . (a) and (c) are the results of IGR and
Ground truth respectively.
arXiv:2301.04860v1  [cs.CV]  12 Jan 2023


--- Page 2 ---

JOURNAL OF LATEX CLASS FILES, 2019
2
by incorporating an explicit gradient constraint on SAL. Gropp et
al. [19] proposed a novel implicit geometric regularization (IGR)
method to directly learn an implicit neural representation from
raw data and achieved surprising results. Different from SAL [18]
and SALD [17], IGR only relies on implicit regularization con-
straints, without the need for a unsigned distance function. More
speciﬁcally, IGR proposes an implicit geometric regularization,
which amounts to solving a particular Eikonal boundary value
problem that constrains the norm of spatial gradients to be 1
almost everywhere. Yet, when the normal information cannot be
available and the number of input points is not dense enough,
the above algorithms often lead to unsatisfactory reconstruction
results (See Figure 1(a)).
We observed that the main reason for the unsatisfactory re-
construction results is that the implicit function needs to ﬁt the
input point cloud as much as possible, and the noise information
in the point cloud tends to cause the implicit surface to be very
unsmooth. In other words, the main reason for this phenomenon is
the inconsistency of normal in the local region of the reconstructed
surface. Therefore, it is an intuitive idea to keep the local normal
of the surface consistent as much as possible; Meanwhile, it
should be noted that not all regions are restricted in their normal
consistency, for example, obviously sharp edges often exist in the
surface (as shown in Figure 1). In the reconstruction process,
we hope that this part of the area will not be overly smoothed.
Therefore, The edge preserving local normal consistency is more
accurate for implicit surface representation .
In view of the above problem, it can be visually viewed
as a standard Laplacian minimization problem; Meanwhile, we
can also use the Laplacian operator to identify the edge region
effectively, which has achieved good results in many image
processing tasks. Therefore, in other words, we can design an
intuitive Laplacian regularization, which can effectively improve
the quality of reconstruction results.
However, in this task, the raw data type we consider is point
cloud data, and the difference method cannot be directly used to
approximate high-order derivatives, mainly because point cloud
data does not have a clear topological relationship like mesh
or image. If the algorithm similar to KNN is used, the nearest
neighbor points searched cannot guarantee the correct topology
structure (as shown in Figure 3), especially when the point cloud
is not dense and the normal are not available , such wrong nearest
neighbor results will easily lead to the anti-optimization results (as
shown in Figure 4(a)).
Recently, there is growing interest in differentiable optimiza-
tion of implicit neural representations that enable differential
nature as supervision in learning frameworks
[3], [19], [21]–
[25]. The advantage of differentiable implicit neural represen-
tations is that it can directly solve the higher derivative of the
input signal instead of discretization approximation, which greatly
improves its optimization performance and application range.
Thanks to the analytically-differentiable nature of implicit neural
representation, we can easily design a differentiable Laplacian
regularizer. Meanwhile, the differentiable Laplacian regularizer
can be easily and intuitively incorporated into implicit neural
surface representations (as shown in Figure 1). We show that it
signiﬁcantly improve the quality of 3D reconstruction. Meanwhile,
in order to facilitate qualitative and quantitative comparisons in
this paper, unless otherwise stated, in this paper, all experimental
results are obtained by incorporating them into IGR
[19]. We
carefully evaluate its performance through a series of ablation
studies. Meanwhile, we demonstrate through several experiments
that our method can be conveniently and effectively applied to
some point cloud analysis tasks, including point cloud edge feature
extraction, normal estimation, etc.
In summary, we make the following contributions: In this pa-
per, we use the inﬁnite differentiability property of implicit neural
representation to propose a novel edge-preserving implicit surface
reconstruction method, which mainly consists of a differentiable
Laplican regularizer and a dynamic edge sampling strategy. 1),
Among them, the differential Laplican regularizer can effectively
alleviate the implicit surface unsmoothness caused by the point
cloud quality deteriorates; 2), Meanwhile, in order to reduce
the excessive smoothing at the edge regions of implicit suface,
we proposed a dynamic edge extract strategy for sampling near
the sharp edge of point cloud, which can effectively avoid the
Laplacian regularizer from smoothing all regions.
2
RELATED WORK
2.1
Data-driven based Implicit surface reconstruction
3D surface reconstruction from raw data has gained signiﬁcant
research progress in recent year, beneﬁting from the advances in
machine learning techniques
[1]–[8]. Early studies
[26]–[28]
most utilize predeﬁned geometric priors (such as local linearity
and smoothness) towards speciﬁc tasks. These geometric priors
often encode statistical properties of raw data and are designed
to be optimized, such as poisson equation
[28], [29], radius
basis function [26], moving least squares [27]. Recently, implicit
neural representation has gained signiﬁcant research progress for
geometry reconstruction
[1]–[3], [6], [7], [16], [30]–[34] and
object representation [3], [23], [35]–[45] due to their simplicity
and excellent performance, which learn an approximate implicit
function with multi-layer perceptron (MLP). Compared to the
traditional continuous and discrete representations (grid, point
cloud and voxel), implicit neural representations have many poten-
tial beneﬁts, which can provide higher modeling quality without
discretization errors, ﬂexibility and ﬁdelity, and save storage
space. However, most of these methods need ground truth data
as supervision [1]–[3], which have difﬁculty in generalizing well
to unseen shapes that are dissimilar to the training samples.
In addition, there are hybridization-based methods [46]–[50]
that combine data-driven priors with optimization strategy that can
achieve state-of-the-art performance. However, the above methods
also require additional ground truth data as supervision, which
seriously limits their applicability.
2.2
Sign Agnostic Implicit surface reconstruction
Recently, some methods [17]–[20] have been proposed to re-
construct implicit neural representations directly from raw data.
Compared to big data-driven approaches, building implicit neural
representations directly from raw data is obviously more appeal-
ing. These methods can avoid the need for a large number of
ground truth signed distance representation of training data as
supervision. SAL
[18] introduces a sign agnostic regression
loss to a given unsigned distance function to raw data, which
is the signed version of unsigned distance function. Meanwhile,
that avoids the use of surface normals by properly initializing
implicit decoder networks so that they can only produce signed
solutions of implicit functions using unsigned distance function.
Subsequently, SALD
[17], a generalized version of SAL
[18]


--- Page 3 ---

JOURNAL OF LATEX CLASS FILES, 2019
3
was proposed, which can obtain higher quality reconstruction
results by incorporating an explicit gradient constraint on SAL.
Similarly, in this paper, our approach also uses implicit neural
representation to estimate level set functions directly from raw
data. The major difference is that our proposed regularization
terms are directly based on differentiable implicit optimization,
and does not explicitly enforce some regularization on the zero
level set, such constraints, when the normal information cannot be
available and the number of input point cloud is not dense enough,
the implicit neural representation often lead to unsatisfactory
reconstruction results.
2.3
Differentiable implicit neural representation
Compared with general implicit neural representation, differen-
tiable implicit neural representation has the advantage that it
can directly use various properties of differential geometry in-
stead of discretization approximation, which can lead to more
stable solutions in many optimization problems. Recently, there is
growing interest in differentiable optimization of implicit neural
representation that enable differential nature as supervision in
learning frameworks [3], [19], [21], [21]–[25]. General numerical
optimization often uses the discrete approximation of differential
geometry, for example, ﬁnite difference method is often used to
enhance the smoothness between adjacent samples in space. But
thanks to the analytically-differentiable nature of implicit neural
representation, differentiable implicit neural representations can
make direct use of many properties in differential geometry, such
as gradients [19], [21], [23], curvatures [24], and the solution of
partial differential equations [22], [25]. Recently, Gropp et al. [19]
proposed to use the differentiable implicit neural representation
to directly reconstruct surface from raw data. More speciﬁcally,
it proposes an implicit regularization constraint, which amounts
to solving a particular Eikonal boundary value problem that
constrains the norm of spatial gradients to be 1 almost everywhere.
Similarly, Sitzmann et al. [21] uses the proposed a differentiable
periodic activation functions to represent signed distance ﬁelds
in a fully-differentiable manner. Both of these works [19], [21]
, however, when the normal information cannot be available and
the number of input points is not dense enough, often lead to
unsatisfactory reconstruction results. In this paper, our work is also
based on the differentiability of implicit neural representations
to optimize implicit level set function estimated directly from
the input point cloud. Speciﬁcally, we designed an implicit dif-
ferentiable Laplacian regularizer, which effectively alleviated the
problem of unsatisfactory reconstruction results caused by direct
ﬁtting of input point cloud by implicit neural function.
3
METHOD
We present a differentiable laplacian regularizer for neural implicit
representation directly from input point cloud without normal
supervision. Note that our differential Laplacian regularizer can
be incorporated into any implicit neural representation, such as
IGR [19],SAL [18],SALD [17]. In this paper, unless otherwise
noted, we incorporate it in the IGR, which use level sets of neural
network to represent 3D shape (Sec. 3.1). More speciﬁcally, IGR
proposes an implicit geometric regularization, which amounts to
solving a particular Eikonal boundary value problem that con-
strains the norm of spatial gradients to be 1 almost everywhere.
Yet, when the normal information cannot be available and the
number of input points is not dense enough, IGR often lead
Fig. 2: Illustrations of the local normal consistency.
to unsatisfactory reconstruction results (See Figure 1(a)). We
observed that the main reason for the unsatisfactory reconstruction
results is that the implicit function needs to ﬁt the input point cloud
as much as possible, and the noise information in the point cloud
tends to cause the implicit surface to be very unsmooth.
To
overcome
this
problem,
we
use
the
analytically-
differentiable nature of implicit neural representation, to propose
a differential Laplacian regularizer, which can effectively alleviate
the unsatisfactory reconstruction results (Sec. 3.2). Meanwhile, in
order to reduce the excessive smoothing at the edge regions of
3D shape (such as man-made shapes), a dynamic edge extraction
strategy (Sec. 3.2) is introduced for sampling near the sharp edge
of input point cloud, which can effectively avoid the Laplacian
regularizer from smoothing all regions, so as to effectively im-
prove the quality of reconstruction results while maintaining the
edge.
3.1
Background
A neural implicit representations is a continuous function that
approximate the signed distance function. The underlying surface
of 3D shape is implicitly represented by the zero level set of this
function,
fθ(x) = 0, ∀x ∈X.
(1)
where θ indicates the parameters to be learned and X indicates the
set of input point cloud. In general, one parameterize this function
using a multi-layer perceptron (MLP). Meanwhile, in order to
conveniently use the analytically-differentiable (such as, gradi-
ents,etc.) nature of implicit neural representation, recent works
[19], [21] usually replace the commonly used ReLU activation
function with a non-linear differentiable activation functions, thus
transforming MLP into a continuous and inﬁnitely differentiable
function.
In IGR, the training is done by minimizing the loss that
encourages f to vanish on X:
Lvanish =
1
N(X)
X
x∈X
|fθ(x)|
(2)
where N(X) is the number of point set X, | • | indicates abso-
lute value. if the input point cloud includes normal information
ngt(x), the corresponding loss function can be designed to make
the predicted normal (the differentiable gradient ▽fθ(x) of the
implicit function) as close as possible to the ground truth normal
ngt(x):
Lnormal =
1
N(X)
X
x∈X
||▽fθ(x) −ngt(x)||2
(3)
In addition to the above two intuitive ﬁtting loss terms, IGR
[19] based on the Eikonal partial differential equation presents
an additional loss (Eikonal loss), which is equivalent to solve


--- Page 4 ---

JOURNAL OF LATEX CLASS FILES, 2019
4
Fig. 3: Illustrations of two different N nearest neighbors of non-
topological preservation (b) and topological preservation (c) for
geometric structure (a).
boundary value problems of a particular Eikonal that constrains
the norm of spatial gradients ▽fθ(x) to be 1 almost everywhere:
Leikonal =
1
N(X)
X
x∈X
(||▽fθ(x)||2 −1)2
(4)
Note that, in our approach, we do not consider normal infor-
mation as supervision, so we will not consider Lnormal term in
all subsequent experiments. More speciﬁcally, our approach builds
upon the above two items Lvanish and Leikonal.
3.2
Differentiable laplace regularization
Neighborhood normal consistency. A high-quality result can be
generated based on the above two terms (Lvanish and Leikonal)
when the input point data is large enough, however, when the
normal information cannot be available and the number of input
points is not dense enough, often lead to unsatisfactory reconstruc-
tion results (See Figure 1(a)).
We observed that the main reason for the unsatisfactory re-
construction results is that the implicit function needs to ﬁt the
input point cloud as much as possible, and the noise information
in the point cloud tends to cause the implicit surface to be
very unsmooth. More speciﬁcally, the optimization results are
not guaranteed to provide a high-quality reconstruction result,
which is intuitively reﬂected by the possibility that the normal
of reconstruction result is inconsistent in the neighborhood.
From another perspective, it is well known that 3D shapes
tend to be piecewise smooth, that is, ﬂat surfaces are more
likely than high-frequency structures [51]. For this purpose, we
incorporate this prior into implicit neural function by encouraging
the geometric smoothness of the reconstructed results. Therefore,
an intuitive solution is to constrain the consistency of the neighbor-
hood normal of the reconstruction results (as shown in Figure 2):
Lneibor =
X
x∈X
X
xi∈nei(x)
||▽fθ(x) −▽fθ(xi)||2
(5)
where nei(x) indicates the neighbor point set of point x.
However, in this paper, the raw data type we consider is point
cloud data, which does not have a clear topological structure
like mesh or voxels. If the algorithm similar to KNN is used,
the nearest neighbor points searched cannot guarantee that they
maintain the correct topology structure, especially when the point
cloud is not dense and the normal are not available, as shown in
Figure 3(b) where the three points P4, P5 and P6 do not meet the
nearest neighbor result of N = 5 under the maintenance of the
topology structure, and the correct set of nearest neighbor points
Fig. 4: The comparison of Lneibor (a) and Llaplacian (b).
should be {P1, P2, P3, P8, P9}. Moreover, it is difﬁcult to get a
reasonable value for this parameter nei(x) in practice. As shown
in Figure 4, we can easily see that the wrong reconstructed results,
which is mainly caused by the above reasons.
Differentiable Laplacian regularizer. In fact, the above con-
straint Lneibor is mainly used to constrain the normal consistency
in the local domain, which can be easily interpreted as a discrete
Laplace operator. The Laplacian operator △f is a second-order
differential operator in n-dimensional euclidean space, deﬁned as
the divergence (▽· f) of the gradient (▽f). Thanks to the inﬁnite
differentiability of implicit neural representation, we can design a
simple but effective differentiable Laplacian regularizer:
Llaplacian =
X
x∈X
△fθ(x)2
(6)
where △fθ(x) indicates the differentiable Laplace operator of
point x.
As shown in Figure 4(b), compared with the explicit regular-
ization constraint Lneibor based on the nearest neighbor normal
consistency, the differentiable Laplacian regularizer can obtain
more stable results without introducing hyperparameter nearest
neighbors N.
3.3
Dynamic edge sampling
However, while the differentiable Laplacian regularizer restricts
the normal consistency, it also brings a new problem: It imposes
undifferentiated constraints on all 3D regions, even in the sharp-
edge regions, as shown in Figure 6. As we know, complex 3D
shapes are generally constructed by multiple piecewise smooth
surfaces, which may not be differentiable at the joints, and are
more likely to form sharp edges. Therefore, in essence, a complex
3D shape (piecewise smooth model with sharp edges) cannot
be accurately represented by an implicit function, because it is
obviously not differentiable at sharp edges, so if it is forced to be
represented by an implicit function, especially only sparse point
sets without normal information are used as supervision, it is easy
to form an overly smooth reconstruction at the sharp edges (as
shown in Figure 6).
The most intuitive solution is to implicitly represent each
piecewise smooth surface separately, but this is difﬁcult to do in
practice because it ﬁrst requires the segmentation of the input point
set, which is difﬁcult to do accurately in unsupervised conditions.
Therefore, we propose a novel dynamic edge sampling
strategy to effectively extract sharp edge regions in the training


--- Page 5 ---

JOURNAL OF LATEX CLASS FILES, 2019
5
Fig. 5: Statistics of Laplacian operators |△fθ(x)| and edge thresh-
old τ selection.
process. In theory, the remaining regions not only satisfy the
differentiable property, but also conform to the normal consistency
constraint, which can effectively avoid the indifference smoothing
of all regions, including the edge regions, of the laplace regular-
izer.
Speciﬁcally, for each point p in the input point set, we may
quickly determine whether it is an edge point according to its
differentiable Laplacian operator △fθ(x). Essentially, Laplacian
is mainly used to describe the rate of change of gradient, and
is often used for edge detection in image processing. From the
perspective of differential geometry, it is used to describe the
change rate of spatial position normal. Therefore, the larger the
laplacian of the point, the stronger the possibility that the point is
an edge point. We threshold the Laplacian |△fθ(x)| < τ to obtain
a corresponding set of non-edge points X′. According to statistics
(as shown in Figure 5), we set the parameter τ = 20 throughout
our experiments. This operation is performed before the back-
propagation of each iteration, therefore, we call it dynamic edge
sampling.
Llaplacian =
X
x∈X′
△fθ(x)2
(7)
where X′ indicates the non-edge subset of the input point cloud
X. Finally, we optimize the total loss:
Ltotal = Lvanish + λ1Leikonal + λ2Llaplacian
(8)
In which, we set λ1 = 0.1 and λ2 = 0.001 throughout our
experiments.
4
DETAILS, RESULTS AND EVALUATIONS
4.1
Implementation details
Data preparation. To facilitate quantitative evaluation of our
method on multiple tasks, including reconstruction , edge ex-
traction and normal estimation, we selected 100 3D shapes with
rich geometric topologies to construct the evaluation dataset (See
Figure 8) from ABC dataset [52], which provides more than 1
million standard 3D CAD models with multiple types of standard
CAD format ﬁles. In addition to 3D geometry and normal informa-
tion, the geometric edges information mentioned above does not
provide us explicitly. To this end, we have developed a tool that,
Fig. 6: The comparison of with (b) and without Dynamic Edge
Sampling (DES) (a).
for each 3D shape, can quickly and easily extract the geometric
edge information from the multiple CAD ﬁles, thus fully meeting
the needs of our method for multi-task quantitative evaluation.
Point sampling. For each model, we sample it into a point
cloud containing 16, 384 points by uniform point sampling.
Meanwhile, in order to simulate the real point cloud noise, we
added Gaussian noise with mean µ = 0 and standard devia-
tion δ = 0.005 to each sampling point. In each case, except
where otherwise stated, the network is trained on the noisy data
throughout our experiments. A few metrics on point cloud multi-
tasks accuracy are deﬁned to support quantitative evaluation of our
approach; see the following subsections for details.
4.2
Metrics
In our experiments, both qualitative and quantitative evaluations
are provided. We evaluate our approach via ablation studies
(Section 4.6), comparisons to state-of-the-art methods for 3D
reconstruction (Section 4.3) , edge detection (Section 4.4) and
normal estimation (Section 4.5). For the quantitative assessment of
the 3D reconstruction results, we used the two-sided Chamfer dC
and Hausdorff distances dH introduced by [19]. For the evaluation
of the normal estimation, we use the angle dangle between the
predicted normal and the groudtruth normal as the metric. To
evaluate edge detection, we measure precision/recall and the
IoU between predictions and ground truth, while to evaluate the
geometric accuracy of the reconstructed edges, we employ the
Edge Chamfer Distance (ECD) introduced by [1].
4.3
Reconstruction
Comparison with IGR [19]. To facilitate a fair comparison with
IGR [19], our network architecture is consistent with IGR [19]. In
all experiments, we used the default training procedure speciﬁed
in IGR to train our network, except that we did not use normal
information in the training and set iterations to 10000. We set the
loss parameters (see equation (8)) λ2 = 0.1 and λ3 = 0.001
throughout our experiments. Qualitative and quantitative experi-
ments are reported in Table 1 and Figure 7 we can also see that
the performance of our method is signiﬁcantly better.
Comparison with state-of-the-art methods SAL [18] and
SALD [17]. In addition to IGR [19], our method is also compared
with SAL [18] and SALD [17], two state-of-the-art sign agnostic
learning based methods from raw data. The results shown in
Table 1(row 1 and 2) are inferior to those of our method. As shown
in Figure 7, the results demonstrate the signiﬁcant advantage of


--- Page 6 ---

JOURNAL OF LATEX CLASS FILES, 2019
6
Fig. 7: Qualitative comparison with state-of-the-art methods IGR [19], SAL [18] and SALD [17].
Fig. 8: An overview of multi-task evaluation dataset.
dC
dH
Mean
Median
Mean
Median
SAL [18]
0.019
0.016
0.094
0.050
SALD [17]
0.016
0.015
0.053
0.042
IGR [19]
0.028
0.011
0.111
0.034
Our (Llaplace)
0.017
0.009
0.068
0.026
Our (Llaplace + DES)
0.007
0.007
0.021
0.021
TABLE 1: A quantitative comparison of our method and ablation
against IGR [19], SAL [18] and SALD
[17] on multi-task
evaluation dataset.
our approach, due to the fact that differential Laplacian regularizer
can effectively alleviate the unsatisfactory reconstruction results.
4.4
Edge recognition
Speciﬁcally, for each point p in the input point set, we may quickly
determine whether it is an edge point according to its differentiable
laplace operator △fθ(x) . Essentially, laplace operator is mainly
used to describe the rate of change of gradient, and is often used
for edge detection in image processing. From the perspective of
differential geometry, it is used to describe the change rate of
spatial position normal. Therefore, the larger the laplace operator
of the point, the stronger the possibility that the point is an edge
point. We threshold the laplace operator |△fθ(x)| > τ to obtain a
corresponding set of non-edge points Xedge. We set the parameter
τ = 20 throughout our experiments, as shown in Figure 10.
In addition to IGR [19], we also choose two representative
classical non-learning based methods: Voronoi Covariance Mea-
sure (VCM) [53], and Edge-Aware Resampling (EAR) [54], as
both have been adopted in the point-set processing routines of the
well known CGAL library. As reported in Table 4, our method
completely outperforms these classical methods, This is mainly
because we use the differentiable Laplacian operator of each
sampling point as the metric, which can be approximate to the
average curvature in the implicit surface representation. Note that,
there are a large number of high-quality edge detection methods
based on data-driven. We do not use these methods as references
here, mainly because ours is a self-supervised learning approach.
4.5
Normal estimation
Essentially, an implicitly represented MLP with softplus activation
funtion represents a differentiable Signed Distance Functions d =
fθ(x). According to the properties of differential geometry, the
gradient operator of each point on the implicit surface fθ(x) = 0
can be regarded as the normal vector of the current point x.
Therefore, after the training, for each point in the input point
cloud, we can directly calculate the gradient operator ▽fθ(x) of
the differentiable function fθ(x) at the current point x, that is, the
normal vector of the current point x. The experimental results are
reported in Table 1. The comparison results demonstrate how our
method achieves signiﬁcantly better performance; as immediately
quantiﬁed by the fact that dangle is larger than the one reported
for our method.


--- Page 7 ---

JOURNAL OF LATEX CLASS FILES, 2019
7
Fig. 9: Visualization normal estimation of differential Laplacian regularizer (c) and dynamic edge sampling strategy (d).
Fig. 10: Visualization edge recognition of differential Laplacian regularizer (c) and dynamic edge sampling strategy (d).
dC
dH
Mean
Median
Mean
Median
X = 0.010
0.0102
0.0108
0.0509
0.0543
X = 0.005
0.0069
0.0069
0.0206
0.0209
X = 0.000
0.0055
0.0057
0.0148
0.0153
D = 4, 096
0.0075
0.0075
0.0350
0.0328
D = 8, 192
0.0071
0.0072
0.0352
0.0269
D = 16, 384
0.0069
0.0069
0.0206
0.0209
TABLE 2: Algorithm performance with respect to noise X and
sampling density D.
4.6
Analysis of parameters and networks
Effect of noise. We stress test Laplacian regularizer by increasing
the level of noise. Speciﬁcally, we randomly add a Gaussian noise
whose mean is 0 and variance is X to each sampling point on
the surface of the 3D shape, where we tested four values of
X = {0, 0.005, 0.01, 0.02}. In each case, the implicit neural
surface was trained with the noise-added data. Table 2 shows
the quantitative results. As we can observe that, the Laplacian
regularizer, even when trained with noisy data, can still out-
perform these state-of-the-art methods [17]–[19] when they are
tested on point cloud with 0.005 noise.
Effect of density. We also train our method on point clouds
at a reduced density. Speciﬁcally, for each 3D shape, we sam-
pled a different number D of points to verify whether our
network could handle the sparser point clouds, where D =


--- Page 8 ---

JOURNAL OF LATEX CLASS FILES, 2019
8
Fig. 11: Effect of edge preserving differential Laplacian regu-
larizer. (b) are the optimization results of the edge preserving
differential Laplacian regularizer which is incorporated into the
state-of-the-art method SALD [17]. (a) and (c) are the results of
SALD and Ground truth respectively.
dC
dH
dangle
IGR [19]
0.028
0.111
0.514
Our (+Llaplacian)
0.017
0.068
0.274
Our (+Llaplacian + DES)
0.009
0.036
0.133
TABLE 3: Ablation studies – We evaluate the quantitative per-
formance of our method with/without components Llaplacian and
dynamic edge sampling (DES).
{4, 096, 8, 192, 16, 384}. (Results in Table 2 reveal a similar
trend as from the previous stress test. Namely, our network, when
trained on sparser point clouds, can still outperform these state-of-
the-art methods [17]–[19] when they are tested on or trained on
data at full resolution (16,384 points).
Effect of Llaplacian. To evaluate the effectiveness of loss
Llaplacian, We incorporate this into another state-of-the-art
method, SALD [17], This qualitative result is shown in Figure 11,
we can ﬁnd that, compared with the original algorithm, the re-
construction quality can be effectively improved by incorporating
Laplacian. This is mainly because the differentiable Laplacian reg-
ularizer can effectively alleviate the unsatisfactory reconstruction
results.
Dynamic edge sampling. We evaluate the effect of dynamic
edge sampling strategy on reconstruction quality. We experiment
with the dynamic edge sampling, while keeping all other
parameters the same. From Table 1 and Figure 7 and 12 , we can
see that at the sharp edges, we can effectively improve the quality
of modeling compared with state-of-the-art methods (Table 1
(rows 1 3)) and the baseline method without dynamic edge
sampling, this is largely due to thedynamic edge sampling
strategy for sampling near the sharp edge of input point cloud,
which can effectively avoid the regularizer from smoothing all
regions.
ECD
IoU
Precision
Recall
VCM [53]
0.0017
0.1925
0.2238
0.5998
EAR [54]
0.0071
0.1146
0.2399
0.1933
IGR [19]
0.0063
0.0880
0.0958
0.5620
Our
0.0015
0.2375
0.2665
0.6934
TABLE 4: Comparison state-of-the-art edge recognition tech-
niques - VCM [53], EAR [54], and IGR [19].
5
CONCLUSION AND LIMITATION
We present a differential Laplacian regularizer for neural implicit
representation directly from input point cloud without normal
supervision. More speciﬁcally, we use the inﬁnite differentiability
property of implicit neural representation to propose a differen-
tiable Laplacian regularizer, which can effectively alleviate the
unsatisfactory reconstruction results. Meanwhile, we propose a
dynamic edge sampling strategy for sampling near the sharp
edge of input point cloud, which can effectively avoid the Lapla-
cian regularizer from smoothing all regions, so as to effectively
improve the quality of reconstruction results while maintaining
the edge. Moreover, the differentiable Laplacian regularizer can
be easily and intuitively incorporated into implicit neural sur-
face representations. We carefully evaluate its generation quality
through a series of ablation studies, which show that our method
signiﬁcantly improve the quality of 3D reconstruction. In addition
to 3D reconstruction, our method can also be conveniently applied
to other point cloud analysis tasks, including edge extraction and
normal estimation, etc.
Limitation. Our approach has a few limitations, which point
out the directions of future study. Some representative failure cases
are shown in Figure 13. First, our method is prone to problems
in the reconstruction of ultra-thin geometric structures, probably
because the point cloud data is noisy, resulting in the geometric
structure has been completely destroyed. Second, Our method
for extremely detailed structure may be overlooked, resulting in
incorrect reconstruction results.
ACKNOWLEDGEMENT
We thank the anonymous reviewers for their valuable comments.
This work was supported in part by Natural Science Foundation
of China (62102328), and Fundamental Research Funds for the
Central Universities (SWU120076).
REFERENCES
[1]
Z. Chen and H. Zhang, “Learning implicit ﬁelds for generative shape
modeling,” in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2019, pp. 5939–5948.
[2]
L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger,
“Occupancy networks: Learning 3d reconstruction in function space,” in
Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition, 2019, pp. 4460–4470.
[3]
J. J. Park, P. Florence, J. Straub, R. Newcombe, and S. Lovegrove,
“Deepsdf: Learning continuous signed distance functions for shape
representation,” in Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition, 2019, pp. 165–174.
[4]
J. Chibane, T. Alldieck, and G. Pons-Moll, “Implicit functions in feature
space for 3d shape reconstruction and completion,” in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2020, pp. 6970–6981.
[5]
P. Erler, P. Guerrero, S. Ohrhallinger, N. J. Mitra, and M. Wimmer,
“Points2surf learning implicit surfaces from point clouds,” in European
Conference on Computer Vision.
Springer, 2020, pp. 108–124.


--- Page 9 ---

JOURNAL OF LATEX CLASS FILES, 2019
9
Fig. 12: Visualization examples of differential Laplacian regularizer (c) and dynamic edge sampling strategy (d).
Fig. 13: Failure cases.
[6]
S. Peng, M. Niemeyer, L. Mescheder, M. Pollefeys, and A. Geiger, “Con-
volutional occupancy networks,” in European Conference on Computer
Vision.
Springer, 2020, pp. 523–540.
[7]
S. Saito, Z. Huang, R. Natsume, S. Morishima, A. Kanazawa, and H. Li,
“Pifu: Pixel-aligned implicit function for high-resolution clothed human
digitization,” in Proceedings of the IEEE/CVF International Conference
on Computer Vision, 2019, pp. 2304–2314.
[8]
Q. Xu, W. Wang, D. Ceylan, R. Mech, and U. Neumann, “Disn: Deep
implicit surface network for high-quality single-view 3d reconstruction,”
Advances in Neural Information Processing Systems, vol. 32, 2019.
[9]
H. Fan, H. Su, and L. J. Guibas, “A point set generation network for 3d
object reconstruction from a single image,” in Proceedings of the IEEE
conference on computer vision and pattern recognition, 2017, pp. 605–
613.
[10] C. B. Choy, D. Xu, J. Gwak, K. Chen, and S. Savarese, “3d-r2n2: A
uniﬁed approach for single and multi-view 3d object reconstruction,” in
European conference on computer vision.
Springer, 2016, pp. 628–644.
[11] J. Wu, C. Zhang, T. Xue, B. Freeman, and J. Tenenbaum, “Learning a
probabilistic latent space of object shapes via 3d generative-adversarial
modeling,” Advances in neural information processing systems, vol. 29,
2016.
[12] T. Groueix, M. Fisher, V. Kim, B. Russell, and M. Aubry, “Atlasnet: A
papier-mˆach´e approach to learning 3d surface generation. arxiv 2018,”
arXiv preprint arXiv:1802.05384, 1802.
[13] H. Kato, Y. Ushiku, and T. Harada, “Neural 3d mesh renderer,” in
Proceedings of the IEEE conference on computer vision and pattern
recognition, 2018, pp. 3907–3916.
[14] J. Tang, X. Han, J. Pan, K. Jia, and X. Tong, “A skeleton-bridged deep
learning approach for generating meshes of complex topologies from
single rgb images,” in Proceedings of the ieee/cvf conference on computer
vision and pattern recognition, 2019, pp. 4541–4550.
[15] J. Tang, X. Han, M. Tan, X. Tong, and K. Jia, “Skeletonnet: A topology-
preserving solution for learning mesh reconstruction of object surfaces
from rgb images,” IEEE transactions on pattern analysis and machine
intelligence, 2021.
[16] M. Atzmon, N. Haim, L. Yariv, O. Israelov, H. Maron, and Y. Lipman,
“Controlling neural level sets,” Advances in Neural Information Process-
ing Systems, vol. 32, 2019.
[17] M. Atzmon and Y. Lipman, “Sald: Sign agnostic learning with deriva-
tives,” arXiv preprint arXiv:2006.05400, 2020.
[18] ——, “Sal: Sign agnostic learning of shapes from raw data,” 2020, pp.
2565–2574.
[19] A. Gropp, L. Yariv, N. Haim, M. Atzmon, and Y. Lipman, “Im-
plicit geometric regularization for learning shapes,” arXiv preprint
arXiv:2002.10099, 2020.
[20] W. Zhao, J. Lei, Y. Wen, J. Zhang, and K. Jia, “Sign-agnostic implicit
learning of surface self-similarities for shape modeling and reconstruc-
tion from raw point clouds,” in Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, 2021, pp. 10 256–10 265.
[21] V. Sitzmann, J. Martel, A. Bergman, D. Lindell, and G. Wetzstein, “Im-
plicit neural representations with periodic activation functions,” Advances
in Neural Information Processing Systems, vol. 33, pp. 7462–7473, 2020.
[22] H. Chen, R. Wu, E. Grinspun, C. Zheng, and P. Y. Chen, “Implicit
neural spatial representations for time-dependent pdes,” arXiv preprint
arXiv:2210.00124, 2022.
[23] L. Yariv, J. Gu, Y. Kasten, and Y. Lipman, “Volume rendering of neural
implicit surfaces,” Advances in Neural Information Processing Systems,
vol. 34, pp. 4805–4815, 2021.
[24] T. Ehret, R. Mar´ı, and G. Facciolo, “Nerf, meet differential geometry!”
arXiv preprint arXiv:2206.14938, 2022.
[25] J. Zehnder, Y. Li, S. Coros, and B. Thomaszewski, “Ntopo: Mesh-free
topology optimization using implicit neural representations,” Advances
in Neural Information Processing Systems, vol. 34, pp. 10 368–10 381,
2021.
[26] J. C. Carr, R. K. Beatson, J. B. Cherrie, T. J. Mitchell, W. R. Fright, B. C.
McCallum, and T. R. Evans, “Reconstruction and representation of 3d
objects with radial basis functions,” in Proceedings of the 28th annual
conference on Computer graphics and interactive techniques, 2001, pp.
67–76.
[27] M. Alexa, J. Behr, D. Cohen-Or, S. Fleishman, D. Levin, and C. T. Silva,
“Computing and rendering point set surfaces,” IEEE Transactions on
visualization and computer graphics, vol. 9, no. 1, pp. 3–15, 2003.
[28] M. Kazhdan, M. Bolitho, and H. Hoppe, “Poisson surface reconstruc-


--- Page 10 ---

JOURNAL OF LATEX CLASS FILES, 2019
10
tion,” in Proceedings of the fourth Eurographics symposium on Geometry
processing, vol. 7, 2006.
[29] M. Kazhdan and H. Hoppe, “Screened poisson surface reconstruction,”
ACM Transactions on Graphics (ToG), vol. 32, no. 3, pp. 1–13, 2013.
[30] K. Genova, F. Cole, D. Vlasic, A. Sarna, W. T. Freeman, and
T. Funkhouser, “Learning shape templates with structured implicit func-
tions,” in Proceedings of the IEEE/CVF International Conference on
Computer Vision, 2019, pp. 7154–7164.
[31] M. Niemeyer, L. Mescheder, M. Oechsle, and A. Geiger, “Occupancy
ﬂow: 4d reconstruction by learning particle dynamics,” in Proceedings
of the IEEE/CVF international conference on computer vision, 2019, pp.
5379–5389.
[32] M. Oechsle, S. Peng, and A. Geiger, “Unisurf: Unifying neural implicit
surfaces and radiance ﬁelds for multi-view reconstruction,” in Proceed-
ings of the IEEE/CVF International Conference on Computer Vision,
2021, pp. 5589–5599.
[33] M. Tancik, P. Srinivasan, B. Mildenhall, S. Fridovich-Keil, N. Raghavan,
U. Singhal, R. Ramamoorthi, J. Barron, and R. Ng, “Fourier features let
networks learn high frequency functions in low dimensional domains,”
Advances in Neural Information Processing Systems, vol. 33, pp. 7537–
7547, 2020.
[34] P. Wang, L. Liu, Y. Liu, C. Theobalt, T. Komura, and W. Wang, “Neus:
Learning neural implicit surfaces by volume rendering for multi-view
reconstruction,” arXiv preprint arXiv:2106.10689, 2021.
[35] V. Sitzmann, M. Zollh¨ofer, and G. Wetzstein, “Scene representation
networks: Continuous 3d-structure-aware neural scene representations,”
Advances in Neural Information Processing Systems, vol. 32, 2019.
[36] A. Bergman, P. Kellnhofer, and G. Wetzstein, “Fast training of neural
lumigraph representations using meta learning,” Advances in Neural
Information Processing Systems, vol. 34, pp. 172–186, 2021.
[37] J. Chibane, A. Bansal, V. Lazova, and G. Pons-Moll, “Stereo radiance
ﬁelds (srf): Learning view synthesis for sparse views of novel scenes,”
in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2021, pp. 7911–7920.
[38] C. Gao, Y. Shih, W.-S. Lai, C.-K. Liang, and J.-B. Huang, “Portrait neural
radiance ﬁelds from a single image,” arXiv preprint arXiv:2012.05903,
2020.
[39] Y. Jiang, D. Ji, Z. Han, and M. Zwicker, “Sdfdiff: Differentiable render-
ing of signed distance ﬁelds for 3d shape optimization,” in Proceedings
of the IEEE/CVF conference on computer vision and pattern recognition,
2020, pp. 1251–1261.
[40] P. Kellnhofer, L. C. Jebe, A. Jones, R. Spicer, K. Pulli, and G. Wetzstein,
“Neural lumigraph rendering,” in Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition, 2021, pp. 4287–4297.
[41] L. Liu, J. Gu, K. Zaw Lin, T.-S. Chua, and C. Theobalt, “Neural
sparse voxel ﬁelds,” Advances in Neural Information Processing Systems,
vol. 33, pp. 15 651–15 663, 2020.
[49] M. Yang, Y. Wen, W. Chen, Y. Chen, and K. Jia, “Deep optimized
priors for 3d shape modeling and reconstruction,” in Proceedings of
[42] R. Martin-Brualla, N. Radwan, M. S. Sajjadi, J. T. Barron, A. Doso-
vitskiy, and D. Duckworth, “Nerf in the wild: Neural radiance ﬁelds
for unconstrained photo collections,” in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, 2021, pp.
7210–7219.
[43] B. Mildenhall, P. P. Srinivasan, M. Tancik, J. T. Barron, R. Ramamoorthi,
and R. Ng, “Nerf: Representing scenes as neural radiance ﬁelds for view
synthesis,” arXiv preprint arXiv:2003.08934, 2020.
[44] M. Niemeyer, L. Mescheder, M. Oechsle, and A. Geiger, “Differentiable
volumetric rendering: Learning implicit 3d representations without 3d
supervision,” in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2020, pp. 3504–3515.
[45] L. Yariv, Y. Kasten, D. Moran, M. Galun, M. Atzmon, B. Ronen, and
Y. Lipman, “Multiview neural surface reconstruction by disentangling
geometry and appearance,” Advances in Neural Information Processing
Systems, vol. 33, pp. 2492–2502, 2020.
[46] C. Jiang, A. Sud, A. Makadia, J. Huang, M. Nießner, T. Funkhouser et al.,
“Local implicit grid representations for 3d scenes,” in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2020, pp. 6001–6010.
[47] E. Tretschk, A. Tewari, V. Golyanik, M. Zollh¨ofer, C. Stoll, and
C. Theobalt, “Patchnets: Patch-based generalizable deep implicit 3d
shape representations,” in European Conference on Computer Vision.
Springer, 2020, pp. 293–309.
[48] R. Chabra, J. E. Lenssen, E. Ilg, T. Schmidt, J. Straub, S. Lovegrove,
and R. Newcombe, “Deep local shapes: Learning local sdf priors for
detailed 3d reconstruction,” in European Conference on Computer Vision.
Springer, 2020, pp. 608–625.
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2021, pp. 3269–3278.
[50] J. Tang, J. Lei, D. Xu, F. Ma, K. Jia, and L. Zhang, “Sa-convonet:
Sign-agnostic optimization of convolutional occupancy networks,” in
Proceedings of the IEEE/CVF International Conference on Computer
Vision, 2021, pp. 6504–6513.
[51] J. Huang, A. B. Lee, and D. Mumford, “Statistics of range images,” in
Proceedings IEEE Conference on Computer Vision and Pattern Recogni-
tion. CVPR 2000 (Cat. No. PR00662), vol. 1.
IEEE, 2000, pp. 324–331.
[52] S. Koch, A. Matveev, Z. Jiang, F. Williams, A. Artemov, E. Burnaev,
M. Alexa, D. Zorin, and D. Panozzo, “Abc: A big cad model dataset for
geometric deep learning,” in The IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), June 2019.
[53] Q. M´erigot, M. Ovsjanikov, and L. J. Guibas, “Voronoi-based curvature
and feature estimation from point clouds,” IEEE Transactions on Visual-
ization and Computer Graphics, vol. 17, no. 6, pp. 743–756, 2010.
[54] H. Huang, S. Wu, M. Gong, D. Cohen-Or, U. Ascher, and H. Zhang,
“Edge-aware point set resampling,” ACM transactions on graphics
(TOG), vol. 32, no. 1, pp. 1–12, 2013.
