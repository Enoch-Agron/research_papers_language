# Image Vectorization_ a Review.pdf
# Converted: 2025-07-19 12:45:29
# Method: pymupdf
# Domain: pixel2physics
# Source: ../layer2_completion/Image Vectorization_ a Review.pdf
# Output: ../layer2_completion/txt/Image Vectorization_ a Review.txt


--- Page 1 ---

Image Vectorization: a Review
Maria Dziuba1, Ivan Jarsky1, Valeria Efimova1, and Andrey Filchenkov2
1 ITMO University {dziuba.maria,ivanjarsky,vefimova}@itmo.ru
2 GO AI LAB aaafil@gmail.com
Abstract. Nowadays, there are many diffusion and autoregressive mod-
els that show impressive results for generating images from text and other
input domains. However, these methods are not intended for ultra-high-
resolution image synthesis. Vector graphics are devoid of this disadvan-
tage, so the generation of images in this format looks very promising.
Instead of generating vector images directly, you can first synthesize a
raster image and then apply vectorization. Vectorization is the process
of converting a raster image into a similar vector image using primitive
shapes. Besides being similar, generated vector image is also required
to contain the minimum number of shapes for rendering. In this pa-
per, we focus specifically on machine learning-compatible vectorization
methods. We are considering Mang2Vec, Deep Vectorization of Technical
Drawings, DiffVG, and LIVE models. We also provide a brief overview
of existing online methods. We also recall other algorithmic methods,
Im2Vec and ClipGEN models, but they do not participate in the com-
parison, since there is no open implementation of these methods or their
official implementations do not work correctly. Our research shows that
despite the ability to directly specify the number and type of shapes,
existing machine learning methods work for a very long time and do not
accurately recreate the original image. We believe that there is no fast
universal automatic approach and human control is required for every
method.
Keywords: Vector graphics · Image vectorization · Computer vision.
1
Introduction
In computer graphics, two main approaches for image representation coexist.
While a bitmap image is a matrix of pixels, a vector image is a sequence of
shapes drawn with the canvas. Raster graphics are commonly used for complex
images containing a large number of visual details and complex color transitions.
Most often these are photos and photorealistic drawings. At the same time, vec-
tor images consist of figures, which typically have a constant one-color fill. This
results in the simplicity and abstractness of the resulting image. Therefore, the
primary domains of vector graphics are icons, logos, simple illustrations, and
fonts. Vector images are easily embedded in HTML markup and a crucial re-
quirement is the small size of the code describing them for fast data transfer
to the user and subsequent rapid rendering. The most popular vector format is
arXiv:2306.06441v1  [cs.CV]  10 Jun 2023


--- Page 2 ---

2
M. Dziuba et al.
SVG, which defines a vector image as a tag sequence using XML markup. Each
tag can use XML attributes to specify the shape color characteristics and trans-
formations. Using this markup, a renderer program draws an image consisting
of the specified figures. Thus, the task of vectorizing a bitmap image is similar
to the task of obtaining a sequence of shapes and their parameters that together
form the original raster image.
In 2014, generative adversarial models [9] became the first machine learning
algorithm for image synthesis. Since then, image synthesis has become an im-
portant part of digital art, data augmentation techniques, design, fashion, and
several other domains. Currently, the image generation task is solved with deep
generative models based on diffusion models [24,25] and autoregressive mod-
els [7,35].
Modern generative methods have recently achieved significant success in the
raster domain. However, despite these approaches being designed to generate
highly realistic images in different styles from the input text, the resulting images
do not have a high resolution; usually, it is less than 2048x2048 pixels. However,
it is not enough for logos, covers, and for printing. In these domains, vector
graphics are standard.
One of the ways to obtain such images is to use vector graphics instead of
raster graphics. Notably, little research is done in vector image generation [1,32,8,5,19,26,11,4].
The creation of vector images is still done by humans, but working with the vec-
tor image code is not an easy task. Therefore, the ability to generate such images
automatically with a minimal number of post-processing steps is very necessary.
A possible solution for obtaining a vector image is the vectorization of raster
images. It may also allow the enrichment of vector datasets that are required
for training vector image generation algorithms, but the size of which is still not
sufficient in comparison with bitmap image datasets.
The existing image vectorization methods can be divided into two categories:
algorithmic and machine learning-based methods. Algorithmic approaches have
recently been reviewed [31]. The authors classify the vectorization methods as
mesh-based and curve-based. Mesh-based methods split the image into non-
overlapping 2D patches and interpolate colors across them. The patch shape can
be triangular [38,18,10], rectangular [21,29,15], or even irregular, for example, in
the form of Bézigons, closed regions bounded by Bézier curves [30,16,34], and the
patch vertices or interior can store color and other attributes. Curve-based meth-
ods are based on diffusion curves, which are Bézier curves with colors defined on
their left and right sides. Color discontinuities can be modeled by diffusing the
colors from both sides of the curves to create the resulting image. For smooth
edges, the diffusion process might be followed by a blurring phase. There are dif-
ferent formulations of diffusion curves to work with: basic and harmonic [2,37,12],
and biharmonic [33] as well.
Although several vectorization methods exist, no decent comparison was
made to the best of our knowledge. In this paper, we focus on machine learning-
compatible image vectorization methods. We aim to classify and compare them
using different evaluation criteria. The main comparison criteria of the vector-


--- Page 3 ---

Image Vectorization: a Review
3
izing methods are: 1) similarity to the original bitmap; 2) the simplicity or
complexity of the resulting image including the number of shapes and their pa-
rameters; 3) the speed of generation; 4) versatility — the ability to generate a
fairly accurate copy of the input image without prior model training; 5) human
control to adjust hyperparameters.
The contributions of this paper are overview of machine learning-compatible
vectorization methods and comparison of their performance.
2
Machine Learning-compatible Methods
2.1
DiffVG
The work suggesting DiffVG [17] is grounding for machine learning-based vector
image generation methods as it implements a differentiable vector image ras-
terization function linking vector and raster domains. A raster image can be
vectorized with DiffVG by fitting a predefined number of randomly initialized
Bézier curves to the target image, see Fig. 1. Optimization can be performed
by minimizing the L2 loss between a raster and rasterized vector images or a
deep-learning-based perceptual loss [36].
Original
image
Step 1
Step 20
Step 50
Step 100
Step 200
Step 500
Fig. 1. Iterative vectorization using DiffVG method. Each generated image has 62
paths, the same number paths is used in the original vector image.
The authors also propose a simple variational autoencoder [13] for vectorizing
MNIST digits images [3]. The encoder convolves the input raster image into a
latent space, a vector image is synthesized from the embedding, then the input
and synthesized images are compared using the proposed rasterization function.
The resulting images are inaccurate because each character is represented by
several curves that look like the artist’s strokes. The results do not exactly
match the original images of such a simple dataset as MNIST.
One of this method features is also worth mentioning. The running time of
the rasterization algorithm significantly depends on the size of the output image.
However, output size reduction result in the loss of important image details. This
problem arises due to the nature of vector images. By analogy with raster images
size decrease, that leads to the loss of image details, the same effect occurs when
the number of paths is reduced in vector images.


--- Page 4 ---

4
M. Dziuba et al.
2.2
Im2Vec
The Im2Vec [23] paper offers a model for image vectorization and interpolation.
Its architecture is based on the variational auto-encoder (VAE) [14] proposed in
DiffVG. The model maps an input raster image into a latent space sequentially
generating a similar vector image. While training, to compare the generated
vector image with the input raster image, the vector image is rasterized using a
differentiable rasterizer.
In the paper, the authors propose a new way of generating closed shapes.
Initially, a circle is sampled for each shape, and then, based on the latent vectors
of the shapes generated with LSTM, the circle deforms.
Since the difference between the target and output images is significant at the
beginning of training, the authors suggest using multi-resolution loss. The paper
proposes to rasterize images in different resolutions, thus building a pyramid of
images, with the loss function for each layer being calculated. The total multi-
resolution loss optimized is:
EI∼D
L
X
l=1
∥pyrl(I) −Ol∥2,
where L is the number of pyramid levels, pyrl(I) is the l-th pyramid level,
Ol is output rasterized at the corresponding spatial resolution, and D is the
training dataset. Unfortunately, using the official implementation, the results
can hardly be reproduced. During the first 700 epochs of training on the emoji
dataset, which was collected and published by the authors, the generation result
has no changes and consists of a single point in the center of the image. We
have also noticed that the shapes colors are fixed in the implementation, i.e.
no separate color generation can be performed, so we have added a separate
LSTM model for predicting the colors of figures. However, resolving issues to
their implementation, the authors themselves point out that color prediction
causes instability during generation.
Thus, this work cannot be considered as a universal model for vectorizing any
image, because: 1) it must be pretrained on a large number of vector images,
which are hard to obtain; 2) the found shortcomings are likely to lead to learning
instability providing resulting images of poor quality.
2.3
LIVE
In paper [20], LIVE vectorizer was introduced. LIVE is a logical continuation of
the iterative method proposed in DiffVG. However, LIVE does not operate with
all shapes simultaneously from the first iteration. Instead, it gradually adds one
or more shapes to the canvas layer by layer and then performs an optimization
step.
Unlike DiffVG, LIVE operates only with closed shapes consisting of cubic
Bézier curves. There is an issue that some of them may become self-interacted


--- Page 5 ---

Image Vectorization: a Review
5
during optimization, which results in undesirable artifacts and incorrect topol-
ogy. Although additional paths could cover artifacts, it would complicate the
resulting SVG making it impossible to effectively investigate the underlying
topological data. The authors discovered that a self-intersecting path always
intersects the lines of its control points, and vice versa, assuming that all of
the Bézier curves are of the third order. Therefore, the authors introduce a new
loss function (Xing-loss) designed to solve this self-intersection problem. The
fundamental idea is to only optimize the case when the angle of the curve is
180°degrees. In other words, the authors urge the angle between the first and
last control points connections to be greater than 180°in a cubic Bézier path.
This loss acts as a regularizer on self-intersection and its formula is:
LXing = D1(ReLU(−D2))(1 −D1)(ReLU(D2))
where D1 is a characteristic of the angle between two segments of a cubic Bézier
path, and D2 = sin α — value of that angle.
To make each path responsible only for a single feature of the image, the
authors introduce Unsigned Distance guided Focal loss (UDF loss) as well; it
treats each pixel differently depending on how close it is to the shape contour.
According to intuition, the UDF loss amplifies differences near the contour and
suppresses differences in other areas — LIVE weighs an L2 reconstruction loss
by distance to the nearest path. By doing this, LIVE defends against the mean
color problem caused by MSE and keeps accurate color reconstruction:
LUDF = 1
3
w×h
X
i=1
d′
i
3
X
c=1
(Ii,c −ˆ
Ii,c)2,
where I is the target image, ˆI is the rendering, c indexes RGB channels in I, d′
i
is the unsigned distance between pixel i, and the nearest path boundary, and w,
h are width and height of the image.
LIVE produces relatively clean SVGs by initializing paths in stages, localized
to poorly reconstructed, high-loss regions. LIVE’s main advantage is its ability to
reconstruct an image with a user-defined amount of paths, significantly reducing
the SVG file size compared to other methods. However, it takes much time
to vectorize an image even on GPU, thus, this method is hardly applicable in
practice for complex images with a great optimal number of paths. See the
iterative process in Fig. 2.
2.4
ClipGen
The ClipGen paper [27] proposes a method based on deep learning for automati-
cally vectorizing the clipart of man-made objects. The suggested approach needs
a raster clipart image and relevant object category (for instance, airplanes). It
sequentially creates new layers, each formed by a new closed path that is filled
with a single color. All layers are combined to create a vector clipart that fits the
desired category to produce the resulting image. The suggested method is built


--- Page 6 ---

6
M. Dziuba et al.
Original
image
1 figure
(1 layer)
9 figures
(3 layers)
26 figures
(5 layers)
56 figures
(8 layers)
106 figures
(13 layers)
256 figures
(28 layers)
Fig. 2. Iterative vectorization using LIVE method.
on an iterative generative model that chooses whether to keep synthesizing new
layers and defines their geometry and appearance. For training their generative
model, they developed a joint loss function that includes shape similarity, sym-
metry, and local curve smoothness losses, as well as vector graphics rendering
accuracy loss for synthesizing a human-recognizable clipart. However, ClipGen
only works with a predefined number of categories, therefore, it cannot process
arbitrary images.
2.5
Mang2Vec
The authors of the Mang2Vec [28] paper suggest the first method for vectorizing
raster mangas by using Deep Reinforcement Learning. They develop an agent
that is trained to generate the best possible sequence of stroke lines while being
constrained to match the target manga visual features. The control parameters
for the strokes are then collected and converted to the vector format. They also
propose a reward to produce accurate strokes and a pruning method to avoid
errors and redundant strokes. Mang2Vec works only with black and white manga
and cannot be used with colored images.
Original
image
Init step 0
Step 1
Step 2
Step 3
Step 4
Step 5
Fig. 3. Vectorization using Mang2Vec method.
2.6
Deep Vectorization of Technical Drawings
The paper [6] proposes a technical line drawings vectorization method (DVoTD),
for example, for drawings of floor plans. The authors convert a technical raster
drawing, which is cleared of text, into a set of line segments and quadratic
Bézier curves that are specified by control points and width. They preprocess the


--- Page 7 ---

Image Vectorization: a Review
7
input image by eliminating noise, modifying contrast, and adding missing pixels.
Then, they divide the image into patches and calculate the starting primitive
parameters for each patch. To do this, each patch is encoded with a ResNet-based
feature extractor and decoded as feature embeddings of the primitives using a
sequence of transformer blocks. To train the network for primitive extraction,
the following loss function is proposed:
L(p, ˆp, θ, ˆθ) =
1
nprim
nprim
X
k=1
(Lcls(pk, ˆpk) + Lloc(θk, ˆθk),
where
Lcls(pk, ˆpk) = −ˆpk log pk −(1 −ˆpk) log(1 −pk),
Lloc(θk, ˆθk) = (1 −λ)∥θk −ˆθk∥1 + λ∥θk ˆθk∥2
2,
ˆp — the target confidence vector (is all ones, with zeros in the end that indicate
placeholder primitives, all target parameters ˆθk of which are set to zero).
The approximated primitives improve by aligning to the cleaned raster. The
improved predictions from all patches are combined.
3
Online Vectorization Methods
There are plenty of websites that can vectorize any raster image. Existing on-
line methods can be free to use (svgstorm.com, www.visioncortex.org/vtracer,
vectorization.eu) or proprietary (vectorizer.io).
Common options provided by these methods is the selection of vector graph-
ics output file format (SVG, EPS, PDF), color palette and the number of colors
used. Some services allow choosing the quality of image detail (Low, Medium,
High), the type of shapes used (Curve Fitting - pixel/polygon/curve), back-
ground removal and many other actions and parameters. These options affect
the processing speed, the visual result and the number of shapes. The generation
speed highly depends on the resolution of the input raster image and its details
complexity. On average, the processing time of one image is 10 seconds.
Even though they are easy to use, a lot of parameters should be fixed by
a user. It should be mentioned that the resulting image quality and its size
hardly depend on the input image quality and resolution. Low quality results
in producing images with a lot more paths that are actually needed leading to
noticeable artifacts.
One of the popular online services for vectorization is VTracer [22], which
provides many options for a user. According to its documentation, firstly the
method clusters the input image by hierarchical clustering and each of the output
clusters traces into vector. After converting pixels into staircase-like paths, the
method then simplifies the paths into polygons and in the end smoothens and
approximate them with a curve-fitter.
We have come across the following drawbacks of this service. Firstly, VTracer
does not work well with all image formats, for example, it produces a black


--- Page 8 ---

8
M. Dziuba et al.
background instead of a transparent one while processing PNGs and there are
no options to change this behaviour. Secondly, VTracer does not handle low-
quality images well, creating many unnecessary inaccurate shapes. In Fig. 4, we
show an example of the black background appearance for a PNG high-quality
image and the result for the same image converted to JPG having low quality.
Original
PNG image
PNG
vectorized
with black
background
(81 paths)
Original
JPG image
JPG
vectorized
(720 paths)
Fig. 4. VTracer vectorization and its issues with the black background color and inac-
curate vectorization of low-quality images.
4
Comparison
4.1
Comparison Criteria
To make a valuable comparison of vectorization methods, it is necessary to con-
sider that the visual appealingness and similarity of the resulting vector image
to the original raster image is not the only important criterion. The speed of
vectorization is also an important factor.
The main advantages of a vector image are its simplicity and a small number
of shapes used. Although a vector image can contain various shapes (circles,
rectangles, paths, etc.), vectorization methods tend to generate images using
only paths. Paths themselves consist of segments (Bèzier curves, straight lines,
etc.) and their number in each path should be low as well. This is necessary
both for simpler post-processing by designers and faster image transfer to the
user through the Internet with subsequent vector image rendering.
Thus, the main five criteria for evaluating vectorization methods are:
1. similarity to the original bitmap;
2. the simplicity or complexity of the resulting image including the number of
shapes and their parameters;
3. the speed of generation;
4. versatility — the ability to generate a fairly accurate copy of the input image
without prior model training;
5. human control to adjust hyperparameters.


--- Page 9 ---

Image Vectorization: a Review
9
Image De-
scription
Original
Mang2Vec
DVoTD
DiffVG
(closed)
DiffVG
(unclosed)
LIVE
Simple
Vector
Medium
Vector
Hard
Vector
Simple
Raster
Medium
Raster
Hard
Raster
Fig. 5. Qualitative comparisons of image vectorization results using different methods.
DiffVG closed stands for the DiffVG method with closed paths, unclosed - with unclosed
strokes. DiffVG and LIVE results for the 3 initially vector images have the paths
amount as in the original images, for the Simple raster image 32 paths were used, for
the Medium and Hard Raster – 1024 paths. The other methods have been run with
their default parameters.
However, taking into account all the criteria at the same time is challenging,
because the methods we consider have many different parameters that affect
all the criteria simultaneously. Typically, by changing one parameter, one can
achieve an increase in image processing speed but at the same time reduce the
quality of the resulting image.
4.2
Experiment Setup
We selected 6 images for comparison: 3 rasterized vector images and 3 bitmaps
of different complexity. The original target vector images before rasterization
had the following number of paths: dragon had 25, burger – 62, red landscape
– 100. Ideally, vectorization methods should create images consisting of an ap-


--- Page 10 ---

10
M. Dziuba et al.
proximately similar number of paths in a short period of time. At the same time,
it does not worth expecting vectorization methods to account for every image
detail on initially raster images, as an over-detailed vector image does not satisfy
the simplicity criterion — a smaller number of paths. It is also desirable that
simple monochrome patches should be decorated with a minimum number of
shapes and the image subject should not be lost.
We compare the following methods (with publicly available implementation):
Mang2Vec, Deep Vectorization of Technical Drawings (DVoTD), iterative Dif-
fVG and LIVE methods, and online methods. The following models are not
included in the comparison: 1) Im2Vec [23], because we could not confirm in
practice the results described in the paper, and it also requires additional serious
pre-training for processing relatively diverse images; 2) ClipGEN [27], because
the model is limited to the set of predefined classes and there no its implementa-
tion is publicly available; 3) VAE and GAN introduced in DiffVG [17], because
they also require additional pre-training. Also, even on such a simple dataset as
MNIST, we found their results are not satisfactory enough; 4) algorithmic meth-
ods, since we found no implementations publicly available. Fig. 5 contains the
original images and their vectorized versions using different methods reviewed
in our paper.
Our experiments have proven that the Mang2Vec and DVoTD models are not
versatile, since they are capable of processing only black-and-white images. At
first glance, Mang2Vec vectorizes the image well, but its significant drawback is
the use of a very large number of shapes: for instance, the “burger” image on the
last 5th iteration had 3065 paths and the “dragon” image on the 20th iteration
16600 had paths. Also, the method adds many <clippath> and <circle> tags,
which seems useless. The method uses image splitting into patches and performs
a separate vectorization of each patch, which is acceptable when processing de-
tailed manga images. However, a large monochrome space becomes divided into
a large number of shapes, which is unacceptable. In the Mang2Vec method, you
can specify a different number of iterations, but with a small number of them,
the patches boundaries, into which the division is performed, become clearly
visible. Since Mang2Vec automatically resizes image to 4096x4096 resolution its
working time is constant and is 157 seconds.
Deep Vectorization of Technical Drawings (DVoTD) was meant to be able
to use either quadratic Bézier curves or straight lines. We managed to run the
method for curves, but the implementation of the second method (straight lines)
is imperfect and the code is likely to contain some issues that lead to a crash
during execution, which we could not fix. The method struggles to fill in contours
with a solid color, as it was originally made to generate black stroke lines. We
ran the method with default parameters and, for instance, the “dragon” image
had 132 paths. The running time of the 270x480 image was 142 seconds, 373x405
– 179 seconds, 582x496 – 273 seconds.
Vectorization by the DiffVG iterative method can be done in two ways: gen-
erating images consisting of curves and of closed shapes. The approach is simple
and quite effective, but it produces many artifacts with shapes that the method


--- Page 11 ---

Image Vectorization: a Review
11
apparently attempts to hide, but it fails to succeed. In addition, the reconstruc-
tion of absolutely exact visual copies of the original vector images cannot be
obtained even using a large number of paths (1024 shapes).
Different renderers convert a vector image to a bitmap in different ways.
For example, images generated by DiffVG and LIVE will look inaccurate and
careless, when they are rendered by the InkScape. This behavior occurs due
to the fact that these images contain curves protruding beyond the edges of
the viewBox attribute, and InkScape displays them instead of cropping them.
At the same time, other renderers, for example, in Google Chrome browser,
process images correctly without extra curves that remain beyond the viewBox.
However, these curves are still a problem, since they are superfluous and they
create additional artifacts in the image code and add an extra size to it.
The LIVE method iteratively adds a layer consisting of one or more shapes
specified by user to the image and optimizes the resulting image. In addition,
number of image processing iterations after applying each layer should be spec-
ified manually. LIVE sets the number of iterations to 500 by default, but we
noticed that after about 200 iterations, the image almost does not change, so
we set this value in our experiments. In the optimization process, LIVE uses the
DiffVG rasterizer to convert the current vector image into a raster image and
compare it with the target image. Rasterization is performed by default at the
same resolution as the target image, but for large resolutions it is computation-
ally time-consuming. For example, for a resolution of 1080x1920, processing the
first layer in 200 iterations on the Nvidia RTX 3090 Ti GPU took 212 seconds,
then by 10th layer, processing of one layer reached 244 seconds. Finally, pro-
cessing of 28 layers has took almost 2 hours. Therefore, we decided to pre-scale
the raster images so that their maximum side does not exceed 512 pixels. At
the same time, it is worth noting that this approach carries the risk of losing
details in the image. With this approach, the processing of the first layer took 16
seconds, but by the 10th layer, the processing time of one layer was 40 seconds.
The total processing time of 46 layers took about 32 minutes. When limiting the
maximum image side to 256 pixels, the processing time of the first layer was 6
seconds, and totally 32 layers were processed in 22 minutes. It should also be
known that the processing time is also affected by the number of shapes in each
layer. In our experiments we used less than 7 shapes in each layer only the first 5
layers, after that we used 7, 10, 20 or 30 shapes in each layer gradually increasing
the number.
LIVE creates the most accurate images among the ML methods. However,
the most significant disadvantage of this method is a very long image processing
time, which depends on the number of layer additions, the number of iterations
of processing each layer, the dimensions of the image for which intermediate
rasterization is performed.
It is worth noting that DiffVG also has problems with long intermediate
rasterization, however, due to the smaller total number of iterations, this is less
noticeable. The results of DiffVG and LIVE operation times are shown in more
detail in the Tab. 1 and Tab. 2.


--- Page 12 ---

12
M. Dziuba et al.
Image Resolution Total paths Time (sec)
512x512
16
47
405x373
62
48
496x582
25
56
512x512
32
56
512x288
256
143
512x381
256
186
512x288
512
216
512x381
512
280
1920x1080
32
296
1920x1080
64
319
1920x1080
100
349
512x288
1024
389
1920x1080
256
435
512x381
1024
446
1920x1432
256
582
1920x1080
512
583
1920x1432
512
770
1920x1080
1024
837
1920x1432
1024
1099
Table 1. The running time of the DiffVG iterative algorithm at different startup
parameters on NVidia RTX 3090Ti GPU. Total iterations number is 500. There is no
serious speed difference between methods with closed and unclosed paths.
Image Resolution
Layers schema
Total layers Total paths Time (sec)
256x256
4x1
4
4
33
256x256
8x1
8
8
77
256x218
1,2,3,4,5x3
7
25
78
256x256
16x1
16
16
158
235x256
1,3,5x2,7x7
11
62
162
144x256
1,3,4,5,7,10x8
13
100
169
256x218
25x1
25
25
278
256x256
32x1
32
32
423
235x256
62x1
62
62
945
144x256
100x1
100
100
1231
471x512
1,3,5,7,10x24
28
256
1448
190x256
1,3,5,7,8,10x2,20x4,30x30
41
1024
2332
256x218
1,3,5,7,8,10x2,20x4,30x30
41
1024
2490
288x512
1,3,5,7,8,10x2,20x4,30x30
41
1024
3197
471x512
1,3,5,7,8,10x2,20x4,30x30
41
1024
3891
1080x1920
1,3,5,7,10x24
28
256
7150
Table 2. The running time of the LIVE algorithm with different startup parameters
on NVidia RTX 3090Ti GPU. Each layer is processed for 200 iterations.


--- Page 13 ---

Image Vectorization: a Review
13
The requirement of DiffVG and LIVE models of directly controlling the num-
ber and type of applied shapes on the one hand is their advantage, but on the
other hand, since there are no good models for determining the required number
of shapes, automatic vectorization of a large set of various raster images becomes
almost impossible.
The online methods we found show the best quality of image vectorization.
However, this is achieved by using a large number of shapes, the number of which
can only be controlled indirectly by specifying the number of available colors.
The results are presented in Tab. 3.
Method
Approach Type
Code Versatility
Speed
Number of figures
DiffVG
ML: Iterative
+
+
Low
User-defined
Im2Vec
ML: VAE
+
-
Pretrain needed
User-defined
LIVE
ML: Iterative
+
+
Very low
User-defined
ClipGEN
ML: Iterative+DL
-
-
Pretrain needed
User-defined
Mang2Vec
ML: RL
+
-
Medium
Many
DVoTD
ML: DL
+
-
Medium
Many
VTracer
Algorithmic, online
+
+
Very High
Medium
Table 3. Classification and comparison of vectorization methods. ’ML’ means machine
learning, ’DL’ means deep learning, and ’RL’ means reinforcement learning.
However, none of the considered methods could recreate exact copies using
such a number of figures.
5
Conclusion
In this work we have shown that current image vectorization methods are diffi-
cult to use in practice. Online methods without manual hyperparameter tuning
create images containing a large number of paths, which increases the amount
of used memory, and design refinement becomes a time-consuming task. All the
existing machine learning-compatible methods also require human control and
adjustment of method iterations number, output vector image parameters, etc.
The Im2Vec model is not capable of storing and generating complex images and
is not a universal vectorizer that could create a vector analog for any input im-
age. The LIVE method is the only universal model that allows you to control
the number of drawn shapes, however, due to the use of an iterative approach,
generating a single image takes a huge amount of time.
According to our measurements, DiffVG is the fastest among ML methods
without much quality losses. However, a large number of paths are required for
high-quality results. At the same time, LIVE is able to get no worse quality
using fewer shapes. However, the main problem with the LIVE method is its
extra-long running time.


--- Page 14 ---

14
M. Dziuba et al.
Perhaps, generally, it is best to use online methods, but they do not allow
you to adjust the number of applied shapes.
To summarize, vectorization methods are connected with a tradeoff between
image quality, path number, segment number, closed or not paths are, number
of iterations, and running time.
References
1. Carlier, A., Danelljan, M., Alahi, A., Timofte, R.: Deepsvg: A hierarchical gen-
erative network for vector graphics animation. CoRR abs/2007.11301 (2020),
https://arxiv.org/abs/2007.11301
2. Dai, W., Luo, T., Shen, J.: Automatic image vectorization using superpixels and
random walkers. 2013 6th International Congress on Image and Signal Processing
(CISP) 2, 922–926 (2013)
3. Deng, L.: The mnist database of handwritten digit images for machine learning
research. IEEE Signal Processing Magazine 29(6), 141–142 (2012)
4. Efimova, V., Chebykin, A., Jarsky, I., Prosvirnin, E., Filchenkov, A.: Neural style
transfer for vector graphics (2023)
5. Efimova, V., Jarsky, I., Bizyaev, I., Filchenkov, A.: Conditional vector graphics
generation for music cover images. arXiv preprint arXiv:2205.07301 (2022)
6. Egiazarian, V., Voynov, O., Artemov, A., Volkhonskiy, D., Safin, A., Taktasheva,
M., Zorin, D., Burnaev, E.: Deep vectorization of technical drawings. In: Computer
Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020,
Proceedings, Part XIII 16. pp. 582–598. Springer (2020)
7. Esser, P., Rombach, R., Ommer, B.: Taming transformers for high-resolution image
synthesis. In: Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition. pp. 12873–12883 (2021)
8. Frans, K., Soros, L.B., Witkowski, O.: Clipdraw: Exploring text-to-drawing syn-
thesis through language-image encoders. CoRR abs/2106.14843 (2021), https:
//arxiv.org/abs/2106.14843
9. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S.,
Courville, A., Bengio, Y.: Generative adversarial networks. Communications of the
ACM 63(11), 139–144 (2020)
10. Hettinga, G.J., Echevarria, J., Kosinka, J.: Efficient image vectorisation using mesh
colours. The Eurographics Association (2021)
11. Jain, A., Xie, A., Abbeel, P.: Vectorfusion: Text-to-svg by abstracting pixel-based
diffusion models. arXiv preprint arXiv:2211.11319 (2022)
12. Jeschke, S., Cline, D., Wonka, P.: Estimating color and texture parameters for
vector graphics. In: Computer Graphics Forum. vol. 30, pp. 523–532. Wiley Online
Library (2011)
13. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114 (2013)
14. Kingma, D.P., Welling, M.: An introduction to variational autoencoders. arXiv
preprint arXiv:1906.02691 (2019)
15. Lai, Y.K., Hu, S.M., Martin, R.R.: Automatic and topology-preserving gradient
mesh generation for image vectorization. ACM Transactions on Graphics (TOG)
28(3), 1–8 (2009)
16. Lecot, G., Lévy, B.: Ardeco: automatic region detection and conversion. In: Euro-
graphics Symposium on Rendering (2006)


--- Page 15 ---

Image Vectorization: a Review
15
17. Li, T.M., Lukáč, M., Michaël, G., Ragan-Kelley, J.: Differentiable vector graphics
rasterization for editing and learning. ACM Trans. Graph. (Proc. SIGGRAPH
Asia) 39(6), 193:1–193:15 (2020)
18. Liao, Z., Hoppe, H., Forsyth, D., Yu, Y.: A subdivision-based representation for
vector image editing. IEEE transactions on visualization and computer graphics
18(11), 1858–1867 (2012)
19. Lopes, R.G., Ha, D., Eck, D., Shlens, J.: A learned representation for scalable vector
graphics. CoRR abs/1904.02632 (2019), http://arxiv.org/abs/1904.02632
20. Ma, X., Zhou, Y., Xu, X., Sun, B., Filev, V., Orlov, N., Fu, Y., Shi, H.: Towards
layer-wise image vectorization. In: Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. pp. 16314–16323 (2022)
21. Price, B., Barrett, W.: Object-based vectorization for interactive image editing.
The Visual Computer 22, 661–670 (2006)
22. Pun, S., Tsang, C.: Vtracer (2020)
23. Reddy, P., Gharbi, M., Lukac, M., Mitra, N.J.: Im2vec: Synthesizing vector graph-
ics without vector supervision. In: Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition. pp. 7342–7351 (2021)
24. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution
image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition. pp. 10684–10695 (2022)
25. Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.L., Ghasemipour,
K., Gontijo Lopes, R., Karagol Ayan, B., Salimans, T., et al.: Photorealistic text-
to-image diffusion models with deep language understanding. Advances in Neural
Information Processing Systems 35, 36479–36494 (2022)
26. Schaldenbrand, P., Liu, Z., Oh, J.: Styleclipdraw: Coupling content and style in
text-to-drawing translation. arXiv preprint arXiv:2202.12362 (2022)
27. Shen, I.C., Chen, B.Y.: Clipgen: A deep generative model for clipart vectorization
and synthesis. IEEE Transactions on Visualization and Computer Graphics 28(12),
4211–4224 (2021)
28. Su, H., Niu, J., Liu, X., Cui, J., Wan, J.: Vectorization of raster manga by deep
reinforcement learning. arXiv preprint arXiv:2110.04830 (2021)
29. Sun, J., Liang, L., Wen, F., Shum, H.Y.: Image vectorization using optimized
gradient meshes. ACM Transactions on Graphics (TOG) 26(3), 11–es (2007)
30. Swaminarayan, S., Prasad, L.: Rapid automated polygonal image decomposition.
35th IEEE Applied Imagery and Pattern Recognition Workshop (AIPR’06) pp.
28–28 (2006)
31. Tian, X., Günther, T.: A survey of smooth vector graphics: Recent advances in
representation, creation, rasterization and image vectorization. IEEE Transactions
on Visualization and Computer Graphics (2022)
32. Wang, Y., Lian, Z.: Deepvecfont: synthesizing high-quality vector fonts via dual-
modality learning. ACM Transactions on Graphics (TOG) 40(6), 1–15 (2021)
33. Xie, G., Sun, X., Tong, X., Nowrouzezahrai, D.: Hierarchical diffusion curves for
accurate automatic image vectorization. ACM Transactions on Graphics (TOG)
33(6), 1–11 (2014)
34. Yang, M., Chao, H., Zhang, C., Guo, J., Yuan, L., Sun, J.: Effective clipart im-
age vectorization through direct optimization of bezigons. IEEE Transactions on
Visualization and Computer Graphics 22, 1063–1075 (2016)
35. Yu, J., Xu, Y., Koh, J.Y., Luong, T., Baid, G., Wang, Z., Vasudevan, V., Ku,
A., Yang, Y., Ayan, B.K., et al.: Scaling autoregressive models for content-rich
text-to-image generation. arXiv preprint arXiv:2206.10789 (2022)


--- Page 16 ---

16
M. Dziuba et al.
36. Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O.: The unreasonable
effectiveness of deep features as a perceptual metric. In: Proceedings of the IEEE
conference on computer vision and pattern recognition. pp. 586–595 (2018)
37. Zhao, S., Durand, F., Zheng, C.: Inverse diffusion curves using shape optimization.
IEEE transactions on visualization and computer graphics 24(7), 2153–2166 (2017)
38. Zhou, H., Zheng, J., Wei, L.: Representing images using curvilinear feature driven
subdivision surfaces. IEEE transactions on image processing 23(8), 3268–3280
(2014)
