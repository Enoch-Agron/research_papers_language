# RESEARCH PAPERS COMPENDIUM: LAYER1

Generated: Sat 19 Jul 17:55:27 NZST 2025
Purpose: Research foundation for layer1 domain
Source: ./layer1/

---

# TABLE OF CONTENTS

Chapter 1: PAPERS IN LAYER1

---

# CHAPTER 1: PAPERS IN LAYER1

Directory: ./layer1/
Papers: 5 research papers

## Section 1.1: Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper

Source File: Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper.txt

### Paper Content:

```
# Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper.pdf
# Converted: 2025-07-18 12:58:48
# Method: pdfplumber
# Domain: pixel2physics
# Source: /home/user/vekt/papers/pixel2physics/pdfs/layer1/Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper.pdf
# Output: /home/user/vekt/papers/pixel2physics/dot_txt/layer1/Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper.txt


--- Page 1 ---

Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds
using Convolutional Neural Networks
Yizhak Ben-Shabat Michael Lindenbaum Anath Fischer
Mechanical Engineering Computer Science Mechanical Engineering
Techion IIT Techion IIT Techion IIT
Haifa, Israel Haifa, Israel Haifa, Israel
sitzikbs@gmail.com mic@cs.technion.ac.il meranath@technion.ac.il
Abstract tion [21] and surface reconstruction [11].
Estimating the normals from a raw, point-only,
In this paper, we propose a normal estimation cloud, is a challenging task due to difficulties asso-
methodforunstructured3Dpointclouds. Thismethod, ciated with sampling density, noise, outliers, and de-
called Nesti-Net, builds on a new local point cloud rep- tail level. The common approach is to specify a local
resentation which consists of multi-scale point statis- neighborhood around a point and to fit a local basic
tics(MuPS),estimatedonalocalcoarseGaussiangrid. geometric surface (e.g. a plane) to the points in this
This representation is a suitable input to a CNN archi- neighborhood. Then the normal is estimated from the
tecture. The normals are estimated using a mixture- fitted geometric entity. The chosen size (or scale) of
of-experts (MoE) architecture, which relies on a data- the neighborhood introduces an unavoidable tradeoff
driven approach for selecting the optimal scale around between robustness to noise and accuracy of fine de-
each point and encourages sub-network specialization. tails. A large-scale neighborhood over-smoothes sharp
Interesting insights into the network’s resource dis- corners and small details but is otherwise robust to
tribution are provided. The scale prediction signif- noise. A small neighborhood, on the other hand, may
icantly improves robustness to different noise levels, reproduce the normals more accurately around small
point density variations and different levels of detail. details but is more sensitive to noise. Thus it seems
Weachievestate-of-the-artresultsonabenchmarksyn- that an adaptive, data-driven scale may improve esti-
thetic dataset and present qualitative results on real mation performance.
scanned scenes.
We propose a normal estimation method for un-
structured 3D point clouds. It features a mixture-
of-experts network for scale prediction, which signif-
1. Introduction
icantly increases its robustness to different noise lev-
els, outliers, and varying levels of detail. In addition,
Commodity 3D sensors are rapidly becoming an in-
this method overcomes the challenge of feeding point
tegralpartofautonomoussystems. Thesesensors,e.g.
clouds into CNNs by extending the recently proposed
RGB-D cameras or LiDAR, provide a 3D point cloud
3D modified Fischer Vector (3DmFV) representation
representing the geometry of the scanned objects and
[4] to encode local geometry on a coarse multi-scale
surroundings. This raw representation is challenging
grid. It outperforms state-of-the-art methods for nor-
to process since it lacks connectivity information or
mal vector estimation.
structure, and is often incomplete, noisy and contains
The main contributions of this paper are:
pointdensityvariations. Inparticular,processingitby
means of the highly effective convolutional neural net-
Anewnormalestimationmethodforunstructured
works (CNNs) is problematic because CNNs require
•
3D point clouds based on mixture of experts and
structured, grid-like data as input.
scale prediction.
When available, additional local geometric informa-
tion,suchasthesurfacenormalsateachpoint,induces
a partial local structure and improves performance of A local point representation which can be used as
•
differenttaskssuchasover-segmentation[3],classifica- input to a CNN.
110112

--- Page 2 ---

Figure 1. Nesti-Net pipeline for normal estimation. For each point in a given point cloud, we compute a multi-scale point
statistics representation (MuPS). Then, a scale manager network is used to determine the optimal scale and uses the
corresponding expert sub-network to estimate the normal.
2. Related-work to fail in estimating normals near edges. Computing
the optimal neighborhood size can decrease the esti-
2.1.Deeplearningforunstructured3Dpointclouds
mation error [18] but requires the (usually unknown)
The point cloud representation is challenging for noise standard deviation value and a costly iterative
deep learning methods because it is both unstructured process to estimate the local curvature and additional
and point-wise unordered. In addition, the number of density parameters.
points in the point cloud is usually not constant. Sev- OtherapproachesrelyonusingVoronoicellsofpoint
eral methods were proposed to overcome these chal- clouds [2, 17, 9]. These methods are characterized by
lenges. Voxel-based methods embed the point cloud robustness to sharp features but are sensitive to noise.
into a voxel grid but suffer from several accuracy- To overcome this challenge, Alliez et al. [1] proposed
complexity tradeoffs [16]. The PointNet approach PCA-Voronoi approach to create cell sets which group
[20, 21] applies a symmetric, order-insensitive, func- adjacentcellstoprovidesomecontroloversmoothness.
tiononahigh-dimensionalrepresentationofindividual While many of these methods hold theoretical guaran-
points. The Kd-Network [14] imposes a kd-tree struc- teesonapproximationandrobustness,inpracticethey
ture on the points and uses it to learn shared weights rely on a preprocessing stage in the presence of strong
fornodesinthetree. Therecentlyproposed3DmFV[4] or unstructured noise in addition to a fine-tuned set of
represents the points by their deviation from a Gaus- parameters.
sian Mixture Model (GMM) whose Gaussians are uni-
Afewdeeplearningapproacheshavebeenproposed
formly positioned on a coarse grid.
to estimate normal vectors from unstructured point
In this paper, we propose a point-wise and multi-
clouds. Boulchetal. proposedtotransformlocalpoint
scale variation of 3DmFV. Instead of generating a
cloud patches into a 2D Hough space accumulator by
structuredrepresentationfortheentirepointcloud,we
randomly selecting point triplets and voting for that
represent each point and its neighbors within several
plane’s normal. Then, the normal is estimated from
scales.
theaccumulatorbydesigningexplicitcriteria[5]forbin
selectionor,morerecently,bytraininga2DCNN[6]to
2.2.Normalestimation
estimate it continuously as a regression problem. This
A classic method for normal estimation uses Princi- method does not fully utilize the 3D information since
pal Component Analysis (PCA) [12]. It first specifies it loses information during the transformation stage.
the neighbors within some scale, and then uses PCA We reffer to this method as HoughCNN in the evalu-
regression to estimate a tangent plane. Variants fit- ation section. A more recent method, PCPNnet [11],
ting local spherical surfaces [10] or jets [7] (truncated uses a PointNet [20] architecture on local point neigh-
Taylorexpansion)werealsoproposed. Toberobustto borhoods of multiple scales. It achieves good normal
noise,thesemethodsusuallychoosealarge-scaleneigh- estimationperformanceandhasbeenextendedtoesti-
borhood, leading them to smooth sharp features and mating other surface properties. However, it processes
10113

--- Page 3 ---

the multi-scale point clouds jointly and does not select with the GMM density is:
an optimal scale. This type of architecture tends to
K
encourage averaging during training rather than spe-
u (p)= w u (p). (2)
cialization [13]. λ k k
kX=1
In this paper we propose a method that approxi-
matesthelocalnormalvectorusingapoint-wise,multi- The 3DmFV uses a uniform GMM on a coarse
scale 3DmFV representation which serves as an input m m m3Dgrid,wheremisanadjustableparame-
to a deep 3D CNN architecture. In addition, we learn ter × usua × lly chosen to be from m=3 to 8. The weights
the neighborhood size that minimizes the normal es- are set to be w = 1, the standard deviation is set to
k K
timation error using a mixture of experts (MoE) [13], beσ = 1,andthecovariancematrixtobeΣ =σ I.
k m k k
which encourages specialization. Although the parameters in GMMs are usually set us-
ing maximum likelihood estimation, here uniformity is
2.3.Representingpointcloudsusing3DmFV crucial for shared weight filtering (convolutions).
The FV is expressed as the sum of normalized gra-
The 3DmFV representation for point clouds [4] dients for each point p . The 3DmFV is specified sim-
t
achieved good results for point cloud classification us- ilarly using additional symmetric functions, i.e. min
ing a 3D CNN. See Section 3.1 for details. In this pa- and max. They are symmetric in the sense proposed
perweproposetheMulti-scalePointStatistics(MuPS) in [20] and are therefore adequate for representing the
representation, which extends the 3DmFV and com- structureless and orderless set of points. Adding these
putes a point-wise multi-scale 3DmFV. functions makes the representation more informative
and the associated classification more accurate [4]:
3. Approach
T
GX = L logu (p ), (3)
The proposed method is outlined in Figure 1. It FVλ λ ∇ λ λ t
Xt=1
receives a 3D point cloud as input and consists of two
mainstages. Inthefirststage,wecomputeamultiscale T L logu (p )
p st o a i g n e t w re e p f r e e e s d en it ta i t n i t o o n, a d m e i n x o tu te r d e-o M f-e u x P p S e . rt I s n (M th o e E) se C co N n N d G 3 X DmFVλ = P ma t x = t 1 (L λ λ ∇ ∇ λ λ logu λ λ (p t t ) (cid:12) (cid:12) (cid:12)|λ λ = = α α , , µ µ , , σ σ  (4)
 min (L logu (p )) 
architecture and estimate the normal at each point as  t λ ∇ λ λ t |λ=µ,σ 
output. The stages are detailed below. whereL isthesquarerootoftheinverseFisherInfor-
λ
mation Matrix, and the normalized gradients are:
3.1.MuPS-Multi-scalepointstatistics
T
1
GX = (γ (k) w ), (5)
MuPS is a local multi-scale representation which αk √w t − k
computes point statistics on a coarse Gaussian grid.
k Xt=1
It builds on the well-known Fisher Vector (FV) [22], 1 T p µ
and the recently proposed 3DmFV representation [4]. GX = γ (k) t − k , (6)
µk √w t (cid:18) σ (cid:19)
Therefore, we first outline the FV and the 3DmFV, k Xt=1 k
and then continue to the MuPS representation and its
1 T (p µ )2
attractive properties. GX = γ (k) t − k 1 . (7)
FV and 3DmFV for 3D point clouds: Given σk √2w k Xt=1 t (cid:20) σ k 2 − (cid:21)
a set of T 3D points X = p R3,t = 1,...T
t Here,wefollow[15]andensurethatu (x)isavaliddis-
{ ∈ } λ
and a set of parameters for a K component GMM,
tributionbychangingthevariablew toα tosimplify
k k
λ = (w ,µ ,Σ ),k = 1,...K , where w ,µ ,Σ are
k k k k k k the gradient calculation using :
{ }
the mixture weight, center, and covariance matrix of
the k-th Gaussian. The likelihood of a single 3D point w = exp(α k ) . (8)
p associated with the k-th Gaussian density is k K exp(α )
j=1 j
P
u (p)=
1
exp
1
(p µ )
′
Σ
−1(p
µ ) .
Inaddition,γ
t
(k)expressesthesoftassignmentofpoint
k (2π)D/2 | Σ k | 1/2 (cid:26)−2 − k k − k (cid:27) p t to Gaussian k, as obtained from the derivatives:
(1)
w u (p )
γ (k)= k k t . (9)
Therefore, the likelihood of a single point associated t K w u (p )
j=1 j j t
P
10114

--- Page 4 ---

Scale manager Expert
The FV and 3DmFV are normalized by the number of Input: MuPS
points in order to be sample-size independent [22]: 3 3 D D I I n n c c e e p p t t i i o o n n : : [ [3 3 , , 5 5 , , 1 2 2 5 8 6 ] ] Input: G 3 X˜ D i m (r F i) V
3D Inception: [3, 5, 256] 3D Inception : [3, 5, 128]
1 1 maxpool [2, 2, 2] 3D Inception: [3, 5, 256]
GX GX ,GX GX . (10) 3D Inception: [2, 4, 512] maxpool [2, 2, 2]
FVλ ← T FVλ 3DmFVλ ← T 3DmFVλ 3D Inception: [2, 4, 512] 3D Inception: [2, 4, 256]
maxpool [2, 2, 2]
maxpool [2, 2, 2]
3D Inception: [1, 2, 512]
3D Inception: [2, 4, 512]
maxpool [2, 2, 2]
maxpool [2, 2, 2]
Note that these are global representations which are FC [1024]
FC [256] FC [512]
applied to the entire set, i.e., the entire point cloud. FC [128] FC [128]
MuPS definition : For each point p in point set X FC [n] FC [64]
softmax FC [3]
we first extract n point subsets X˜ i (r i ) | i=1,...n ⊂ X Output: q i Output: N i
whichcontainT i (p,r i )pointsandliewithinadistance 3D Inception: [c, c, M]
1 2
of radius r from p. We refer to each of these subsets Input: [m x m x m x L]
i
as a scale. Note that each scale may contain a
Avg. pool: CNN
different number of points. For scales with many Filter: [cx cx c] Filter: [1x1x1]
1 1 1
Channels: 1 Channels : M
points, we set a maximal point threshold, and sample
a random subset of T points for that scale. Here, CNN CNN CNN
max Filter: [1x1x1] Filter: [cx cx c] Filter: [cx cx c]
r i and T max are design parameters. Next, the scales Channels : M Channe 1 l s : M 1 /2 1 Channe 2 l s : M 2 /2 2
(subsets) are independently translated and uniformly
Concatenate
scaled so that they fit into a zero-centered unit sphere Output: [m x m x m x 3N]
with p mapped to the origin. Then, the 3DmFV Figure 2. The mixture of experts and 3D Inception mod-
representation is computed for each scale relative to a ule architecture details. The scale manager and experts
Gaussian grid positioned around the origin; see above. use several convolutional and maxpooling layers followed
Concatenating the 3DmFVs of all scales yields the by fully connected layers.
MuPS representation:
Gp = GX˜ 1(r1) ,...,GX˜ n(rn) . (11)
MuPS 3DmFV 3DmFV
(cid:16) (cid:17)
MuPSproperties: TheMuPSrepresentationovercomes estimate the normal correctly.
the main challenges associated with feeding point Experts: Thenormalisestimatedusingnseparate”ex-
clouds into CNNs. The symmetric functions make it pert” networks. Each is a multi-layered 3D Inception
independent of the number and order of points within inspired CNN followed by four fully connected layers.
eachscale. Inaddition,theGMMgivesititsgridstruc- TheMuPSrepresentationisdistributedtotheexperts.
ture, necessary for the use of CNNs. Furthermore, the This distribution is a design choice. We obtained the
multi-scale representation incorporates description of bestresultswhenfeedingeachscaletotwodifferentex-
fine detail as well as robustness to noise. perts in addition to one expert which receives the en-
tire MuPS representation as input. Specifically, Nesti-
3.2.TheNesti-Netarchitecture
Net uses 7 experts: experts 1-2 receive the smallest
The deep network architecture is outlined in Fig- scale (1%), 3-4 the medium scale (3%), 5-6 the large
ure 1 (the green part). It is a mixture-of-experts ar- scale (5%), and expert 7 receives all the scales. The
chitecture [13] which consists of two modules: a scale last layer of each expert outputs a three-element vec-
managernetworkmodule,andanexpertsmodule. The tor N = (N ,N ,N ) . The final predicted normal
i x y z i
MoE architecture was chosen in order to overcome the (forpointp)isN ,i.e.,thenormalassociated
argmax(qi)
averaging effect of typical networks when solving a re- with the expert expected to give the best results. The
gression problem. architecture is specified in the top right of Figure 2.
Scale manager network: This module receives the Loss function: We train the network to minimize the
MuPS representation as input and processes it using differencebetweenapredictednormalN andaground
i
several 3D Inception inspired convolutions, and max- truthnormalN . Thisdifferenceisquantifiedbythe
GT
pool layers, followed by four fully connected layers, af- metric D = sinθ, where the angle θ is the difference
N
ter which a softmax operator is applied. The architec- between the vectors, and D is calculated as the mag-
N
ture is specified in the top left part of Figure 2. The nitude of the cross product between these two vectors;
output is a vector of n scalars q , which can be in- see Eq. 12. In addition, to encourage specialization of
i
tuitively interpreted as the probability of expert i to each expert network, we follow [13] and minimize the
10115

--- Page 5 ---

loss: Gaussian noise - perturbing the points with three
•
levelsofnoisespecifiedbyσ,givenasapercentage
n n
N N
L= q D = q k i × GT k . (12) of the bounding box.
i · N i N N
Xi=1 Xi=1 k i k·k GT k
Densityvariation-selectingasubsetofthepoints
•
Usingthisloss,eachexpertisrewardedforspecializing basedontwosamplingregimes: gradient,simulat-
in a specific input type. Note that during training, all ingeffectsofdistancefromthesensor,andstripes,
n normal vectors are predicted and used to compute simulating occlusions.
the loss and derivatives. However, at test time, we
For the geometric methods, we show results for three
compute only one normal, which is associated with
different scales: small, medium and large, which corre-
the maximal q .
i
spond to 18, 112, 450 nearest neighbors. For the deep
learning based methods we show the results for the
single-scale (ss) and multi-scale (ms) versions. Addi-
4. Evaluation
tional evaluation results using other metrics are avail-
4.1.Datasets able in the supplemental material.
Table 1 shows the unoriented normal estimation re-
For training and testing we used the PCPNet shape
sults for the methods detailed above. It can be seen
dataset [11]. The trainset consists of 8 shapes: four
that our method outperforms all other methods across
CAD objects (fandisk, boxunion, flower, cup) and
all noise levels and most density variations. It also
four high quality scans of figurines (bunny, armadillo,
shows that both PCA and Jet perform well for spe-
dragon and turtle). All shapes are given as triangle
cific noise-scale pairs. In addition, for PCPNet and
meshes and densely sampled with 100k points. The
HoughCNN, using a multi-scale approach only mildly
data is augmented by introducing Gaussian noise for
improves performance.
each point’s spacial location with astandard deviation
Figure3illustratesNesti-Net’sresultsonthreepoint
of 0.012, 0.006, 0.00125 w.r.t the bounding box. This
clouds. Forvisualization, thenormalvectorismapped
yields a set with 3.2M points and 3.2M corresponding
to the RGB cube. It shows that for complex shapes
training examples. The test set consists of 22 shapes,
(pillar, liberty) with high noise levels, the general di-
including figurines, CAD objects, and analytic shapes.
rectionofthenormalvectorispredictedcorrectly,but,
For evaluation we use the same 5000 point subset per
the fine details and exact normal vector are not ob-
shape as in [11].
tained. For a basic shape (Boxysmooth) the added
Forqualitativetestingonscanneddata,weusedthe
noise does not affect the results substantially. Most
NYU Depth V2 dataset [19] and the recent ScanNet
notably, Nesti-Net shows robustness to point density
dataset [8], which include RGB-D images of indoor
corruptions. The angular error in each point is visual-
scenes.
ized in Figure 4 for the different methods using a heat
4.2.Trainingdetails map. For PCA and Jet we display the best result out
ofthethreescales(small, medium, andlarge, specified
All variations of our method were trained using above), and for PCPNet the best out of its single-scale
32,768 (1024 samples 32 shapes) random subsets of andmulti-scaleoptions. Forallmethods,itcanbeseen
×
the 3.2M training samples at each epoch. For each that more errors occur near edges, corners and small
point, we extract 512 neighboring points enclosed regions with a lot of detail and high curvature. Nesti-
within a sphere of radius r. For neighborhoods with Net suffers the least from this effect due to its scale
more than 512 points, we perform random sampling, manager,whichallowsittoadapttothedifferentlocal
and for those with fewer points we use the maximum geometry types. Figure 5 shows the performance of
number of points available. For the MuPS represen- thescalemanagernetwork. Acolorisassignedtoeach
taiton we chose to use an m = 8 Gaussian grid. We expertandthechosenexpertcolorisvisualizedoverthe
used Tensorflow on a single NVIDIA Titan Xp GPU. pointcloud. Thisprovidessomeinsightregardingeach
expert’s specialization. For example, the figure shows
4.3.Normalestimationperformance
that experts 1, 2 (small scale) specialize in points in
We use the RMS normal estimation error metric for regions with high curvatures (near corners). Experts 3
comparing the proposed NestiNet to other deep learn- and 4 (medium scale) specialize in the complex cases
ing based [11, 6] and geometric methods [12, 7]. We where multiple surfaces are close to each other, or in
also analyze robustness for two types of data corrup- the presence of noise. As for the large-scale experts,
tions (augmentations): expert5specializesinplanarsurfaceswithnormalvec-
10116

--- Page 6 ---

Our
Aug. PCA [12] Jet [7] PCPNet [11] HoughCNN [6]
Nesti-Net
scale ms small med large small med large ss ms ss ms
None 6.99 8.31 12.29 16.77 7.60 12.35 17.35 9.68 9.62 10.23 10.02
Noise
σ =0.00125 10.11 12.00 12.87 16.87 12.36 12.84 17.42 11.46 11.37 11.62 11.51
σ =0.006 17.63 40.36 18.38 18.94 41.39 18.33 18.85 18.26 18.87 22.66 23.36
σ =0.012 22.28 52.63 27.5 23.5 53.21 27.68 23.41 22.8 23.28 33.39 36.7
Density
Gradient 9.00 9.14 12.81 17.26 8.49 13.13 17.8 13.42 11.7 11.02 10.67
Stripes 8.47 9.42 13.66 19.87 8.61 13.39 19.29 11.74 11.16 12.47 11.95
average 12.41 21.97 16.25 18.87 21.95 16.29 19.02 14.56 14.34 16.9 17.37
Table 1. Comparison of the RMS angle error for unoriented normal vector estimation of our Nesti-Net method to classic
geometric methods (PCA [12] , Jet [7]) with three scales, and deep learning methods (PCPNet [11], HoughCNN [6])
Figure 3. Nesti-Net normal prediction results for different
noiselevels(columns1-4),anddensitydistortions(columns
5-6). Thecolorsofthepointsarenormalvectorsmappedto
RGB.Thisfigureisbestvieweddigitallyonalargescreen.
Figure 4. Normal estimation error results for Nesti-Net
compared to other methods for three types of point clouds
withlownoiselevel(σ=1%). Thecolorsofthepointscor-
tors, which have a large component in the x direction,
respond to angular difference, mapped to a heatmap rang-
whereas expert 6 specializes in planar surfaces, which
ing from 0-60 degrees; see bottom color bar. The number
have a large component in the y direction. Expert 5
under each point cloud is its RMS error.
also specializes in very noisy planar surfaces with a
large component in the z direction. Expert 7 (com-
4.4.Scaleselectionperformance
bined scales) plays multiple roles; it handles points on
planar surfaces which have a large component in the z
We analyze the influence of scale selection on the
direction,complexgeometry,andlowtomediumnoise.
normal estimation performance. We create several ab-
Figure 6 shows the number of points assigned to each
lations of our method.
expertforallpointsinthetestset, andtheaverageer-
rorperexpert. Itshowsaninverserelationbetweenthe ss - A single scale version which directly feeds a
•
numberofpointsassignedtoanexpertanditsaverage 3DmFV representation into a CNN architecture
error: themorepointsassignedtotheexpert,thelower (a single-scale MuPS).
the error. This is consistent with the definition of the
ms - A multi-scale version which feeds the MuPS
cost function. Timing performance and visualization •
representation into a CNN architecture.
of additional results are provided in the supplemental
material. ms-sw - A multi scale version which first tries to
•
10117

--- Page 7 ---

Aug. ss ms ms-sw NestiNet
0.01
0.01 0.01 0.01
scale 0.01 0.05 0.03
0.05 0.05 0.05
0.05
None 9.32 12.73 10.83 7.88 7.76 6.99
Noise
σ =0.00125 11.31 13.36 12.98 10.46 10.29 10.11
σ =0.006 36.5 18.37 21.06 18.43 18.45 17.63
σ =0.012 55.24 23.14 26.03 22.59 22.25 22.28
Density
Gradient 16.61 14.65 12.81 11.89 9.44 9.00
Stripes 14.5 14.57 12.97 10.06 9.65 8.47
average 23.91 16.14 16.11 13.55 12.97 12.41
Table2.ComparisonoftheRMSangleerrorforunoriented
normal vector estimation of our method using single-scale
(SS), multi-scale (MS), multi-scale with switching (MS-Sw
Figure 5. Nesti-Net predicted experts (scales). Each color and multi-scale with mixture of experts (Nesti-Net)
representsthepredictedexpert foroptimalnormalestima-
tion. Color coding is given at the bottom.
unsupervised, i.e., does not need the additional noise
parameters as input during training.
4.5.Resultsonscanneddata
Weshowqualitativeresultsonscannedpointclouds
fromtheScanNet[8]andNYUDepthV2[19]datasets
in Figure 7. For visualization we project the normal
vectors’ color back to the depth image plane. column
(c)showstheresultsforNesti-Net,trainedonsynthetic
Figure 6. Nesti-Net expert (scale) prediction statistics. data with Gaussian noise. The estimated normals re-
Number of points assigned to each expert (left), and av- veal the nonsmoothness of the scanned data associ-
erage expert error (right). ated with the correlated, non-Gaussian, noise signa-
ture associated with the scanning process. Essentially
itshowsnormalestimationoftherawdata,ratherthan
estimatethenoiselevelandthenfeedsthe3DmFV
the desired normal of the underlying surface. The raw
representation of the corresponding input scale
point clouds suffer from ”bumps” which get bigger as
into different sub-networks for a discrete number
the distance from the sensor increases. Further im-
of noise levels (switching). Note that for this ver-
provement may be obtained by training Nesti-Net on
sion, the noise level is provided during training.
data corrupted with scanner noise and with ground
NestiNet - The method described in Section 3 truth normals, but such data is is currently not avail-
• which uses an MoE network to learn the scale. ableandisdifficulttomanuallylabel. Instead,wetrain
Nesti-Net with normal vectors obtained from applying
Details of the architectures for the above methods are a Total Variation (TV) algorithm on the depth map,
provided in the supplemental material. provided by Ladicky et al. [23] for the NYU depth V2
Table 2 summarizes the results of the scale selec- dataset. Note that TV substantially smooths fine de-
tion performance analysis. It shows that Nesti-Net’s tailandusesthedepthimageratherthanunstructured
scale selection performs better than all other varia- point clouds. Column (d) in Figure 7 shows that after
tions. Thisisduetothetrainedscale-managernetwork training on the TV data, the normal vector estimation
withintheMoE.Thesingle-scaleversionperformswell of the underlying surface improves significantly. Col-
for specific noise-scale pairs but inferior performance umn(b)showstheresultsofPCAwithamediumscale
foraninadequatescaleselection. Themulti-scalevaria- forreference,forsmallradius,theresultissignificantly
tionsshowimprovement;however,selectingthecorrect noisier and for large radius it over-smooths detail, see
scale yields improved performance over concatenating supplemental material. Note that Nesti-Net performs
multiple scales. The main advantage of Nesti-Net over theestimationontherawpointcloudanddoesnotuse
the switching variation is that the scale prediction is the depth image grid structure.
10118

--- Page 8 ---

[5] A. Boulch and R. Marlet. Fast and robust normal
estimation for point clouds with sharp features. In
Computer Graphics Forum, volume 31, pages 1765–
1774. Wiley Online Library, 2012.
[6] A. Boulch and R. Marlet. Deep learning for robust
normalestimationinunstructuredpointclouds. Com-
puter Graphics Forum, 35(5):281–290, 2016.
[7] F.CazalsandM.Pouget.Estimatingdifferentialquan-
titiesusingpolynomialfittingofosculatingjets. Com-
Figure7.Normalestimationresultsonscannedpointclouds puter Aided Geometric Design, 22(2):121–146, 2005.
fromtheScanNet[8](top),andNYUDepthV2dataset[19] [8] A. Dai, A. X. Chang, M. Savva, M. Halber, T. A.
(bottom). (a)RGBimage,(b)PCAresultsusingamedium Funkhouser, and M. Nießner. Scannet: Richly-
scale, (c) Nesti-Net results trained on synthetic data (d) annotated3dreconstructionsofindoorscenes. InThe
Nesti-net results trained on TV algorithm data. IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), volume 2, page 10, 2017.
[9] T. K. Dey and S. Goswami. Provable surface recon-
5. Summary
struction from noisy samples. Computational Geome-
try, 35(1-2):124–141, 2006.
Inthiswork,weproposemulti-scalepointstatistics,
[10] G. Guennebaud and M. Gross. Algebraic point set
a new representation for 3D point clouds that encodes
surfaces. ACM Transactions on Graphics (TOG),
fineandcoarsedetailswhileusingagridstructure. The
26(3):23, 2007.
representation is effective processed by a CNN archi-
[11] P. Guerrero, Y. Kleiman, M. Ovsjanikov, and N. J.
tecture(Nesti-Net)forprovideaccuratenormalestima-
Mitra.Pcpnetlearninglocalshapepropertiesfromraw
tion, which can be used for various applications, e.g.
pointclouds. Computer Graphics Forum,37(2):75–85,
surface reconstruction. The mixture-of-experts design 2018.
ofthearchitectureenablesthepredictionofanoptimal
[12] H. Hoppe, T. DeRose, T. Duchampt, J. McDonald,
local scale and provides insights into the network’s re- andW.Stuetzle. Surfacereconstructionfromunorga-
source distribution. The proposed representation and nized points. Computer Graphics, 26:2, 1992.
architecture achieve state-of-the-art results relative to [13] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E.
allothermethodsanddemonstraterobustnesstonoise Hinton. Adaptive mixtures of local experts. Neural
and occlusion data corruptions. Computation, 3(1):79–87, 1991.
[14] R.KlokovandV.Lempitsky. Escapefromcells: Deep
6. Acknowledegment kd-networksfortherecognitionof3dpointcloudmod-
els. In The IEEE International Conference on Com-
We gratefully acknowledge the support of NVIDIA puter Vision (ICCV), pages 863–872, Oct 2017.
Corporation with the donation of the Titan Xp GPU [15] J. Krapac, J. Verbeek, and F. Jurie. Modeling spatial
used for this research. layout with fisher vectors for image categorization. In
The IEEE International Conference on Computer Vi-
References sion (ICCV), pages 1487–1494. IEEE, 2011.
[16] D. Maturana and S. Scherer. Voxnet: A 3d convo-
[1] P.Alliez,D.Cohen-Steiner,Y.Tong,andM.Desbrun. lutional neural network for real-time object recogni-
Voronoi-basedvariationalreconstructionofunoriented tion. In IEEE/RSJ International Conference on In-
point sets. In Symposium on Geometry Processing, telligent Robots and Systems (IROS), pages 922–928.
volume 7, pages 39–48, 2007. IEEE, 2015.
[2] N. Amenta and M. Bern. Surface reconstruction by [17] Q.M´erigot,M.Ovsjanikov,andL.J.Guibas.Voronoi-
voronoifiltering.Discrete&ComputationalGeometry, based curvature and feature estimation from point
22(4):481–504, 1999. clouds. IEEETransactionsonVisualizationandCom-
[3] Y. Ben-Shabat, T. Avraham, M. Lindenbaum, and puter Graphics, 17(6):743–756, 2011.
A. Fischer. Graph based over-segmentation methods [18] N. J. Mitra and A. Nguyen. Estimating surface nor-
for 3d point clouds. Computer Vision and Image Un- mals in noisy point cloud data. In Proceedings of the
derstanding, 2018. Nineteenth Annual Symposium on Computational ge-
[4] Y. Ben-Shabat, M. Lindenbaum, and A. Fischer. ometry, pages 322–328. ACM, 2003.
3dmfv: Three-dimensionalpointcloudclassificationin [19] P. K. Nathan Silberman, Derek Hoiem and R. Fer-
real-time using convolutional neural networks. IEEE gus. Indoor segmentation and support inference from
Robotics and Automation Letters, 3(4):3145–3152, RGBD images. In European Conference on Computer
2018. Vision (ECCV), pages 746–760, 2012.
10119

--- Page 9 ---

[20] C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet:
Deep learning on point sets for 3d classification and
segmentation. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), July 2017.
[21] C.R.Qi,L.Yi,H.Su,andL.J.Guibas. Pointnet++:
Deep hierarchical feature learning on point sets in a
metric space. arXiv preprint arXiv:1706.02413, 2017.
[22] J.Sa´nchez,F.Perronnin,T.Mensink,andJ.Verbeek.
Imageclassificationwiththefishervector: Theoryand
practice. International Journal of Computer Vision,
105(3):222–245, 2013.
[23] B. Zeisl, M. Pollefeys, et al. Discriminatively trained
dense surface normal estimation. In European con-
ference on computer vision, pages 468–484. Springer,
2014.
10120```

---

## Section 1.2: Surface reconstruction from unorganized point clouds

Source File: Surface reconstruction from unorganized point clouds.txt

### Paper Content:

```
# Surface reconstruction from unorganized point clouds.pdf
# Converted: 2025-07-18 12:58:51
# Method: pdfplumber
# Domain: pixel2physics
# Source: /home/user/vekt/papers/pixel2physics/pdfs/layer1/Surface reconstruction from unorganized point clouds.pdf
# Output: /home/user/vekt/papers/pixel2physics/dot_txt/layer1/Surface reconstruction from unorganized point clouds.txt


--- Page 1 ---

See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/243775686
Surface reconstruction from unorganized point clouds
Article · January 1992
CITATIONS READS
197 2,244
5 authors, including:
T. Derose
Pixar Animation Studios
105 PUBLICATIONS 18,533 CITATIONS
SEE PROFILE
All content following this page was uploaded by T. Derose on 15 January 2015.
The user has requested enhancement of the downloaded file.

--- Page 2 ---

Surface Reconstruction from Unorganized Points
HuguesHoppe
(cid:0)
TonyDeRose
(cid:0)
TomDuchamp
y
JohnMcDonald
z
WernerStuetzle
z
UniversityofWashington
Seattle,WA98195
Abstract
We describe and demonstrate an algorithm that takes as input an
unorganized set of points
f x
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) x
n
g (cid:0)
IR3 on or near an un-
knownmanifoldM,andproducesasoutputasimplicialsurfacethat
approximatesM. Neitherthetopology,thepresenceofboundaries,
northegeometryofMareassumedtobeknowninadvance—all
are inferred automatically from the data. This problem naturally
arises in a variety of practical situations such as range scanning
anobjectfrommultipleviewpoints,recoveryofbiologicalshapes
fromtwo-dimensionalslices,andinteractivesurfacesketching.
CR Categories and Subject Descriptors: I.3.5 [Computer
Graphics]: ComputationalGeometryandObjectModeling.
Additional Keywords: Geometric Modeling, Surface Fitting,
Three-DimensionalShapeRecovery,RangeDataAnalysis.
1 Introduction
Broadly speaking, the class of problems we are interested in can
be stated as follows: Given partial information of an unknown
surface,construct,totheextentpossible,acompactrepresentation
ofthesurface. Reconstructionproblemsofthissortoccurindiverse
scientificandengineeringapplicationdomains,including:
(cid:1)
Surfacesfromrangedata: Thedataproduced bylaserrange
scanning systems is typically a rectangular grid of distances
from the sensor to the object being scanned. If the sensor
and object are fixed, only objects that are “point viewable”
can be fully digitized. More sophisticated systems, such as
those produced by Cyberware Laboratory, Inc., are capable
of digitizing cylindrical objects by rotating either the sensor
or the object. However, the scanning of topologically more
(cid:0)
DepartmentofComputerScienceandEngineering,FR-35
y
DepartmentofMathematics,GN-50
z
complex objects, including those as simple as a coffee cup
with a handle (a surface of genus 1), or the object depicted
in Figure 1a (asurface ofgenus 3), cannot be accomplished
byeitherofthesemethods. Toadequatelyscantheseobjects,
multipleviewpointsmustbeused. Mergingthedatagenerated
frommultipleviewpointstoreconstructapolyhedralsurface
representationisanon-trivialtask[11].
DepartmentofStatistics,GN-22
ThisworkwassupportedinpartbyBellcore,theXeroxCorporation,
IBM, Hewlett-Packard, the Digital Equipment Corporation, the Depart-
mentofEnergyundergrantDE-FG06-85-ER25006,theNationalLibraryof
MedicineundergrantNIHLM-04174,andtheNationalScienceFoundation
undergrantsCCR-8957323andDMS-9103002.
(cid:1)
Surfaces from contours: In many medical studies it is com-
montoslicebiologicalspecimensintothinlayerswithami-
crotome. The outlines of the structures of interest are then
digitized to create a stack of contours. The problem is to
reconstruct the three-dimensional structures from the stacks
oftwo-dimensional contours. Althoughthisproblemhasre-
ceivedagooddealofattention,thereremainseverelimitations
with current methods. Perhaps foremost among these is the
difficulty of automatically dealing with branching structures
[3,12].
(cid:1)
Interactive surface sketching: A number of researchers, in-
cluding Schneider [21] and Eisenman [6], have investigated
thecreationofcurvesinIR2 bytracingthepathofastylusor
mouseastheusersketchesthedesiredshape. Sachsetal. [19]
describeasystem,called3-Draw,thatpermitsthecreationof
free-formcurvesinIR3byrecordingthemotionofastylusfitted
withaPolhemussensor. Thiscanbeextendedtothedesignof
free-formsurfacesbyignoringtheorderinwhichpositionsare
recorded,allowingtheusertomovethestylusarbitrarilyback
and forthoverthesurface. Theproblemisthentoconstruct
asurfacerepresentationfaithfultotheunorderedcollectionof
points.
Reconstructionalgorithmsaddressingtheseproblemshavetypi-
callybeencraftedonacasebycasebasistoexploitpartialstructure
inthedata. Forinstance,algorithmssolvingthesurfacefromcon-
toursproblemmakeheavyuseofthefactthatdataareorganizedinto
contours(i.e.,closedpolygons),andthatthecontourslieinparal-
lelplanes. Similarly,specializedalgorithmstoreconstructsurfaces
from multiple view point range data might exploit the adjacency
relationshipofthedatapointswithineachview.
Incontrast,ourapproachistoposeaunifyinggeneralproblem
thatdoesnotassumeanystructureonthedatapoints. Thisapproach
has both theoretical and practical merit. On the theoretical side,
abstractingtoageneralproblemoftenshedslightonthetrulycritical
aspects of the problem. On the practical side, a single algorithm
that solves the general problem can be used to solve any specific
probleminstance.

--- Page 3 ---

1.1 Terminology
By a surface we mean a “compact, connected, orientable two-
dimensional manifold, possibly withboundary, embedded in IR3”
(cf. O’Neill [17]). A surface without boundary will be called a
closedsurface. Ifwewanttoemphasizethatasurfacepossessesa
non-emptyboundary,wewillcallitaborderedsurface.Apiecewise
linearsurfacewithtriangularfaceswillbereferredtoasasimplicial
surface. Weuse
k x k
todenotetheEuclideanlengthofavector
x
,
and weuse d(X
(cid:0)
Y)todenote theHausdorff distance between the
setsofpointsXandY(theHausdorffdistanceissimplythedistance
betweenthetwoclosestpointsofXandY).
Let X =
f x
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) x
n
g
be sampled data points on or near an
unknown surfaceM (seeFigure1b). Tocapturetheerrorinmost
sampling processes, weassume thateach ofthe points
x
i
(cid:2)
X is
oftheform
x
=
i
y
+
i
e
,where
i
y
i
(cid:2)
Misapointontheunknown
surface and
e
i
(cid:2)
IR3 isanerrorvector. Wecallsuch asample X
(cid:2)
-noisyif
k e
i
k (cid:3) (cid:2)
foralli. Avaluefor
(cid:2)
canbeestimatedinmost
applications(e.g.,theaccuracyofthelaserscanner). FeaturesofM
thataresmallcomparedto
(cid:2)
willobviouslynotberecoverable.
Itis also impossible to recover features of M in regions where
insufficientsamplinghasoccurred. Inparticular,ifMisabordered
surface, such asasphere withadiscremoved, itisimpossible to
distinguishholesinthesamplefromholesinthesurface. Tocapture
theintuitivenotion ofsampling density weneed tomake another
definition: LetY =
f y
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) y
n
g (cid:0)
Mbea(noiseless)sampleofa
surfaceM. ThesampleY issaidtobe
(cid:3)
-denseifanyspherewith
radius
(cid:3)
andcenterinMcontainsatleastonesamplepointinY. A
(cid:2)
-noisysample
f x
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) x
n
g (cid:0)
IR3ofasurfaceMissaidtobe
(cid:3)
-
denseifthereexistsanoiseless
(cid:3)
-densesample
f y
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) y
n
g (cid:0)
M
suchthat
x
=
i
y
+
i
e
,
i
k e
i
k (cid:3) (cid:2)
,i=1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0)
n.
1.2 ProblemStatement
ThegoalofsurfacereconstructionistodetermineasurfaceM
(cid:1)
(see
Figure 2f) that approximates an unknown surface M (Figure 1a),
usingasampleX (Figure1b)andinformationaboutthesampling
process, for example, bounds on the noise magnitude
(cid:2)
and the
samplingdensity
(cid:3)
.
Wearecurrentlyworkingtodevelop conditionsontheoriginal
surface M and the sample X that are sufficient to allow M to be
reliablyreconstructed. Asthatworkisstillpreliminary,weareun-
abletogiveguaranteesforthealgorithmpresentedhere. However,
thealgorithmhasworkedwellinpracticewheretheresultscanbe
comparedtotheoriginalsurface(seeSection4).
2 Related Work
2.1 SurfaceReconstruction
Surfacereconstruction methods canbeclassifiedaccording tothe
wayinwhichtheyrepresentthereconstructedsurface.
Implicitreconstruction methods attempttofindasmooth func-
tion f : IR3
(cid:4)
IR such that
f x
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) x
n
g
Incontrasttoimplicitreconstructiontechniques, parametricre-
construction techniques represent the reconstructed surface as a
topologicalembeddingf(
is close to the zero set
Z(f). Theydifferwithrespecttotheformoff andthemeasureof
closeness. Pratt[18]andTaubin[25]minimizethesumofsquared
Hausdorffdistancesfromthedatapointstothezerosetofapoly-
nomialinthreevariables. Muraki[15]takesf tobealinearcombi-
nationofthree-dimensionalGaussiankernelswithdifferentmeans
andspreads. Hisgoodness-of-fitfunctionmeasureshowclosethe
values of f at the data points are to zero, and how well the unit
normalstothezerosetoff matchthenormalsestimatedfromthe
data. MooreandWarren[13]fitapiecewisepolynomialrecursively
and then enforce continuity using a technique they call free form
blending.
(cid:0)
)ofa2-dimensionalparameterdomain
(cid:0)
intoIR3. Previousworkhasconcentratedondomainspaceswith
simple topology, i.e. the plane and the sphere. Hastie and Stuet-
zle[9]andVemuri[26,27]discussreconstructionofsurfacesbya
topologicalembeddingf(
(cid:0)
)ofaplanarregion
(cid:0)
intoIR3. Schudy
and Ballard [22,23]and Brinkley [4]consider the reconstruction
ofsurfacesthatareslightlydeformedspheres, andthuschoose
(cid:0) to be a sphere. Sclaroff and Pentland [24] describe a hybrid im-
plicit/parametric method for fitting a deformed sphere to a set of
pointsusingdeformationsofasuperquadric.
Compared to the techniques mentioned above, our method has
severaladvantages:
(cid:1)
Itrequiresonlyanunorganizedcollectionofpointsonornear
the surface. No additional information is needed (such as
normalinformationusedbyMuraki’smethod).
(cid:1)
Unliketheparametricmethodsmentionedabove,itcanrecon-
structsurfacesofarbitrarytopology.
(cid:1)
Unlike previously suggested implicit methods, it deals with
boundariesinanaturalway,anditdoesnotgeneratespurious
surfacecomponentsnotsupportedbythedata.
2.2 Surface Reconstruction vs Function Recon-
struction
Terms like “surface fitting” appear in reference to two distinct
classes of problems: surface reconstruction and function recon-
struction. Thegoalofsurfacereconstructionwasstatedearlier.The
goaloffunctionreconstructionmaybestatedasfollows: Givena
surfaceM,aset
f x i (cid:2)
M
g
,andaset
f
y
i (cid:2)
IR
g
,determineafunction
f :M
(cid:4)
IR,suchthatf(
x
)
i
(cid:5)
y.
i
ThedomainsurfaceM ismostcommonlyaplaneembeddedin
IR3, in which case the problem is a standard one considered in
approximationtheory. ThecasewhereMisaspherehasalsobeen
extensively treated (cf. [7]). Some recent work under the title
surfacesonsurfacesaddressesthecasewhenMisageneralcurved
surfacesuchastheskinofanairplane[16].
Functionreconstructionmethodscanbeusedforsurfacerecon-
struction in simple, special cases, where the surface to be recon-
structedis,roughlyspeaking,thegraphofafunctionoveraknown
surfaceM. Itisimportanttorecognizejusthowlimitedthesespe-
cialcasesare—forexample,noteverysurfacehomeomorphictoa
sphereisthegraphofafunctionoverthesphere. Thepointwewant
tomakeisthatfunctionreconstructionmustnotbemisconstruedto
solvethegeneralsurfacereconstructionproblem.
3 A Description of the Algorithm
3.1 Overview
Oursurfacereconstructionalgorithmconsistsoftwostages. Inthe
firststagewedefineafunctionf :D
(cid:4)
IR,whereD
(cid:0)
IR3isaregion
nearthedata,suchthatf estimatesthesignedgeometricdistanceto
theunknown surfaceM. ThezerosetZ(f)isourestimateforM.
Inthesecondstageweuseacontouringalgorithmtoapproximate
Z(f)byasimplicialsurface.
Although theunsigned distance function
j
f
j
would be easierto
estimate,zeroisnotaregularvalueof
j
f
j
.Zerois,however,aregular
valueof f, andtheimplicitfunctiontheorem thusguarantees that
ourapproximationZ(f)isamanifold.
Thekeyingredienttodefiningthesigneddistancefunctionisto
associate an oriented plane with each of the data points. These

--- Page 4 ---

tangentplanesserveaslocallinearapproximationstothesurface.
Althoughtheconstructionofthetangentplanesisrelativelysimple,
theselectionoftheirorientationssoastodefineagloballyconsistent
orientationforthesurfaceisoneofthemajorobstaclesfacingthe
algorithm. As indicated in Figure 2b, the tangent planes do not
directlydefinethesurface,sincetheirunionmayhaveacomplicated
non-manifoldstructure. Rather,weusethetangentplanestodefine
the signed distance function to the surface. An example of the
simplicialsurfaceobtainedbycontouringthezerosetofthesigned
distancefunctionisshowninFigure2e. Thenextseveralsections
developinmoredetailthesuccessivestepsofthealgorithm.
3.2 TangentPlaneEstimation
Thefirststeptowarddefiningasigneddistancefunctionistocom-
puteanorientedtangentplaneforeachdatapoint. Thetangentplane
T p
(
x
)associatedwiththedatapoint
i
x
isrepresentedasapoint
i
o
,
i
calledthecenter,togetherwithaunitnormalvector
n(cid:1)
. Thesigned
i
distance of an arbitrary point
p (cid:2)
IR3 to
T p
(
x
) is defined to be
i
dist(
i
p
)=(
p (cid:6) o
)
i
(cid:7) n(cid:1)
. Thecenterandnormalfor
i
T p
(
x
)aredeter-
i
minedbygatheringtogetherthekpointsofXnearestto
x
;thisset
i
isdenotedby
N b h d
(
x
)andiscalledthek-neighborhoodof
i
x
.(We
i
currentlyassumektobeauser-specifiedparameter,althoughinSec-
tion5weproposeamethodfordeterminingkautomatically.) The
centerandunitnormalarecomputedsothattheplane
f
dist(
i
p
)=0
g istheleastsquaresbestfittingplaneto
N b h d
(
x
). Thatis,thecen-
i
ter
o
istaken tobe the centroid of
i
N b h d
(
x
), and the normal
i
n(cid:1)
i
isdeterminedusingprincipalcomponentanalysis. Tocompute
n(cid:1)
,
i
thecovariancematrixof
N b h d
(
x
)isformed. Thisisthesymmetric
i
3
(cid:8)
3positivesemi-definitematrix
CV=
y (cid:2)
X
N b h d
(
x
(
i) y (cid:6) o
) i
(cid:9)
(
y (cid:6) o
) i
where
(cid:9)
denotestheouterproductvectoroperator1. If
(cid:4)
1 i
(cid:10) (cid:4)
2 i
(cid:4)
(cid:10) 3denotetheeigenvaluesofCVassociatedwithuniteigenvectors i
v(cid:1)
1 i
(cid:0) v(cid:1)
2 i
(cid:0) v(cid:1)
3,respectively,wechoose i
n(cid:1)
tobeeither i
v(cid:1)
3or i
(cid:6) v(cid:1)
3. The i
selectiondeterminestheorientationofthetangentplane,anditmust
bedonesothatnearbyplanesare“consistentlyoriented”.
3.3 ConsistentTangentPlaneOrientation
Supposetwodatapoints
x
i
(cid:0) x
j
(cid:2)
Xaregeometricallyclose. Ideally,
whenthedataisdenseandthesurfaceissmooth,thecorresponding
tangent planes
T p
(
x
)=(
i
o
i
(cid:0) n(cid:1)
) and
i
T p
(
x
)=(
j
o
j
(cid:0) n(cid:1)
) are nearly
j
parallel,i.e.
n(cid:1)
i
(cid:7) n(cid:1)
j
(cid:5) (cid:11)
1. Iftheplanesareconsistentlyoriented,
then
n(cid:1)
i
(cid:7) n(cid:1)
j
(cid:5)
+1; otherwise, either
n(cid:1)
or
i
n(cid:1)
should be flipped.
j
Thedifficultyinfindingaconsistentglobalorientationisthatthis
conditionshouldholdbetweenallpairsof“sufficientlyclose”data
points.
We can model the problem as graph optimization. The graph
containsonenodeN pertangentplane i
T p
(
x
),withanedge(i i
(cid:0)
j)
between N and N ifthe tangent plane centers i j
o
and i
o
are suf- j
ficiently close (we will be more precise about what we mean by
sufficientlycloseshortly). Thecostonedge(i
(cid:0)
j)encodesthede-
greetowhichN andN areconsistentlyorientedandistakentobe i j
n(cid:1)
i
(cid:7) n(cid:1)
. Theproblem isthentoselectorientationsforthetangent j
planessoastomaximizethetotalcostofthegraph. Unfortunately,
thisproblemcanbeshowntobeNP-hardviaareductiontoMAX-
CUT [8]. To efficiently solve the orientation problem we must
thereforeresorttoanapproximationalgorithm.
Beforedescribingtheapproximationalgorithmweuse,wemust
decidewhenapairofnodesaretobeconnectedinthegraph. Since
1If
a
and
b
have components ai and bj respectively, then the matrix
a (cid:1) b
thesurfaceisassumedtoconsistofasingleconnectedcomponent,
thegraphshouldbeconnected. Asimpleconnectedgraphforaset
ofpointsthattendstoconnectneighborsistheEuclideanMinimum
SpanningTree(EMST).However,theEMSToverthetangentplane
centers
hasaibjasitsij-thentry.
f o
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) o
n
g
(Figure1c)isnotsufficientlydenseinedges
toserveourpurposes. Wethereforeenrichitbyaddinganumber
of edges to it. Specifically, we add the edge (i
(cid:0)
j) if either
o
is
i
in the k-neighborhood of
o
, or
j
o
isin the k-neighborhood of
j
o
i
(wherek-neighborhood isdefined over
f o
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) o
n
g
asitwasfor
X). Theresultinggraph(Figure1d),calledtheRiemannianGraph,
isthusconstructedtobeaconnectedgraphthatencodesgeometric
proximityofthetangentplanecenters.
Arelativelysimple-mindedalgorithmtoorienttheplaneswould
betoarbitrarilychooseanorientationforsomeplane,then“propa-
gate”theorientationtoneighboringplanesintheRiemannianGraph.
Inpractice,wefoundthattheorderinwhichtheorientationisprop-
agatedisimportant. Figure3bshowswhatmayresultwhenprop-
agating orientation solely on the basis of geometric proximity; a
correctreconstructionisshowninFigure3c. Intuitively,wewould
liketochooseanorderofpropagationthatfavorspropagationfrom
T p
(
x
)to
i
T p
(
x
)iftheunorientedplanesarenearlyparallel. This
j
canbeaccomplishedbyassigningtoeachedge(i
(cid:0)
j)intheRieman-
nianGraphthecost1
(cid:6) n(cid:1)j
i
(cid:7) n(cid:1)
j
j
. Inadditiontobeingnon-negative,
thisassignmenthasthepropertythatacostissmalliftheunoriented
tangent planes are nearly parallel. Afavorable propagation order
canthereforebeachievedbytraversingtheminimalspanningtree
(MST)oftheresultinggraph. Thisorderisadvantageousbecauseit
tendstopropagateorientationalongdirectionsoflowcurvaturein
thedata,therebylargelyavoidingambiguoussituationsencountered
whentryingtopropagateorientationacrosssharpedges(asatthetip
ofthecat’searsinFigure3b). IntheMSTshowninFigure2a,the
edgesarecoloredaccordingtotheircost,withthebrightlycolored
edgescorresponding toregionsofhighvariation(where
n(cid:1)
i
(cid:7) n(cid:1)
is j
somewhatlessthan1).
Toassign orientation toan initialplane, the unit normal of the
plane whose center has the largestzcoordinate isforced topoint
toward the +z axis. Then, rooting the tree at this initial node,
we traverse the tree in depth-first order, assigning each plane an
orientation that is consistent with that of its parent. That is, if
during traversal, the current plane
T p
(
x
) has been assigned the
i
orientation
n(cid:1)
and
i
T p
(
x
)isthenextplanetobevisited,then
j
n(cid:1)
is
j
replacedwith
(cid:6) n(cid:1)
if
j
n(cid:1)
i
(cid:7) n(cid:1)
j
(cid:5)
0.
This orientation algorithm has been used in all our examples
andhasproducedcorrectorientationsinallthecaseswehaverun.
The resulting oriented tangent planes are represented as shaded
rectanglesinFigure2b.
3.4 SignedDistanceFunction
Thesigneddistancef(
p
)fromanarbitrarypoint
p (cid:2)
IR3toaknown
surfaceM isthedistancebetween
p
andtheclosestpoint
z (cid:2)
M,
multipliedby
(cid:11)
1, depending onwhich sideofthesurface
p
lies.
InrealityM isnotknown,butwecanmimicthisprocedureusing
the oriented tangent planes asfollows. First, we find the tangent
plane
T p
(
x
)whosecenter
i
o
isclosestto
i
p
. Thistangentplaneis
alocallinearapproximation toM,sowetakethesigneddistance
f(
p
)toMtobethesigneddistancebetween
p
anditsprojection
z onto
T p
(
x
);thatis,
i
f(
p
)=dist( i
p
)=(
p (cid:6) o
) i
(cid:7) n(cid:1)
i
(cid:1)
If M is known not to have boundaries, this simple rule works
well. However,therulemustbeextendedtoaccommodatesurfaces
thatmighthaveboundaries. RecallthatthesetX =
f x
1
(cid:0) (cid:1) (cid:1) (cid:1) (cid:0) x
n
g isassumedtobea
(cid:3)
-dense,
(cid:2)
-noisysampleofM. Iftherewasno
noise,wecoulddeducethatapoint
z
withd(
z (cid:0)
X)
(cid:6) (cid:3)
cannotbe

--- Page 5 ---

apointofMsincethatwouldviolateXbeing
(cid:3)
-dense. Intuitively,
the sample points do not leave holes of radius larger than
(cid:3)
. If
thesampleis
(cid:2)
-noisy,theradiusoftheholesmayincrease,butby
no more than
(cid:2)
. We therefore conclude that a point
z
cannot be
a point of M if d(
z (cid:0)
X)
(cid:6) (cid:3)
+
(cid:2)
. If the projection
z
of
p
onto
theclosesttangentplanehas d(
z (cid:0)
X)
(cid:6) (cid:3)
+
(cid:2)
, wetakef(
p
)tobe
undefined. Undefinedvaluesareusedbythecontouringalgorithm
ofSection3.5toidentifyboundaries.
Statedprocedurally,oursigneddistancefunctionisdefinedas:
i
(cid:12)
indexoftangentplanewhosecenterisclosestto
f
p
Computezastheprojectionof pontoTp(x) i
z (cid:12) o
g i
(cid:6) (cid:2)
(
p (cid:6) o
) i
(cid:7) n(cid:1)
i
(cid:3) n(cid:1)
i
if d(
z (cid:0)
X)
(cid:5) (cid:3)
+
(cid:2)
then
f(
p
)
(cid:12)
(
p (cid:6) o
)
i (cid:7) n(cid:1) i f
=
(cid:11) k p (cid:6) z k g else
f(
p
)
(cid:12)
undefined
endif
ThesimpleapproachoutlinedabovecreatesazerosetZ(f)that
ispiecewiselinearbutcontainsdiscontinuities. Thediscontinuities
result from the implicit partitioning of space into regions within
whichasingletangentplaneisusedtodefinethesigneddistance
function. (TheseregionsareinfacttheVoronoiregionsassociated
withthecenters
o
.)Fortunately,thediscontinuitiesdonotadversely i
affect our algorithm. The contouring algorithm discussed in the
next section will discretely sample the function f over a portion
ofa3-dimensionalgridnearthedataandreconstructacontinuous
piecewiselinearapproximationtoZ(f).
3.5 ContourTracing
Contourtracing,theextractionofanisosurfacefromascalarfunc-
tion,isawell-studiedproblem[1,5,28]. Wechosetoimplement
avariationofthemarchingcubesalgorithm(cf. [1])thatsamples
thefunctionattheverticesofacubicallatticeandfindsthecontour
intersectionswithintetrahedraldecompositionsofthecubicalcells.
Toaccuratelyestimateboundaries,thecubesizeshouldbesetso
thatedgesareoflengthlessthan
(cid:3)
+
(cid:2)
. Inpracticewehaveoften
founditconvenient tosetthecubesizesomewhatlargerthanthis
value,simplytoincreasethespeedofexecutionandtoreducethe
numberoftriangularfacetsgenerated.
Thealgorithmonlyvisitscubesthatintersectthezerosetbypush-
ingontoaqueueonlytheappropriateneighboringcubes(Figure2c).
Inthisway,thesigneddistancefunctionf isevaluatedonlyatpoints
closetothedata. Figure2dillustratesthesigneddistancefunction
byshowinglinesegmentsbetweenthequerypoints
p
(atthecube
vertices)and theirassociatedprojected points
z
4 Results
Wehaveexperimentedwiththereconstructionmethodondatasets
obtainedfromseveraldifferentsources. Inallcases,anystructure
(includingordering)thatmighthavebeenpresentinthepointsets
wasdiscarded.
Meshes :Pointswererandomlysampledfromanumberofexisting
simplicialsurfaces3. Forinstance,themeshofFigure3awas
randomlysampledtoyield1000unorganizedpoints,andthese
inturnwereusedtoreconstructthesurfaceinFigure3c. This
particularcaseillustratesthebehaviorofthemethodonabor-
deredsurface(thecathasnobaseandisthushomeomorphic
to a disc). The reconstructed knot (original mesh from Rob
Scharein)ofFigure3disanexampleofasurfacewithsimple
topologyyetcomplexgeometricalembedding.
RayTracedPoints : Tosimulatelaserrangeimagingfrommul-
tipleviewpoints,CSGmodelswereraytracedfrommultiple
eyepoints. Theraytracerrecordedthepointoffirstintersec-
tionalongeachray. Eighteyepoints(theverticesofalarge
cubecenteredattheobject)wereusedtogeneratethepointset
ofFigure1bfromtheCSGobjectshowninFigure1a. This
isthepointsetusedinSection3toillustratethestepsofthe
algorithm(Figures1a-2f).
RangeImages : ThebustofSpock(Figure3e)wasreconstructed
frompointstakenfromanactualcylindricalrangeimage(gen-
eratedbyCyberwareLaboratory,Inc.). Only25
. Assuggested in
Section3.4,nointersectionisreportedwithinacubeifthesigned
distance function is undefined at any vertex of the cube, thereby
givingrisetoboundariesinthesimplicialsurface.
The resulting simplicial surface can contain triangles with ar-
bitrarily poor aspect ratio (Figure 2e). We alleviate this problem
usingapost-processing procedure thatcollapsesedgesinthesur-
face using an aspect ratio criterion.2 Thefinal result isshown in
Figure 2f. Alternatively, other contouring methods exist that can
guaranteeboundsonthetriangleaspectratio[14].
2The edges are kept in a priority queue; the criterion to minimize is
theproductoftheedge length timestheminimuminscribed radiusofits
twoadjacentfaces. Testsarealsoperformedtoensurethatedgecollapses
preservethetopologicaltypeofthesurface.
(cid:4)
oftheorig-
inalpointswereused.
Contours : Points from 39 planar (horizontal) slices of the CT
scanofafemurwerecombinedtogethertoobtainthesurface
ofFigure3f.
Thealgorithm’sparametersareshowninthenexttableforeach
oftheexamples. Theexecutiontimeswereobtainedona20MIPS
workstation. Theparameter
(cid:3)
+
(cid:2)
andthemarchingcubecellsize
arebothexpressedasafractionoftheobject’ssize. Theparameter
(cid:3)
+
(cid:2)
issettoinfinityforthosesurfacesthatareknowntobeclosed.
Object n k
(cid:3)
+
(cid:2)
cellsize time
(seconds)
cat 1000 15 .06 1
(cid:7)
30 19
knot 10000 20
(cid:13)
1
(cid:7)
50 137
mechpart 4102 12
(cid:13)
1
(cid:7)
40 54
spock 21760 8 .08 1
(cid:7)
80 514
femur 18224 40 .06 1
(cid:7)
50 2135
5 Discussion
5.1 TangentPlaneApproximation
Theneighborhood
N b h d
(
x
)ofadatapoint
i x
isdefinedtoconsist
i ofitsknearestneighbors,wherekiscurrentlyassumedtobeanin-
putparameter. Inthecasewherethedatacontainslittleornonoise,
k isnotacriticalparametersincetheoutputhasbeen empirically
observed to be stable over a wide range of settings. However, it
wouldbebestifkcouldbeselectedautomatically. Furthermore,al-
lowingktoadaptlocallywouldmakelessstringenttherequirement
that the data be uniformly distributed over the surface. To select
andadaptk,thealgorithmcouldincrementallygatherpointswhile
monitoringthechangingeigenvaluesofthecovariancematrix(see
Section3.2). Forsmallvaluesofk,datanoisetendstodominate,
theeigenvaluesaresimilar,andtheeigenvectorsdonotrevealthe
surface’s true tangent plane. Atthe other extreme, as k becomes
3Discreteinversetransformsampling[10,page469]ontriangleareawas
usedtoselectfaceindicesfromthemesh,anduniformsamplingwasused
withinthefaces.

--- Page 6 ---

large, the k-neighborhoods become less localized and the surface
curvaturetendstoincreasethe“thickness”
(cid:4)
3oftheneighborhood.
i
Anotherpossiblecriterionistocompare
(cid:4)
3tosomelocalorglobal
i
estimateofdatanoise. Althoughwehavedonesomeinitialexper-
imentationinthisdirection,wehavenotyetfullyexaminedthese
options.
If the data is obtained from range images, there exists some
knowledgeofsurfaceorientationateachdatapoint. Indeed,each
datapointisknowntobevisiblefromaparticularviewingdirection,
sothat,unlessthesurfaceincidentangleislarge,thepoint’stangent
planeorientationcanbeinferredfromthatviewingdirection. Our
methodcouldexploitthisadditionalinformationinthetangentplane
orientationstep(Section3.3)byaugmentingtheRiemannianGraph
withanadditionalpseudo-nodeandnadditionaledges.
5.2 AlgorithmComplexity
A spatial partitioning Abstract Data Type greatly improves per-
formance ofmany of thesubproblems discussed previously. The
criticalsubproblemsare(withtheirstandardtimecomplexity):
(cid:1)
EMSTgraph(O(n2))
(cid:1)
k-nearestneighborstoagivenpoint(O(n+klogn))
(cid:1)
nearesttangentplaneorigintoagivenpoint(O(n))
Hierarchical spatial partitioning schemes such as octrees [20]
and k-D trees [2] can be used to solve these problems more ef-
ficiently. However, theuniform sampling densityassumed inour
dataallowssimplespatialcubicpartitioningtoworkefficiently. The
axis-alignedboundingboxofthepointsispartitionedbyacubical
grid. Pointsareenteredintosetscorrespondingtothecubetowhich
they belong, and these sets are accessed through a hash table in-
dexed by the cube indices. It is difficult to analyze the resulting
improvementsanalytically,but,empirically,thetimecomplexityof
theaboveproblemsiseffectivelyreducedbyafactorofn,except
forthek-nearestneighborsproblemwhichbecomesO(k).
Asaresultofthespatialpartitioning,theRiemannianGraphcan
beconstructedinO(nk)time. BecausetheRiemannianGraphhas
O(n)edges(atmostn+nk),theMSTcomputationusedinfindingthe
bestpathonwhichtopropagateorientationrequiresonlyO(nlogn)
time. TraversaloftheMSTisofcourseO(n).
Thetimecomplexity ofthecontouring algorithmdepends only
onthenumberofcubesvisited,sincetheevaluationofthesigned
distancefunction f atapoint
p
canbedoneinconstanttime(the
closesttangentplaneorigin
o
to
i
p
andtheclosestdatapoint
x
to
j
theprojectedpoint
z
canbothbefoundinconstanttimewithspatial
partitioning).
6 Conclusions and Future Work
Wehavedevelopedanalgorithmtoreconstructasurfaceinthree-
dimensionalspacewithorwithoutboundaryfromasetofunorga-
nizedpointsscatteredonornearthesurface. Thealgorithm,based
ontheideaofdeterminingthezerosetofanestimatedsigneddis-
tancefunction, wasdemonstrated ondatagatheredfromavariety
ofsources. Itiscapableofautomaticallyinferringthetopological
typeofthesurface,includingthepresenceofboundarycurves.
Thealgorithmcan,inprinciple,beextendedtoreconstructmani-
foldsofco-dimensiononeinspacesofarbitrarydimension;thatis,
toreconstructd
(cid:6)
on the sample and the original surface. To further improve the
geometric accuracy of the fit, and to reduce the space required
to store the reconstruction, we envision using the output of our
algorithmasthestartingpointforasubsequentsplinesurfacefitting
procedure. Wearecurrentlyinvestigatingsuchamethodbasedon
anonlinearleastsquaresapproachusingtriangularBe´ziersurfaces.
References
[1] E.L.AllgowerandP.H.Schmidt.Analgorithmforpiecewise
linearapproximationofanimplicitlydefinedmanifold.SIAM
JournalofNumericalAnalysis,22:322–346,April1985.
[2] J.L.Bentley. Multidimensionaldivideandconquer. Comm.
ACM,23(4):214–229,1980.
[3] Y. Breseler, J. A. Fessler, and A. Macovski. A Bayesian
approach toreconstruction fromincomplete projectionsofa
multiple object 3D domain. IEEE Trans. Pat. Anal. Mach.
Intell.,11(8):840–858,August1989.
[4] James F. Brinkley. Knowledge-driven ultrasonic three-
dimensionalorganmodeling. IEEETrans.Pat.Anal.Mach.
Intell.,7(4):431–441,July1985.
[5] DavidP.Dobkin,SilvioV.F.Levy,WilliamP.Thurston,and
AllanR.Wilks. Contourtracingbypiecewiselinearapproxi-
mations. ACMTOG,9(4):389–423,October1990.
[6] John A. Eisenman. Graphical editing of composite bezier
curves.Master’sthesis,DepartmentofElectricalEngineering
andComputerScience,M.I.T.,1988.
[7] T.A.Foley. Interpolationtoscattereddataonasphericaldo-
main. InM.CoxandJ.Mason, editors, AlgorithmsforAp-
proximationII,pages303–310.ChapmanandHall,London,
1990.
[8] Michael R. Garey and David S. Johnson. Computers and
Intractability. W.H.FreemanandCompany,1979.
[9] T.HastieandW.Stuetzle. Principalcurves. JASA,84:502–
516,1989.
[10] AverillM.LawandW.DavidKelton. SimulationModeling
andAnalysis. McGraw-Hill,Inc.,secondedition,1991.
[11] MarshalL.Merriam. Experiencewiththecyberware3Ddig-
itizer. InNCGAProceedings,pages125–133,March1992.
[12] DavidMeyers,ShellySkinner,andKennethSloan. Surfaces
fromcontours: Thecorrespondenceandbranchingproblems.
In Proceedings of Graphics Interface ’91, pages 246–254,
June1991.
[13] DougMooreandJoeWarren. Approximationofdensescat-
tereddatausingalgebraicsurfaces. TR90-135,RiceUniver-
sity,October1990.
[14] Doug Moore and Joe Warren. Adaptive mesh generation ii:
Packingsolids. TR90-139,RiceUniversity,March1991.
[15] ShigeruMuraki. Volumetricshapedescriptionofrangedata
using“blobbymodel”. ComputerGraphics(SIGGRAPH’91
Proceedings),25(4):227–235,July1991.
[16] GregoryM.Nielson,ThomasA.Foley,BerndHamann, and
DavidLane. Visualizingandmodelingscatteredmultivariate
data. IEEECG&A,11(3):47–55,May1991.
1dimensionalmanifoldsinddimensionalspace.
Thus, essentially the same algorithm can be used to reconstruct [17] BarrettO’Neill.ElementaryDifferentialGeometry.Academic
curvesintheplaneorvolumesinfour-dimensionalspace. Press,Orlando,Florida,1966.
The output of our reconstruction method produced the correct [18] Vaughan Pratt. Direct least-squares fitting of algebraic sur-
topology in all the examples. We are trying to develop formal faces. Computer Graphics (SIGGRAPH ’87 Proceedings),
guaranteesonthecorrectnessofthereconstruction,givenconstraints 21(4):145–152,July1987.

--- Page 7 ---

(a)OriginalCSGobject (b)Sampledpoints(
x
)(n=4102)
i
(c)EMSToftangentplanecenters
o
(d)RiemannianGraphover
i
o
i
Figure1: Reconstructionofray-tracedCSGobject(simulatedmulti-viewrangedata).
[19] EmanuelSachs,AndrewRoberts,andDavidStoops.3-Draw: [24] StanSclaroffandAlexPentland. Generalizedimplicitfunc-
A tool for designing 3D shapes. IEEE Computer Graphics tionsforcomputergraphics.ComputerGraphics(SIGGRAPH
andApplications,11(6):18–26,November1991. ’91Proceedings),25(4):247–250,July1991.
[20] Hanan Samet. Applications of Spatial Data Structures. [25] G.Taubin. Estimationofplanarcurves,surfacesandnonpla-
Addison-Wesley,1990. narspacecurvesdefinedbyimplicitequations,withapplica-
tionstoedgeandrangeimagesegmentation.TechnicalReport
[21] PhilipJ.Schneider.Phoenix: Aninteractivecurvedesignsys- LEMS-66,DivisionofEngineering,BrownUniversity,1990.
tem based on the automatic fittingof hand-sketched curves.
[26] B. C. Vemuri. Representation and Recognition of Objects
Master’sthesis,DepartmentofComputerScience,U.ofWash-
FromDenseRangeMaps. PhDthesis,DepartmentofElectri-
ington,1988.
calandComputerEngineering,UniversityofTexasatAustin,
[22] R.B.SchudyandD.H.Ballard. Modeldetectionofcardiac 1987.
chambers inultrasound images. TechnicalReport12, Com-
[27] B. C. Vemuri, A. Mitiche, and J. K. Aggarwal. Curvature-
puterScienceDepartment,UniversityofRochester,1978.
based representation ofobjectsfromrange data. Image and
[23] R.B.SchudyandD.H.Ballard.Towardsananatomicalmodel VisionComputing,4(2):107–114,1986.
of heart motion as seen in 4-d cardiac ultrasound data. In [28] G. Wyvill, C. McPheeters, and B. Wyvill. Data structures
Proceedingsofthe6thConferenceonComputerApplications forsoftobjects. TheVisualComputer,2(4):227–234,August
in Radiology and Computer-Aided Analysis of Radiological 1986.
Images,1979.

--- Page 8 ---

(a)Traversalorderoforientationpropagation (b)Orientedtangentplanes(
T p
(
x
))
i
(c)Cubesvisitedduringcontouring (d)Estimatedsigneddistance(shownas
p (cid:6) z
)
(e)Outputofmodifiedmarchingcubes (f)Finalsurfaceafteredgecollapses
Figure2: Reconstructionofray-tracedCSGobject(continued).

--- Page 9 ---

(a)Originalmesh (b)Resultofnaiveorientationpropagation
(c)Reconstructedborderedsurface (d)Reconstructedsurfacewithcomplexgeometry
(e)Reconstructionfromcylindricalrangedata (f)Reconstructionfromcontourdata
Figure3: Reconstructionexamples.
View publication stats```

---

## Section 1.3: DeepFit_ 3D Surface Fitting via Neural Network Weighted Least Squares

Source File: DeepFit_ 3D Surface Fitting via Neural Network Weighted Least Squares.txt

### Paper Content:

```
# DeepFit_ 3D Surface Fitting via Neural Network Weighted Least Squares.pdf
# Converted: 2025-07-18 12:58:57
# Method: pdfplumber
# Domain: pixel2physics
# Source: /home/user/vekt/papers/pixel2physics/pdfs/layer1/DeepFit_ 3D Surface Fitting via Neural Network Weighted Least Squares.pdf
# Output: /home/user/vekt/papers/pixel2physics/dot_txt/layer1/DeepFit_ 3D Surface Fitting via Neural Network Weighted Least Squares.txt


--- Page 1 ---

DeepFit: 3D Surface Fitting via Neural Network
Weighted Least Squares
Yizhak Ben-Shabat and Stephen Gould
The Australian National University, Australian Centre for Robotic Vision
{yizhak.benshabat,stephen.gould}@anu.edu.au
Abstract. We propose a surface fitting method for unstructured 3D
point clouds. This method, called DeepFit, incorporates a neural net-
work to learn point-wise weights for weighted least squares polynomial
surface fitting. The learned weights act as a soft selection for the neigh-
borhood of surface points thus avoiding the scale selection required of
previousmethods.Totrainthenetworkweproposeanovelsurfacecon-
sistencylossthatimprovespointweightestimation.Themethodenables
extractingnormalvectorsandothergeometricalproperties,suchasprin-
cipal curvatures, the latter were not presented as ground truth during
training.Weachievestate-of-the-artresultsonabenchmarknormaland
curvature estimation dataset, demonstrate robustness to noise, outliers
and density variations, and show its application on noise removal.
Keywords: Normal estimation, surface fitting, least squares, unstruc-
tured 3D point clouds, 3D point cloud deep learning
1 Introduction
Commodity 3D sensors are rapidly becoming an integral component of au-
tonomous systems. These sensors, e.g., RGB-D cameras or LiDAR, provide a
3D point cloud representing the geometry of the scanned objects and surround-
ings. This raw representation, however, is challenging to process since it lacks
connectivityinformationorstructure,andisoftenincomplete,noisyandcontains
point density variations. In particular, processing it by means of convolutional
neural networks (CNNs)—highly effective for images—is problematic because
CNNs require structured, grid-like data as input.
When available, additional local geometric information, such as the surface
normal and principal curvatures at each point, induces a partial local structure
and improves performance of different tasks for interpreting the scene, such as
over-segmentation [1], classification [18] and surface reconstruction [9].
Estimatingthenormalsandcurvaturesfromarawpointcloudwithnoaddi-
tional information is a challenging task due to difficulties associated with sam-
plingdensity,noise,outliers,anddetaillevel.Thecommonapproachistospecify
aneighborhoodaroundapointandthenfitalocalbasicgeometricsurface(e.g.,a
plane)tothepointsinthisneighborhood.Thenormalatthepointunderconsid-
erationisestimatedfromthefittedgeometricsurface.Thechosensize(orscale)
0202
raM
32
]VC.sc[
1v62801.3002:viXra

--- Page 2 ---

2 Y. Ben-Shabat, S. Gould
Point cloud
Query point
𝑞𝑞𝑖𝑖 sruobhgien
tseraen
k
Point-wise weight estimation Point-wise
(512, 256, 128, 1) weights
𝑆𝑆𝑖𝑖 Local features mlp
𝑥𝑥𝑖 𝑦𝑦𝑖 𝑧𝑧𝑖 𝑤𝑤𝑖 Fit n-𝑊𝑊Jet
𝑥𝑥𝑖 𝑦𝑦𝑖 𝑧𝑧𝑖 𝑤𝑤𝑖
PointNet Global
feature Normal vector
Local features
𝑥𝑥𝑖𝑖 𝑦𝑦𝑖𝑖 𝑧𝑧𝑖𝑖
Concatenate 𝑤𝑤𝑖𝑖 𝛽𝛽=(𝑀𝑀𝑇𝑇 𝑇𝑇 𝑊𝑊𝑀𝑀) −𝑖
Max pool Global 𝑀𝑀 𝑊𝑊𝑊𝑊
feature
𝑀𝑀,𝑊𝑊 Principal
curvatures
Compute Vandermondematrix (M), and height function vector (B)
Fig.1: DeepFit pipeline for normal and principal curvature estimation. For each
point in a given point cloud, we compute a global and local representation and
estimate a point-wise wight. Then, we fit an n-jet by solving a weighted least
squares problem.
of the neighborhood introduces an unavoidable trade-off between robustness to
noiseandaccuracyoffinedetails.Alargeneighborhoodover-smoothssharpcor-
nersandsmalldetailsbutisotherwiserobusttonoise.Asmallneighborhood,on
theotherhand,mayreproducethenormalsmoreaccuratelyaroundsmalldetails
butismoresensitivetonoise.Evidently,arobust,scale-independent,data-driven
surface fitting approach should improve normal estimation performance.
We propose a surface fitting method for unstructured 3D point clouds. It
features a neural network for point-wise weight prediction for weighted least
squaresfittingofpolynomialsurfaces.Thisapproachremovesthemulti-scalere-
quiremententirelyandsignificantlyincreasesrobustnesstodifferentnoiselevels,
outliers, and varying levels of detail. Moreover, the approach enables extracting
normalvectorsandadditionalgeometricpropertieswithouttheneedforretrain-
ingoradditionalgroundtruthinformation.Themaincontributionsofthispaper
are:
– A method for per-point weight estimation for weighted least squares fitting
using deep neural networks.
– A scale-free method for robust surface fitting and normal estimation.
– A method for principal curvature and geometric properties estimation with-
out using ground truth labels.
2 Background and Related Work
2.1 Deep learning for unstructured 3D point clouds
The point cloud representation of a 3D scene is challenging for deep learning
methodsbecauseitisbothunstructuredandunordered.Inaddition,thenumber
ofpointsinthepointcloudvariesfordifferentscenes.Severalmethodshavebeen

--- Page 3 ---

DeepFit 3
proposed to overcome these challenges. Voxel-based methods embed the point
cloudintoavoxelgridbutsufferfromseveralaccuracy-complexitytradeoffs[14].
The PointNet approach [17,18] applies a symmetric, order-insensitive, function
on a high-dimensional representation of individual points. The Kd-Network [12]
imposes a kd-tree structure on the points and uses it to learn shared weights for
nodesinthetree.Therecentlyproposed3Dmodifiedfishervectors(3DmFV)[2]
representsthepointsbytheirdeviationfromaGaussianMixtureModel(GMM)
whose Gaussians are uniformly positioned on a coarse grid.
InthispaperweuseaPoinNetarchitectureforestimatingpoint-wiseweights
for weighted least squares surface fitting. We chose PointNet since it operates
directly on the point cloud, does not require preprocessing, representation con-
version or structure, and contains a relatively low number of parameters,
2.2 Normal Estimation
A classic method for estimating normals uses principal component analysis
(PCA) [10]. Here a neighborhood of points within some fixed scale is chosen
and PCA regression used to estimate a tangent plane. Variants that fit local
spherical surfaces [8] or Jets [6] (truncated Taylor expansion) have also been
proposed. Further detail on Jet fitting is given in Section 2.3. To be robust to
noise,thesemethodsusuallychoosealarge-scaleneighborhood,leadingthemto
smooth sharp features and fail to estimate normals near 3D edges. Computing
theoptimalneighborhoodsizecandecreasetheestimationerror[15]butrequires
the(usuallyunknown)noisestandarddeviationvalueandacostlyiterativepro-
cess to estimate the local curvature and additional density parameters.
A few deep learning approaches have been proposed to estimate normal vec-
tors from unstructured point clouds. Boulch and Marlet proposed to transform
local point cloud patches into a 2D Hough space accumulator by randomly se-
lecting point triplets and voting for that plane’s normal. Then, the normal is
estimated from the accumulator by designing explicit criteria [4] for bin selec-
tion or, more recently, by training a 2D CNN [5] to estimate it continuously
as a regression problem. This method does not fully utilize available 3D in-
formation since it loses information during the transformation stage. Another
method,namedPCPNnet[9],usesaPointNet[17]architectureoverlocalneigh-
borhoodsatmultiplescales.Itachievesgoodnormalestimationperformanceand
has been extended to estimating principal curvatures. However, it processes the
multi-scale point clouds jointly and requires selecting a predefined set of scales.
A more recent work, Nesti-Net [3] tries to predict the appropriate scale using
a mixture of experts network and a local representation for different scales. It
achieves high accuracy but suffers from high computation time due to the mul-
tiple scale computations. Nesti-Net shares PCPNet’s drawback of requiring a
predefined set of scales. A contemporary work [13] uses an iterative plane fit-
ting approach which tries to predict all normals of a local neighborhood and
iteratively adjusts the point weights to best fit the plane.
Inthispaperweproposeanovelapproachfornormalestimationbylearning
to fit an n-order Jet while predicting informative points’ weights. Our approach

--- Page 4 ---

4 Y. Ben-Shabat, S. Gould
removes the need of predefined scales and optimal scale selection since the in-
formative points are extracted at any given scale. Our method generalizes the
contemporary method proposed by Lenssen et. al. [13], avoids the iterative pro-
cess, and enables the computation of additional geometric properties.
2.3 Jet fitting using least squares and weighted least squares
We now provide background and mathematical notation for truncated Taylor
expansion surface fitting using least-squares (LS) and weighted least-squares
(WLS).WerefertheinterestedreadertoCazalsandPouget[6]forfurtherdetail.
Any regular embedded smooth surface can be locally written as the graph
of a bi-variate “height function” with respect to any z-direction that does not
belongtothetangentspace[19].WeadoptthenamingconventionofCazalsand
Pouget [6] andrefer to thetruncated Taylor expansionas a degree n jet or n-jet
for short. An n-jet of the height function over a surface is given by:
n k
(cid:88)(cid:88)
f(x,y)=J (x,y)= β xk−jyj (1)
β,n k−j,j
k=0j=0
Hereβ isthejetcoefficientsvectorthatconsistsofN =(n+1)(n+2)/2terms.
n
In this work we wish to fit a surface to a set of N 3D points. For clarity,
p
we move to the matrix notation and specify the Vandermonde matrix M =
(1,x
i
,y
i
,...,x
i
y
i
n−1,y
i
n)
i=1,...,Np
∈ RNp×Nn and the height function vector B =
(z ,z ,...z )T ∈ RN representing the sampled points. We require that every
1 2 Np p
point satisfy Eq. 1, yielding the system of linear equations:
Mβ =B (2)
When N > N the system is over-determined and an exact solution may not
n p
exist. Therefore we use an LS approximation that minimizes the sum of square
errors between the value of the jet and the height function over all points:
β =arg min (cid:107)Mz−B(cid:107)2 (3)
z∈RNn
It is well known that the solution can be expressed in closed-form as:
β =(MTM)−1MTB (4)
Typically the sampled points include noise and outliers that heavily reduce the
fitting accuracy. To overcome this, the formulation given in Eq. 4 can be ex-
tended to a weighted least square problem. In this setting, some points have
more influence on the fitted model than others. Let W ∈RNp×Np be a diagonal
weightmatrixW =diag(w ,w ,...,w ).Eachelementinthematrix’sdiagonal
1 2 Np

--- Page 5 ---

DeepFit 5
w corresponds to the weight of that point.
i
The optimization problem becomes:
(cid:13) (cid:13)2
β =arg min (cid:13)W1/2(Mz−B)(cid:13)
(cid:13) (cid:13)
z∈RNn
 2
(cid:88)
Np
(cid:88)
Nn
=arg min w i M ij z j −B i
z∈RNn
i=1 j=1
and its solution:
β =(MTWM)−1MTWB (5)
Inthiswork,wechoosetofocusonn-jetfittingbecauseanyorderndifferen-
tialquantitycanbecomputedfromthen-jet.Thisisoneofthemainadvantages
ofourmethod.Thatis,ourmethodistrainedforestimatingnormalvectorsbut
is then able to estimate other differential quantities, e.g., principal curvatures,
depending on the jet order.
3 DeepFit
3.1 Learning point-wise weights
The full pipeline for our method is illustrated in Fig. 1. Given a 3D point cloud
S and a query point q ∈ S we first extract a local subset of points S using
i i
k-nearest neighbors. We then use a neural network to estimate the weight of
each point in the neighborhood, which will subsequently be used for weighted
leastsquaressurfacefitting.Specifically,wefeedS intoaPointNet[17]network,
i
whichoutputsaglobalpointcloudrepresentationG(S ).Additionally,weextract
i
local representations from an intermediate layer for each of the points p ∈ S
j i
separately to give g(p ). These representations are then concatenated and fed
j
into a multi-layer perceptron h(·) followed by a sigmoid activation function. We
choose a sigmoid in order to limit the output values to be between 0 and 1.
The output of this network is a weight per point that is used to construct the
diagonal point-weight matrix, W =diag(w ) with
j
w =sigmoid(h(G(S ),g(p )))+(cid:15) (6)
j i ij
Fornumericalstability,weaddaconstantsmall(cid:15)inordertoavoidthedegenrate
case of a zero or poorly conditioned matrix. This weight matrix is then used to
solve the WLS problem of Eq. 5 and approximate the n-jet coefficients β. All
parts of the network are differentiable and therefore it is trained end-to-end.
3.2 Geometric quantities estimation
Giventhen-jetcoefficientsβseveralgeometricquantitiescanbeeasilyextracted:

--- Page 6 ---

6 Y. Ben-Shabat, S. Gould
Normal estimation. The estimated normal vector is given by:
(−β ,−β ,1)
N = 1 2 (7)
i (cid:107)(−β ,−β ,1)(cid:107)
1 2 2
Shape operator and principal curvatures. For the second order informa-
tion we compute the Weingarten map of the surface by multiplying the inverse
of the first fundamental form and the second fundamental form. Its eigenval-
ues are the principal curvatures (k ,k ), and its eigenvectors are the principal
1 2
directions. The computation is done in the tangent space associated with the
parametrization.
1 (cid:20) 1+β2 β β (cid:21)−1(cid:20) 2β β (cid:21)
M =− 1 1 2 3 4 (8)
Weingarten (cid:112) β 1 2+β 2 2+1 β 1 β 2 1+β 2 2 β 4 2β 5
Generally, the principal curvatures can be used as ground truth in training,
however, due to the eigenvalue decomposition, with the high probability of out-
putting two zero principal curvatures (planes) it suffers from numerical issues
when computing the gradients for backpropagation [7]. Therefore, we compute
thecurvaturesonlyattesttime.NotethatMongebasisandhigherorderMonge
coefficients can also be computed, similar to [6].
3.3 Consistency loss
In order to learn point-wise weights, we introduce a local consistency loss L .
con
This loss is composed of two terms, the weighted normal difference term and a
regularization term. The weighted normal difference term computes a weighted
average of the sine of the angle between the ground truth normal and the esti-
mated normal at every local neighborhood point. These normals are computed
analyticallybyconvertingthen-jettotheimplicitsurfaceformofF(x,y,z)=0.
Therefore,foreveryquerypointq anditslocalneighborhoodS wecancompute
i i
the normal at each neighboring point p ∈S using:
j i
(cid:12)
N j = (cid:107) ∇ ∇ F F(cid:107) (cid:12) (cid:12) (cid:12) (cid:12) = (−β i ∂ ∂ M x (cid:107) T ∇ , F β i (cid:107) ∂ ∂ M y T ,1)(cid:12) (cid:12) (cid:12) (cid:12) (9)
pj (cid:12)
pj
Notethatthisformulationassumesallpointstolieonthesurface,forpointsthat
arenotonthesurface,thenormalerrorwillbelarge,thereforethatpointsweight
will be encouraged to be small. This term can easily converge to an undesired
local minimum by setting all weights to zero. In order to avoid that, we add a
regularization term which computes the negative average log of all weights. In
summary, the consistency loss for a query point q is then given by:
i
 
1 (cid:88)
Nqi
(cid:88)
Nqi
L
con
=
N
− log(w
j
)+ w
j
|N
GT
×N
j
| (10)
qi
j=1 j=1

--- Page 7 ---

DeepFit 7
In contrast to Lenssen et. al. [13], this formulation allows us to avoid solving
multiple linear systems iteratively for each point in the local neighborhood.
Intotal,totrainthenetwork,wesumseverallossterms:Thesinlossbetween
theestimatedunorientednormalandthegroundtruthnormalatthequerypoint,
the consistency loss, and PointNet’s transformation matrix regularization terms
(cid:12) (cid:12)
L
reg
=(cid:12)I−AAT(cid:12).
L =|N ×N |+α L +α L (11)
tot GT i 1 con 2 reg
Here, α , and α are weighting factors, chosen empirically.
1 2
3.4 Implementation notes
In our experiments we report results using DeepFit with the following configu-
ration, unless otherwise stated. A four layer MLP with sizes 512, 256, 128, and
1; a neighborhood size of 256 points, and a 3-order jet. In order to avoid numer-
ical issues, simplify the notation, and reduce the linear algebra operations, we
perform the following pre-processing stages on every local point cloud:
1. Normalization: we translate the point cloud to position the query point in
the origin and scale the point cloud to fit a unit sphere.
2. Basis extraction: we perform principal component analysis (PCA) on the
pointcloud.Wethenusetheresultingthreeorthonormaleigenvectorsasthe
fitting basis so that the vector associated with the smallest eigenvalue is the
last vector of the basis.
3. Coordinate frame transformation: We perform a change of coordinates to
move the points into the coordinate system of the fitting basis.
4. Preconditioning: we precondition the Vandermonde matrix by performing
column scaling. Each monomial xkyl is divided by hk+l. That is, M(cid:48) =
i i
MD−1 with D the diagonal matrix D = diag(1,h,h2,...,hn). We use the
mean of the norm (cid:107)(x ,y )(cid:107) as h. The new system is then M(cid:48)(Dβ)=B and
i i
β =D−1(M(cid:48)TWM(cid:48))−1M(cid:48)TWB.
Notethatafterthenormalisestimatedweapplytheinversetransformtooutput
the result in the original coordinate frame.
4 Results
4.1 Dataset and training details
FortrainingandtestingweusedthePCPNetshapedataset[9].Thetrainingset
consists of eight shapes: four CAD objects (fandisk, boxunion, flower, cup) and
four high quality scans of figurines (bunny, armadillo, dragon and turtle). All
shapes are given as triangle meshes and densely sampled with 100k points. The
data is augmented by introducing i.i.d. Gaussian noise for each point’s spacial
location with a standard deviation of 0.012, 0.006, 0.00125 w.r.t the bounding

--- Page 8 ---

8 Y. Ben-Shabat, S. Gould
box size. This yields a set with 3.2M training examples. The test set consists of
22shapes,includingfigurines,CADobjects,andanalyticshapes.Forevaluation
we use the same 5000 point subset per shape as in Guerrero et al. [9].
All variations of our method were trained using 32,768 (1024 samples by
32 shapes) random subsets of the 3.2M training samples at each epoch. We
used a batch size of 256, the Adam optimizer and a learning rate of 10−3. The
implementation was done in PyTorch and trained on a single Nvidia RTX 2080
GPU.
4.2 Normal estimation performance
We use the RMSE metric for comparing the proposed DeepFit to other deep
learning based methods [9,3,13] and classical geometric methods [10,6]. Addi-
tionally, we analyze robustness for two types of data corruption:
– Pointdensity—applyingtwosamplingregimesforpointsubsetselection:gra-
dient, simulating effects of distance from the sensor, and stripes, simulating
local occlusions.
– Point perturbations–adding Gaussian noise to the points coordinates with
threelevelsofmagnitudespecifiedbyσ,givenasapercentageofthebound-
ing box.
For the geometric methods, we show results for three different scales: small,
medium and large, which correspond to 18, 112, 450 nearest neighbors. For the
deep learning based methods we show the results for the single-scale (ss) and
multi-scale (ms) versions.
Table1showstheunorientednormalRMSEresultsforthemethodsdetailed
above. It can be seen that our method slightly outperforms all other methods
for low, medium and no noise augmentation and for gradient density augmenta-
tion. For high noise, and striped occlusion augmentation we are a close second
tothecontemporaryworkofLenssenetal.[13]whichonlyestimatesthenormal
vectors while DeepFit also estimates other geometric properties, e.g., principal
curvatures. The results also show that all method’s performance deteriorate as
the noise level rises. In this context, both PCA and Jet perform well for specific
noise-scalepairs.Inaddition,forPCPNet,usingamultiplescalesonlymildlyim-
proves performance. Nesti-Net’s mixture of experts mitigate the scale-accuracy
tradeoffwellatthecostofcomputationalcomplexity.DeepFit’ssoftpointselec-
tion process overcomes this tradeoff. In the supplemental materials we perform
additional evaluation using the percentage of good points (PGPα) metric.
Figure 2a depicts a visualization of DeepFit’s results on three point clouds.
HerethenormalvectorsaremappedtotheRGBcube.Itshowsthatforcomplex
shapes(pillar,liberty)withhighnoiselevels,thegeneraldirectionofthenormal
vectorispredictedcorrectly,but,thefinedetailsandexactnormalvectorarenot
obtained. For a basic shape (Boxysmooth) the added noise does not affect the
results substantially. Most notably, DeepFit shows robustness to point density
corruptions. Figure 2b depicts a visualization of the angular error in each point

--- Page 9 ---

DeepFit 9
Len-
Our
PCA Jet PCPNet ssen Nesti-
Aug. Deep-
[10] [6] [9] et. al Net
Fit
[13]
scale ss small med largesmall med large ss ms ss ms (MoE)
None 6.51 8.31 12.2916.77 7.60 12.3517.35 9.68 9.62 6.72 6.99
Noise σ
0.00125 9.21 12.0012.8716.8712.3612.8417.4211.46 11.37 9.95 10.11
0.006 16.72 40.3618.3818.9441.3918.3318.8518.26 18.87 17.18 17.63
0.012 23.12 52.63 27.5 23.5 53.2127.6823.41 22.8 23.28 21.96 22.28
Density
Gradient 7.31 9.14 12.8117.26 8.49 13.13 17.8 13.42 11.7 7.73 9.00
Stripes 7.92 9.42 13.6619.87 8.61 13.3919.2911.74 11.16 7.51 8.47
average 11.8 21.9716.2518.8721.9516.2919.0214.56 14.34 11.84 12.41
Table 1: Comparison of the RMSE angle error for unoriented normal vector
estimationofourDeepFitmethodtoclassicalgeometricmethods(PCA[10]and
Jet[6]-forthreescalessmall,med,andlargecorrespondingtok =18,122,450),
and deep learning methods (PCPNet [9], Lenssen et. al [13], and Nesti-Net [3])
for the different methods using a heat map. For the Jet method [6] we display
the results for medium scale. For all methods, it can be seen that more errors
occur in regions with small details, high curvature e.g. edges and corners, and
complexgeometry.DeepFitsufferstheleastfromthiseffectduetoitspoint-wise
weight estimation, which allows it to adapt to the different local geometryand
disregard irrelevant points in the fitting process.
Figure 3 qualitatively visualizes the performance of DeepFit’s point-wise
weight prediction network. The colors of the points correspond to weight mag-
nitude, mapped to a heatmap ranging from 0 to 1 i.e. red points highly affect
the fit while blue points have low influence. It shows that the network learns to
adaptwelltocornerregions(columnn=1),assigninghighweightstopointson
one plane and excluding points on the perpendicular one. Additionally, it shows
howthenetworkadaptedtheweighttoachieveagoodfitforcomplexgeometries
(column n=2,3,4).
Fig. 4 shows the unoriented normal RMSE results for different parameter
choices of our method. We explore different Jet orders n = 1,2,3,4, and a
different number of neighboring points k = 64,128,256, It shows that using a
large neighborhood size highly improves the performance in high noise cases
while only minimally affecting the performance in low noise. It also shows that
all jet orders are comparable with a small advantage for order 1-jet (plane) and
order3-jetwhichisanindicationforabiasinthedatasettowardslowcurvature
geometry. Additional ablation results, including more augmentations and the
PGPα metric are provided in the supplemental material.
Timingandefficiencyperformanceareprovidedinthesupplementalmaterial.
DeepFitisfasterandhasfewerparametersthanPCPNetandNesti-Netandhas
the potential of only being slightly slower than CGAL implementation of Jet

--- Page 10 ---

10 Y. Ben-Shabat, S. Gould
(b)
(a)
Fig.2:(a)DeepFit’snormalestimationresultsfordifferentnoiselevels(columns
1-4), and density distortions (columns 5-6). The colors of the points are normal
vectors mapped to RGB. (b) Normal estimation error visualization results of
DeepFit compared to other methods for three types of point clouds without
noise. The colors of the points correspond to angular difference, mapped to a
heatmap ranging from 0-60 degrees.
Fig.3: DeepFit point-wise weight prediction. Three views of different n-jet sur-
face fits. The colors of the points correspond to weight magnitude , mapped to
a heatmap ranging from 0 to 1; see color bar on the right i.e. red points highly
affect the fit while blue points have low influence.
.

--- Page 11 ---

DeepFit 11
n=1 n=2 n=3 n=4
8.0
7.5
7.0
6.5
6.0
64 128 256
Number of points
ESMR
elgna
No Noise
32
30
28
26
24
64 128 256
Number of points
(a)
ESMR
elgna
High Noise
(b)
Fig.4: Normal estimation RMSE results for DeepFit ablations for (a) no noise
and(b)highnoiseaugmentations.Comparingtheeffectofnumberofneighboring
points and jet order.
fitting because the forward pass for weight estimation is linear with respect to
the number of points and the network weights.
4.3 Principal curvature estimation performance
Figure 5 qualitatively depicts DeepFit’s results on five point clouds. For vi-
sualization, the principal curvatures are mapped to RGB values according to
the commonly used mapping given in its bottom right corner i.e. both positive
(dome) are red, both negative (bowl) are blue, one positive and one negative
(saddle) are green, both zero (plane) are white, and one zero and one posi-
tive/negative (cylinder) are yellow/cyan. For consistency in color saturation we
mapeachmodeldifferentlyaccordingtothemeanandstandarddeviationofthe
principal curvatures. Note that the curvature sign is determined by the ground
truth normal orientation.
For quantitative evaluation we use the normalized RMSE metric curvature
estimation evaluation proposed in Guerrero et. al. [9] and given in Eq. 12, for
comparing the proposed method to other deep learning based [9] and geometric
methods [6]. Table 2 summarizes the results and shows an average error reduc-
tion of 35% and 13.7% for maximum and minimum curvatures respectively. We
analyze robustness for the same types of data corruptions as in normal estima-
tion i.e. point perturbation and density. DeepFit significantly outperforms all
other methods for maximum principal curvature k . For the minimum principal
1
curvature k DeepFit outperforms all methods for low and no noise augmenta-
2
tioninadditiontogradientandstripeddensityaugmentation,howeverPCPNet
has a small advantage for medium and high noise levels. The results for the

--- Page 12 ---

12 Y. Ben-Shabat, S. Gould
Fig.5: Curvature estimation results visualization. The colors of the points cor-
responds to the mapping of k ,k to the color map given in the bottom right.
1 2
Values in the range [−(µ(|k |)+σ(|k |)),µ(|k |)+σ(|k |)]| .
i i i i i=1,2
minimum curvature are very sensitive since most values are close to zero.
(cid:12) (cid:12)
D kj = (cid:12) (cid:12) (cid:12)ma k x j { − |k k GT |,1} (cid:12) (cid:12) (cid:12) , for j =1,2. (12)
GT
ThenormalizedRMSEmetricisvisualizedinFig.6forDeepFitandPCPNet
as the magnitude of the error vector mapped to a heatmap. It can be seen that
more errors occur near edges, corners and small regions with a lot of detail and
high curvature. These figures show that for both simple and complex geometric
shapes DeepFit is able to predict the principal curvatures reliably.
4.4 Surface reconstruction and noise removal
Wefurtherinvestigatetheeffectivenessofoursurfacefittinginthecontextoftwo
subsequent applications—Poisson surface reconstruction [11] and noise removal.
Surface reconstruction. Fig. 7a shows the results for the classical Jet fitting
and our DeepFit approach. Since the reconstruction requires oriented normals,
we orient the normals, in both methods, according to the ground truth normal.
It shows that using DeepFit, the poisson reconstruction is moderately more
satisfactory by being smoother overall, and crispier near corners. It also retains
small details (liberty crown, cup rim).
Noise removal. The point-wise weight prediction network enables a better
fit by reducing the influence of neighboring points. This weight can also be
interpretedasthenetwork’sconfidenceofthatpointtolieontheobject’ssurface.
Therefore, we can use the weight to remove points with low confidence. We first

--- Page 13 ---

DeepFit 13
Our PCP- Our PCP-
Jet Jet
Aug. Deep- Net Aug. Deep- Net
[6] [6]
Fit [9] Fit [9]
output k +n k +n k k k output k +n k +n k k k
1 1 1 1 1 2 2 2 2 2
scale ss ms small med. large scale ss ms small med. large
None 1.00 1.36 2.19 6.55 2.97 None 0.46 0.54 1.61 2.91 1.59
Noise σ Noise σ
0.00125 1.00 1.48 57.35 6.68 2.90 0.00125 0.47 0.53 25.83 2.98 1.53
0.006 0.98 1.46 60.91 9.86 3.30 0.006 0.57 0.51 22.27 4.88 1.73
0.012 1.21 1.59 49.4010.78 3.58 0.012 0.68 0.53 18.17 5.22 1.84
Density Density
Gradient 0.59 1.32 2.07 1.40 1.53 Gradient 0.31 0.61 2.04 0.79 0.83
Stripes 0.6 1.09 2.04 1.54 1.89 Stripes 0.31 0.55 1.92 0.89 1.09
average 0.89 1.38 28.99 6.13 2.69 average 0.466 0.54 11.97 2.94 1.43
reduc. 35.5% reduc. 13.7%
Table 2: Comparison of normalized RMSE for (left) maximal (k ) and (right)
1
minimal(k )principalcurvatureestimationofourDeepFitmethodtotheclassic
2
Jet [6] with three scales, and PCPNet [9]
Fig.6: Curvature estimation error results for DeepFit compared PCPNet. The
numbers under each point cloud are its normalized RMSE errors in the format
(k , k ). The color corresponds to the L2 norm of the error vector mapped to a
1 2
heatmap ranging from 0-5.

--- Page 14 ---

14 Y. Ben-Shabat, S. Gould
(b)
(a)
Fig.7: DeepFit performance in two subsequent application pipelines: (a) Pois-
son surface reconstruction using estimated normal vectors from the classical Jet
fitting and the proposed DeepFit. (b) Noise removal results using DeepFit pre-
dicted weights.
aggregate the weights by summing all of its weight prediction from all of its
neighbors.Thenwecomputethemeanandstandarddeviationoftheaggregateed
(cid:80) (cid:80)
weightsandremovepointsunderathresholdofµ( w )−σ( w ).Theoutput
i i
point cloud contains less points than the original one and the removed points
are mostly attributed to outliers or noise. The results are depicted in Fig. 7b.
5 Summary
In this paper we presented a novel method for deep surface fitting for unstruc-
tured3Dpointclouds.Themethodconsistsofestimatingpoint-wiseweightsfor
solvingaweightedleastsquarefittingofann-jetsurface.Ourmodelisfullydif-
ferentiable and can be trained end-to-end. The estimated weights (at test time)
canbeinterpretedastheaconfidencemeasureforeverypointinthepointcloud
and used for noise removal. Moreover, the formulation enables the computation
ofnormalvectorsandhigherordergeometricquantitieslikeprincipalcurvatures.
The approach demonstrates high accuracy, robustness and efficiency compared
to state-of-the-art methods. This is attributed to its ability to adaptively select
the neighborhood of points through a learned model while leveraging classic ro-
bust surface fitting approaches, allowing the network to achieve high accuracy
with a low number of parameters and computation time.
References
1. Yizhak Ben-Shabat, Tamar Avraham, Michael Lindenbaum, and Anath Fischer.
Graph based over-segmentation methods for 3d point clouds. Computer Vision
and Image Understanding, 2018.

--- Page 15 ---

DeepFit 15
2. Yizhak Ben-Shabat, Michael Lindenbaum, and Anath Fischer. 3dmfv: Three-
dimensional point cloud classification in real-time using convolutional neural net-
works. IEEE Robotics and Automation Letters, 3(4):3145–3152, 2018.
3. Yizhak Ben-Shabat, Michael Lindenbaum, and Anath Fischer. Nesti-net: Normal
estimationforunstructured3dpointcloudsusingconvolutionalneuralnetworks.In
ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,
pages 10112–10120, 2019.
4. Alexandre Boulch and Renaud Marlet. Fast and robust normal estimation for
pointcloudswithsharpfeatures. InComputer Graphics Forum,volume31,pages
1765–1774. Wiley Online Library, 2012.
5. AlexandreBoulchandRenaudMarlet. Deeplearningforrobustnormalestimation
in unstructured point clouds. Computer Graphics Forum, 35(5):281–290, 2016.
6. Fr´ed´ericCazalsandMarcPouget. Estimatingdifferentialquantitiesusingpolyno-
mial fitting of osculating jets. Computer Aided Geometric Design, 22(2):121–146,
2005.
7. Zheng Dang, Kwang Moo Yi, Yinlin Hu, Fei Wang, Pascal Fua, and Mathieu
Salzmann.Eigendecomposition-freetrainingofdeepnetworkswithzeroeigenvalue-
based losses. In Proceedings of the European Conference on Computer Vision
(ECCV), pages 768–783, 2018.
8. Ga¨el Guennebaud and Markus Gross. Algebraic point set surfaces. ACM Trans-
actions on Graphics (TOG), 26(3):23, 2007.
9. PaulGuerrero,YanirKleiman,MaksOvsjanikov,andNiloyJMitra. Pcpnetlearn-
ing local shape properties from raw point clouds. Computer Graphics Forum,
37(2):75–85, 2018.
10. HuguesHoppe,TonyDeRose,TomDuchampt,JohnMcDonald,andWernerStuet-
zle. Surface reconstruction from unorganized points. Computer Graphics, 26:2,
1992.
11. Michael Kazhdan, Matthew Bolitho, and Hugues Hoppe. Poisson surface recon-
struction. InProceedings of the fourth Eurographics symposium on Geometry pro-
cessing, volume 7, 2006.
12. RomanKlokovandVictorLempitsky. Escapefromcells:Deepkd-networksforthe
recognition of 3d point cloud models. In The IEEE International Conference on
Computer Vision (ICCV), pages 863–872, Oct 2017.
13. Jan Eric Lenssen, Christian Osendorfer, and Jonathan Masci. Differentiable iter-
ative surface normal estimation. arXiv preprint arXiv:1904.07172, 2019.
14. Daniel Maturana and Sebastian Scherer. Voxnet: A 3d convolutional neural net-
work for real-time object recognition. In IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), pages 922–928. IEEE, 2015.
15. Niloy J Mitra and An Nguyen. Estimating surface normals in noisy point cloud
data. In Proceedings of the Nineteenth Annual Symposium on Computational ge-
ometry, pages 322–328. ACM, 2003.
16. Pushmeet Kohli Nathan Silberman, Derek Hoiem and Rob Fergus. Indoor seg-
mentationandsupportinferencefromRGBDimages. InEuropean Conference on
Computer Vision (ECCV), pages 746–760, 2012.
17. CharlesR.Qi,HaoSu,KaichunMo,andLeonidasJ.Guibas.Pointnet:Deeplearn-
ing on point sets for 3d classification and segmentation. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), July 2017.
18. CharlesRuizhongtaiQi,LiYi,HaoSu,andLeonidasJGuibas. Pointnet++:Deep
hierarchicalfeaturelearningonpointsetsinametricspace. InAdvancesinneural
information processing systems, pages 5099–5108, 2017.

--- Page 16 ---

16 Y. Ben-Shabat, S. Gould
19. MichaelDSpivak. A comprehensive introduction to differential geometry. Publish
or perish, 1970.

--- Page 17 ---

DeepFit 17
6 Supplementary Material
6.1 Normal and principal curvature estimation performance
Performance on real data. Wequalitativelyevaluatetheperformanceofour
method on the NYU Depth V2 dataset [16]. This dataset was captured using a
Kinect v1 RGBD camera and contains indoor scene environment and includes
missing data and a noise pattern thatis significantly different than the PCPNet
dataset. Specifically, the noise often has the same magnitude as some of the
features. Most importantly, this dataset, much like other real-world datasets,
does not have ground truth normals. Fig. 8 and Fig. 9 show the performance of
DeepFit’s normal and principal curvature estimation respectively compared to
Jet. DeepFit was trained with 256 points, however, since the network’s weights
are shared between the points it can be used with any neighborhood size. In
theseresultsweshowtheperformancefor128,256,512,1024neighboringpoints.
It shows that DeepFit is less sensitive to noise and is able to overcome the over-
smoothing affect commonly attributed to using a large neighborhood while also
preserving fine details.
Additional normal estimation results. We evaluate the normal estimation
performanceonthePCPNetdatastusingthepercentageofgoodpoints(PGPα)
metric.Fig10showstheresultsofdifferentlearningbasedmethodsforincreasing
α values . It shows that for low and medium noise levels, DeepFit is comparable
to Lenssen et.al. [13] while in all other categories their performance is better.
This is most likely attributed to the dataset bias towards flat and low curvature
surfaces, in which case, our method does not pose an advantage. DeepFit main
advantage is in curvy surfaces where an n-jet yields a better fit than a plane.
We evaluate DeepFit’s normal estimation performance using RMSE for dif-
ferent n-jet orders and number of points in the neighborhood. The results are
showninFig.11.Itshowsthattheincreaseinthenumberofneighboringpoints
slightly decreases the performance in the no noise augmentation however it sig-
nificantly improves the performance in high noise. This is mainly attributed to
theweightestimationnetworkthatsoftlyselectsthemostrelevantpointsforthe
fit.Italsoshowsthat1-jet(planes)performwell,howeverhigherorderjetshave
an advantage in the low and medium noise augmentation categories. In theory,
thehigherorderjetshavethecapacitytofitplanes,howeverinpracticeitisnot
always the case.
Fig. 12 depicts a visualization of DeepFit’s results on PCPNet point clouds.
Here the normal vectors are mapped to the RGB cube. Fig. 13 depicts a visu-
alization of the angular error in each point for the PCPNet dataset. Here, the
points’ color correspond to angular difference, mapped to a heatmap ranging
from 0-60 degrees. It shows that for complex shapes with high noise levels, the
generaldirectionofthenormalvectorispredictedcorrectly,but,thefinedetails
andexactnormalvectorarenotobtained.Forbasicshapestheaddednoisedoes
not affect the results substantially. Most notably, DeepFit shows robustness to
point density corruptions.

--- Page 18 ---

18 Y. Ben-Shabat, S. Gould
Fig.8:NormalestimationresultsforDeepFitandJetonNYUDepthV2dataset
for different neighborhoods sizes (128,256,512,1024). The colors of the points
are normal vectors mapped to RGB and projected to the image plane.
Fig.9:PrincipalcurvatureestimationresultsforDeepFitandJetonNYUDepth
V2 dataset for different neighborhoods sizes (128,256,512,1024). The colors of
the points correspond to their principal curvature values using the colormap in
the bottom-left corner and projected to the image plane.

--- Page 19 ---

DeepFit 19
1.0
0.8
0.6
0.4
0.2
0.0
0 5 10 15 20 25 30
PGP
No Noise
1.0
0.8
0.6
0.4
DeepFit
Lenssen et. al.
Nesti-Net 0.2
PCPNet
0.0
0 5 10 15 20 25 30
PGP
Low Noise
1.0
0.8
0.6
0.4
DeepFit
Lenssen et. al.
Nesti-Net 0.2
PCPNet
0.0
0 5 10 15 20 25 30
PGP
Medium Noise
DeepFit
Lenssen et. al.
Nesti-Net
PCPNet
1.0
0.8
0.6
0.4
0.2
0.0
0 5 10 15 20 25 30
PGP
High Noise
1.0
0.8
0.6
0.4
DeepFit
Lenssen et. al.
Nesti-Net 0.2
PCPNet
0.0
0 5 10 15 20 25 30
PGP
Variable Density: Gradient
1.0
0.8
0.6
0.4
DeepFit
Lenssen et. al.
Nesti-Net 0.2
PCPNet
0.0
0 5 10 15 20 25 30
PGP
Variable Density: Striped
DeepFit
Lenssen et. al.
Nesti-Net
PCPNet
Fig.10: Comparison of the percentage of good points (PGP) metric for unori-
entednormalestimationoftheproposedDeepFittootherdeeplearningmethods
(PCPNet[9],Nesti-Net[3],Lenssenet.al.[13]).Here,αisthethresholdformea-
suring the percentage of good points.
.
n=1 n=2 n=3 n=4
8.0
7.5
7.0
6.5
6.0
64 128 256
Number of points
ESMR
elgna
No Noise
10.0
9.8
9.6
9.4
9.2
64 128 256
Number of points
ESMR
elgna
Low Noise
21
20
19
18
17
64 128 256
Number of points
ESMR
elgna
Medium Noise
32
30
28
26
24
64 128 256
Number of points
ESMR
elgna
High Noise
9.0
8.5
8.0
7.5
7.0
64 128 256
Number of points
ESMR
elgna
Variable Density: Gradient
9.5
9.0
8.5
8.0
7.5
64 128 256
Number of points
ESMR
elgna
Variable Density: Striped
Fig.11: Comparison of the angle RMSE metric for different DeepFit variants.
Ablations include different n-jet order (1,2,3,4) and number of neighboring
points (64,128,256).
.

--- Page 20 ---

20 Y. Ben-Shabat, S. Gould
Additional principal curvature estimation results. Fig. 14 qualitatively
depictsDeepFit’sresultsonthePCPNetdataset.Forvisualization,theprincipal
curvaturesaremappedtoRGBvaluesaccordingtothecommonlyusedmapping
given in Fig. 5 i.e. both positive (dome) are red, both negative (bowl) are blue,
onepositiveandonenegative(saddle)aregreen,bothzero(plane)arewhite,and
one zero and one positive/negative (cylinder) are yellow/cyan. For consistency
in color saturation we map each model differently according to the mean and
standard deviation of the principal curvatures. Note that the curvature sign is
determinedbythegroundtruthnormalorientation.DeepFit’snormalizedRMSE
metric is visualized in Fig. 15 as the magnitude of the error vector mapped to
a heatmap. It can be seen that more errors occur near edges, corners and small
regions with a lot of detail and high curvature. Moreover, these visualizations
show that for low noise levels, the principal curvature estimation is reliable, as
expected, the reliability declines with the insertion of high magnitude noise.
6.2 Efficiency
Table 3 shows a comparison between the number of parameters and run time
between different deep learning based normal estimation methods. It can be
seen that DeepFit has a significantly lower number of parameters compared to
Nesti-Net and PCPNet and more parameters than Lenssen et. al.. This gap in
thenumberofparameterscanbeexplainedbythelackofpointstructureinour
method while Lessen et. al. construct a graph. Constructing a graph introduces
a limitation with respects to the number of neighboring points, i.e. training and
testing has to be done on the same neighborhood size, using a PointNet archi-
tecture allows to train and test on different sizes of neighborhoods. DeepFit’s ,
number of parameters is mainly attributed to the PointNet transformation sub-
networks. The reported run time is the average run time for a batch of size 64
(i.e. computing normals for 64 points simultaneously). We chose a batch of 64
in order to fairly compare to the more resource intensive methods (Nesti-Net).
Most methods, including ours, can compute in larger batches for faster perfor-
mance, particularly Lenssen et. al. that are able to fit a full size point cloud
(100k points) in a single batch on the GPU.
Lenssen et.
Method Our DeepFit Nesti-Net [3] PCPNet [9]
al. [13]
Parameters 3.5M 179M 22M 7981
Exec time (per
0.35ms 266ms 0.61ms 0.13ms
point)
Table3:Numberofparametersandexecutiontimeperformancefordeeplearning
normals estimation methods. Run time is averaged for batches of size 64.

--- Page 21 ---

DeepFit 21
Fig.12: DeepFit’s normal estimation results for different noise levels (columns
1-4), and density distortions (columns 5-6). The colors of the points are normal
vectors mapped to RGB.

--- Page 22 ---

22 Y. Ben-Shabat, S. Gould
Fig.13: Normal estimation error visualization for different noise levels (columns
1-4), and density distortions (columns 5-6). The colors of the points correspond
to angular difference, mapped to a heatmap ranging from 0-60 degrees. The
number above each point cloud is the RMSE.

--- Page 23 ---

DeepFit 23
Fig.14: Curvature estimation results visualization. The colors of the points cor-
responds to the mapping of k ,k to the color map given in Fig 5. Values in the
1 2
range [−(µ(|k |)+σ(|k |)),µ(|k |)+σ(|k |)]| .
i i i i i=1,2

--- Page 24 ---

24 Y. Ben-Shabat, S. Gould
Fig.15:Curvatureestimationerrorresults.Thenumbersundereachpointcloud
are its RMSE and normalized RMSE. The color corresponds to the L2 norm of
the error vector mapped to a heatmap ranging from 0-5.```

---

## Section 1.4: Reconstruction filters in computer-graphics

Source File: Reconstruction filters in computer-graphics.txt

### Paper Content:

```
# Reconstruction filters in computer-graphics.pdf
# Converted: 2025-07-18 12:58:59
# Method: pdfplumber
# Domain: pixel2physics
# Source: /home/user/vekt/papers/pixel2physics/pdfs/layer1/Reconstruction filters in computer-graphics.pdf
# Output: /home/user/vekt/papers/pixel2physics/dot_txt/layer1/Reconstruction filters in computer-graphics.txt


--- Page 1 ---

~
Computer Graphics, Volume 22, Number 4, August 1988
Reconstruction Filters in Computer Graphics
Don P. Mitchell
Arun N. Netravali
AT&T Bell Laboratories
Murray Hill, New Jersey 07974
ABSTRACT Many conversions between continuous and discrete representations may
occur in the course of generating an image. For example when ray trac-
ing a texture-mapped surface, a photograph may be sampled by a digi-
Problems of signal processing arise in image tizer to define the texture, then the texture samples are inteqxilated and
synthesis because of tlansformations between resampled when a ray strikes the textured surface, the ray samples are
continuous and discrete representations of 2D interpolated and resampled to generate pixel values, and the pixels are
images. Aliasing introduced by sampling has interpolated by a display and finally resampled by retinal cells when the
received much attention in graphics, but recon- image is viewed. Resampling may be more explicit, as in enlarging or
struction of samples into a continuous reducing a digital image or warping an image (e.g., with Catmull and
representation can also cause aliasing as well Smith's algorithm CAT80). Each of these conversions can introduce
as other defects in image quality. The prob- conspicuous errors into an image.
lem of designing a filter for use on images is
discussed, and a new family of piecewise Errors introduced by sampling (e.g., aliasing) have received considerable
cubic filters are investigated as a practical attention in the graphics community since Crow identified this as the
demonstration. Two interesting cubic filters cause of certain unwanted artifacts in synthetic images CRO77. Alias-
are found, one having good antialiasing pro- ing in images was discussed in the classic 1934 paper by Mertz and Gray
perties and the other having good image- MER34. Their discussion contains a description of artifacts well-
quality properties. It is also shown that recon- known to graphics researchers today and shows that the condition for
struction using derivative as well as amplitude preventing aliasing was known, as a rule of thumb, long before
values can greatly reduce aliasing. Shannon's proof of the sampling theorem:
CR Categories and Subject Descriptions: 1.3.3 Computer Graphics :
PictureImage Generation; 1.4.1 Image Processing : Digitization The interference usually manifests itself in the form of serra-
tions on diagonal lines and occasional moir6 effects in the
General Terms: Algorithms received picture. Confusion in the signal may be practically
eliminated by using an aperture of such a nature that it cuts
Additional Keywords and Phrases: Antialiasing, Cubic Filters, Filters, off all Fourier components with n numbers greater than
Derivative Reconstruction, Reconstruction, Sampling N/2 half the scanning rate ....
1. Introduction By comparison, the problems introduced by reconstruction have been
The issues of signal processing arise in image synthesis because of somewhat neglected in the graphics literature. Reconstruction can be
transformation between continuous and discrete representations of responsible for aliasing and other types of distortion that mar the subjec-
images. A continuous signal is converted to a discrete one by sampling, tive quality of an image. This paper will focus on the effects of recon-
and according to the sampling theorem SHA49, all the information in struction and how to design filters for graphics applications.
the continuous signal is preserved in the samples if they are evenly
spaced and the frequency of sampling is twice that of the highest fre- 2. Aliasing Caused by Reconstruction
quency contained in the signal. A discrete signal can be converted to a Aliasing in synthetic images is a serious problem and still not completely
continuous one by interpolating between samples, a process referred to in solved. In other digital-signal-processing applications, aliasing is elim-
the signal-processing literature as reconstruction. inated by prefiltering signals before sampling, as illustrated in Figure l.
Note that it is the prefiltered signal that is reconstructed in this ease.
,screte
reconstructed
sig° s,gnal- I filter I signal
Permission to copy without fee all or part of this material is granted
provided that the copies are not made or distributed for direct
commercial advantage, the ACM copyright notice and the title of the sampling
publication and its date appear, and notice is given that copying is by pulses
permission of the Association for Computing Machinery. To copy
otherwise, or to republish, requires a fee and/or specific permission.
Figure I. Sampling and Reconstruction
While prefi/lering is the classic solution to a/iasing problems, there is a
special problem encountered in computer graphics. Many synthetic
©1988 ACM-O-89791-275-6/88/O08/0221 $00.75 images originate from what we will call procedural signals, in which the
221

--- Page 2 ---

¢
SIGGRAPH '88, Atlanta, August 1-5, 1988
signal is only implicitly defined by an algorithm for computing point centered at the location of an impulse in the comb. Equation (,4) states
samples. Operations that require an explicit representation of the signal that, in the frequency domain, reconstruction can be interpreted as the
cannot be performed, and in particular, prefiltering is impractical. This multiplication by K (v) which is intended to eliminate all the extraneous
difficulty is unique to computer graphics, and ray tracing is the clearest replicas of the signal's spectrum and keep the original base-band cen-
example of it wHIgo}. tered at the origin. K(v) is indicated by the dashed curve in Figure 2.
To explain the role that reconstruction plays in aliasing, it will be helpful However, Figure 2 also demonstrates a problem. The replicas of the sig-
to review briefly the theory of sampling and define the operations of nal spectrum overlap, aad the reconstruction filter can not isolate a pure
sampling and reconstruction more precisely, tn one dimension, a signal version of the base-band signal. When part of the energy in a replica of
can be represented by a continuous function f(x). Producing a discrete the spectrum leaks into the reconstructed signal, aliasing results. If the
signal by sampling is equivalent to multiplying by an infinite train of bandwidth of the signal were narrower or the sampling rate higher, the
impulses known as a comb function: copies would not overlap, and exact reconstruction would be possible.
Even if the replicated spectra do not overlap, alining can result from
£(x) = f (x)" comb(x) (1)
poor reconstruction, as illustrated in Figure 3. When aliasing is a conse-
where quence of undersampling (or lack of prefiltering), it is referred to as
prealiasing, and when it results from poor reconstruction, it is called
comb(x) = ~ ~(x-n) (lb) postaliasing.
Unit spacing between samples is assumed in equation (lb), and ~x) is
the Dirac delta function. In this case, the sampling theorem states that K(v)
f(x) can be reconstructed exacdy from its samples if it contains no fre- r- - ........... -~ F~(V)
quencies greater than 0.5 cycles per sample. This critical frequency is
called the Nyquist frequency.
Reconstruction is accomplished by convolving (indicated by *) the
V
discrete signal with a reconstruction filter kernel, k(x): VN
f,(x) = ./~(x)* k(x) (2)
Figure 3. Postaliasing Resulting from Poor Reconstruction Filter
= ~ f,(u )" k (x - u)du (2b)
Figure 4 shows an extreme example of aliasing in an image. In this fig-
ure, the two-dimensional signal, f(x,y) = sin(x 2 +y2), was sampled on a
= ~ f(n)'k(x-n) (2c) 128 x 128 pixel grid. Then, these samples were reconstructed with a
cubic filter (to be described later in the paper) and resampled to 512 x
512 pixels.
Except in the mathematically ideal case, some error is introduced in the
process of sampling and reconstruction, and f(x) will be somewhat dif- The rings on the left side of the image are part of the actual signal, but
ferent from fr(X). To analyze this error, it is useful to view the problem the rings on the right side are Moit~ patterns due to prealiasing. In the
in the frequency domain. The Fourier transform of the signal is its spec- center of the image is a fainter set of concentric rings resulting from pos-
trum F(v), and the Fourier transform of the filter is its frequency taliasing. Postaliasing occurred when the discrete image of 128 x 128
response K(v). Since multiplication in the spatial domain is equivalent pixels was enlarged to 512 x 5t2 pixels by resampling. Note that this
to convolution in the ffrequency domain (and vice versa), sampling can conspicuous postaliasing pattern results from "treating" between the sig-
be described by: nal and its alias. This can also be understood from Figure 3, where it
can be seen that at the Nyquist frequency (indicated by VN) the signal's
spectrum and its nearest replica come close together. Power in the spec-
F~(v) = F(v)* Comb(v) (3) trum very near the Nyquist frequency is thus the cause of the most diffi-
and reconstruction by: cdt type of aliasing to remove from an image. This problem has been
noted by other graphics researchers COO87 and by Mertz et al.
F,(v) = F,(V) .K(v) (4) MER34.
The Fourier transform of a comb function is also a comb function (with Using the same set of samples as in Figure 4, a much better reconstruc-
reciprocal spacing between impulses). tion filter can be applied (a 30-unit-wide windowed sine filter). Figure 5
demonstrates a dramatic reduction of the postaliasing pattern, but the
prealiasing is unaffected. The spectrum of this reconstruction filter is
very close to the ideal step shape shown in Figures 2 and 3.
K(v)
3. Other Image Defects Caused by Reconstruction
Notice in Figure 2, that a reconstruction filter K(v) has two tasks. First
it must remove the extraneous replicas of the signal spectrum (to prevent
aliasing). Second, it should pass the original signal base band, but the
signal can be distorted if this is not done perfectly. This second type of
reconstruction error will be referred to as base-band attenuation.
From the previous section, one might assume that the literature of signal
Figure 2. Sampling and Reconstruction in Frequency Domain processing provides a complete solution to the reconstruction problem in
graphics; however, there is a serious difficulty with the ideal sine filter
that is not obvious from studying its frequency response. Figure 6
Figure 2 illustrates the consequences of the convolution in equation (3).
shows a simple figure reconstructed with the same filter used in Figure
The spectrum of a sampled signal F,(V) is the sum of an infinite
5. The rippling pattern radiating from the edges is called ringing. Ring-
sequence of shifted replicas of the original signal's spectrum, each
ing is strongly suggested by the form of the impulse response of the sinc
222

--- Page 3 ---

@ *
Computer Graphics, Volume 22, Number 4, August 1988
fiher, as shown in Figure 7: number of free parameters. First, the filter should be smooth in the
sense that its value and first derivative are continuous everywhere.
Discontinuities in k(x) will lead to high-frequency leakage in the fre-
quency response of the filter which can allow aliasing. In addition, the
1 - problem of sample-frequency ripple can be designed out of the filter by
requiring (for all x):
0.5-
k(x-n) = 1 (7)
0-
This means that if all the samples are a constant value, the reconstruction
will be a fiat constant signal. Figure 8 demonstrates this defect by using
I I I
an unnormalized Gaussian filter to reconstruct a 512 x 512 image from
-5 0 5
64 x 64 samples. In the frequency domain, sample ripple can be viewed
as an alias of the image's DC component. It can be shown that the con-
dition given by equation (7) means that the frequency response of these
Figure 7. mpulse Response of Ideal Sinc Filter
cubic filters will be zero at all integer multiples of the sampling fre-
quency except zero, eliminating all extraneous replicas of the DC com-
Classical digital filter design places a heavy emphasis on the frequency ponent.
response of a filter. That works well in the audio domain, but when con-
sidering the appearance of images, it is important to also pay attention to With these constraints, the number of free parameters are reduced from
the shape of the impulse response. eight to two, resulting in the following family of cubic filters;
The response of human viewers to various spatial effects of filters is not (12-9B - 6C) Ixl 3 + if Ixl<l
yet a well-understoed science and is largely subjective in nature. Filters I (_18+i2B+6C)Ix12+(6_2B)
that have some aliasing problems or certain types of base-band attenua-
1 J(-B-6C)Ixl 3 +(6B +30C)IxI 2 + if 1<_ Ixl <2 (8)
tion may turn out to give visually-pleasing results. Schreiber and Troxel
have discussed the spatial effects of reconstruction filters SCH85, and k(x) = 6 /0(-12B-48C)1xl +(8B+24C)
they mention some of the important defects that can occur when judging otherwise
the quality of an image subjectively: sample-frequency ripple, anisotro-
pic effects, ringing, blurring, and aliasing. Each of these effects will be
Some values of (B, C) correspond to well-known cubic splines. (1,0) is
considered in detail in the following section.
the cubic B-spliue, (0, C) is the one-parameter family of cardinal cubits
with (0, 0.5) being the Catmull-Rom spline, and (B, 0) are Duff's ten-
Unfortunately, it is often necessary to trade off one type of distortion for
sinned B-splines DLrF86.
another, and the design of a single filter perfect for all applications is
almost certainly impossible. As Figure 6 illustrated, perfect antialiasing
In two or more dimensions, visible artifacts can be caused by angle-
resulted in the serious defect of ringing. However, Brown realized that a
dependent behavior or anisotropic effects. Figure 9 illustrates this prob-
moderate amount of ringing can improve the subjective quality of an
lem by reconstructing with the separable filter k(x)k(y) using parameter
image by enhancing the appearance of shaqmess BRO69. He found
values of (0,0). Even though sample-frequency ripple has been designed
that a single transient lobe of ringing was effective at sharpening, but
out of k(x), in two dimensions the pixel structure is highly conspicuous
multiple transients (as in Figure 6) always degrade image quality.
because the impulse response and the sampling lattice are not radially
symmetric,
Many of the concepts presented so far have been illustrated in one
dimension for simplicity. However, image reconstruction takes place in
The phenomenon of ringing has already been seen in Figure 6. Filters
two dimensions and involves the convolution of a 2D lattice of samples
with a filter k(x,y). In this paper, we will consider only separable in the cubic filter family can also exhibit this problem as seen in Figure
filters, where the samples are convolved with the product k(x)kty). 10, where parameter values of (0,1) were used. Ringing results when
k(x) has negative side lobes, and although some ringing can enhance
Separable filters are compurationally more efficient than nonseparable
shaqaness, a filter that becomes negative is problematic. In Figure 10, a
because the filtering operation can be performed in separate passes verti-
typical problem is seen where portions of the image near an edge have
cally and horizontally. If the filter kernel is N samples wide, the recon-
struction can be performed with O(N 2) multiplications for the general become negative and have been damped to zero. This results in pro-
filter k(x,y) but with O(N) if the filter is separable. nounced black spots (e.g., at the top of the statue's head). Similar
clamping occurs to white, but is less noticeable because of the eye's non-
linear response to contrast. Schreiber and Troxel have suggested that
4. Piecewise Cubic Reconstruction Filters
subjectively even sharpening can only be produced by introducing ting-
Rather than discuss the issues of filter design abstractly, this paper will ing transients in a suitably nonlinear fashion SCH85. These conspicu-
apply them to the study of a family of filters defined by piecewise cubic ous clamping effects could also be eliminated by reducing the dynamic
polynomials. Cubic filters ate sufficiently complex to have a broad range of the image or raising the DC level of the image.
range of behaviors, but they are simple enough to be compntationally
attractive. Hou and Andrews have studied the fikering properties of the Parameter values of (3/2, -1/4) result in an image that is unnecessarily
cubic B-spline HOU78, and two studies have been made of the one- blurry, as seen in Figure 11. The cubic B-spline also suffers from this
parameter family of cardinal cubic splines KEYSI,PAR83. problem. In viewing many reconstructions with filters in this family,
ringing, anisotropy, and blurring are the dominant behaviors, and in a
The general form for a symmetric cubic filter is: small region of the parameter space, a satisfactory compromise seems to
exist which is seen in Figure 12, using parameter values of (1/3, 1/3).
Plxl3+Qlxl2+RIxI+S if Ixl<l This is quite good, considering that the image is being magnified from
x 64 pixels. There is some degree 0f sharpening, and almost no visi-
k(x)= ~Tlxl3+UIxIZ+VIxI+W ifl_<lxl<2 (6)
ble evidence of the sampling lattice.
to otherwise
To get a better idea of which regions of the parameter space yield which
type of behavior, a simple subjective test was designed. On a neutral
Several obvious constraints can be placed on this function to reduce the background, four images were displayed typifying the effects of ringing,
223

--- Page 4 ---

SIGGRAPH '88, Atlanta, August 1-5, 1988
blurring, anisotropy, and an example of die most satisfactory behavior. in Figure 13), quadratic convergence of fit is achieved. This line con-
In the center of the display, images reconsuucted fxom filters with ran- tains the cubic B-spline and the Catmull-Rom spline (which actually has
dom values of (B, C) were displayed, and the test subject was asked to cubic convergence). Within the interval of B = 5,33 to B = 0, good sub-
choose which of the four behaviors it exemplified. Nine expert jective behavior is found with a simple trade-off between blurring and
observers (researchers working in graphics or image processing) took tinging. Outside this interval, k(x) becomes bimodal or exhibits extreme
part and over 500 samples were taken. It would not be credible to sug- ringing. The filter (1/3, 1/3) used to generate Figure 12 is recommended
gest that a single ideal parameter pair can be deduced from subjective by the authors, but other observers may prefer more or less ringing.
testing. The motivation for this experiment was simply to draw approxi-
mate boundaries between regions of differing behavior as shown in Fig- 5. Postaliasing Revisited
ure 13. The test subjects were quite consistent with one another in their A systematic consideration of subjective appearance along with quantita-
judgements. tive analysis has yielded an excellent piecewise cubic filter. However,
the issue of postaliasing, defined in section 2, has been ignored. In fact
the (1/3, 1/3) filter has only fair antialiasing properties and was used to
generate Figure 4. Postaliasing is usually not strong enough to cause
'""'........ visible "jaggies" on edges unless a very poor filter is used (e.g., a box
filter); however, an image with periodic patterns can have conspicuous
postalias Moire effects unless careful precautions are taken. Synthetic
0.8-
images that contain brick walls, ocean waves, or the ubiquitous checker-
board pattern are examples of images that might have this difficulty.
There are several approaches to fixing this problem.
0.6-
B If the signal is bandlimited and samples carry information about the
parameter derivative as well as about signal amplitude, a better job of reconstruc-
tion can be done PET64. Given samples (at unit spacing) of a signal
0.4-
and of its derivative, a reconstruction can be done in the following form:
0.2- f(x)= n~= ~ If~g(x-n)+f,h(x-n) (1o)
x \ \ In an extension of the sampling theorem, if the signal contains no energy
0
I I I above the sampling frequency (twice the allowed bandwidth of sampling
0 0.2 0.4 0.6 0.8 without derivatives), then it can be perfectly reconstructed by the filter
C parameter kernels:
Figure 13. Regions of Dominant Subjective Behavior sinZ~
g(x)= n2x2 (ll)
sin2
To help choose a good filter rom the two-parameter space, some quanti- h(x) = (llb)
tative analysis can be done to remove one more degree of freedom. ~x
Keys and Park et al. studied the cardinal cubic splines because these
cubics exactly interpolate at the sample positions KEYSI,PAR83.
Using standard numerical analysis, Keys concluded that the Catmull- This is analogous to the ideal sine reconstruction formula in the standard
Rom spline was best. Park et al. reached the same conclusion using an case where no derivative information is present. A common approxima-
equivalent analysis in the frequency domain. Figure 14 illustrates this tion to these ideal reconstruction formulae is Hermite cubic interpolation:
technique;
/ (cid:127)
lxl3-31xl2+l if Ixl_<l
g (x) = otherwise (12)
{ (cid:127)
3-2x Ixl +x if Ixl~l
h (x) = otherwise (12b)
f (x)
Figure 15 shows the aliasing test pattern (stir starting with 128 x 128
samples) reconstructed with the Hermite cubic postfilter. The effect is
2J" X
~--- h --.-~. dramatic when compared to Figure 4, The postaliasing artifact in the
middle of the image is nearly gone, and the prealiasing paltern on the
right is less intense.
Figure 14. f(x) andf~(x)
The theory of derivative reconstruction may have some practical value in
computer graphics. For example, it may be possible to extend Whitted's
As the sample spacing h diminishes, the function and its reconstruction
ray-tracing shading model WHI80 to generate derivatives with respect
become closer. The difference f (x) -f,(x) can be expanded into a power
to the screen coordinates. This is not an easy problem, but we have
series in h to study how parameters affect various orders of behavior.
demonstrated the feasibility of this extension by deriving the formulae
Details of this type of analysis can be found in Keys' paper, and when
for Lambert and Phong shading on quadric surfaces. It is possible that
applied to the two-parameter family, the following is obtained:
the density of rays used to reconstruct an image could be reduced in this
manner by gathering more useful information from each visible surface
f (x)-f,(x) = (2C+B-1)hfr(x) + O(h 2) (9) calculation.
A second approach to improving postaliasing properties is suggested by
r(x) is a polynomial factor. When 2C +B = I (indicated by dotted line
the success of stochastic sampling on the prealiasing problem
224

--- Page 5 ---

'~' Computer Graphics, Volume 22, Number 4, August 1988
COO86,DIPg5,MIT87. However, preliminary experiments conducted A new family of cubic filters has been analyzed, and two interesting
by the authors with stochastic-phase reconstructfon have yielded very filters have been found. The (113, 1/3) filter yields excellent image qual-
poor results. The amount of noise needed to obscure postaliasing seri- ity, and the notch filter (3/2, -1/4) strongly suppresses postaliasing pat-
ously degraded image q?ality. terns.
Finally, it was observed in section 2 that signal energy very near the If derivative values can be generated by a procedural signal, an image
Nyquist frequency is most responsible for conspicuous Moire patterns. It with less aliasing is possible by reconstruction with Hermite intelpolation
is possible to cut out this component by notch-filter reconstruction. The or some other suitable filter.
frequency response of the two-parameter cubic filter in equation (8) is:
More work remains to be done. While the authors do not believe simple
filters will be found that improve much on the cubic filters derived here,
x(v) = -3~-3B- Isinc2(v)_sinc(2v) (13) there aae other avenues for progress. Adaptive filters might allow good
image quality with strong antialiasing only where it is needed in problem
areas. The effects of the reconstruction in the display and eye might be
2C _3sinc2(2v)+ 2sinc(2v)+sinc(4v)
allowed for given models of the visual system NET88.
+ B sinca(v) Finally, the problem of reconstruction from nonuniform sampling is not
entirely solved. Reasonable filters have been proposed MIT87, but
more analysis could be done: "Ideal" nonuniform reconstruction filters
am known which are analogous to the sinc filter used witli uniform sam-
This function goes to zero at v = 1/22 when B = 3/2. In fact, the fre-
pies. A greater challenge will be to understand the subjective issues
quency response is zero at all integer and half-integer multiples of the
involved in designing filters that are well suited to computer graphics.
sampling rate except zero. The filter (3/2, -1/4) is quadratically conver-
gent, and the result of reconstruction with it can be seen in Figure 16, in
7. Acknowledgements
which the postaliasing artifact is almost completely eliminated. Unfor-
tunately, this filter is quite blurry as was seen in Figure 11. The We would like to thank our colleagues who volunteered to help with
behavior of this notch filter can be seen in its frequency response in Fig- subjective testing. We would also like to thank Jim Bergen from the
ure 17 compared with the cubic B-spline filter (1, 0) in Figure 18. The David Sarnoff Laboratory, Jim Johnston from Bell Labs Signal Process-
log magnitudes of the frequency responses are plotted below: ing Research Department., and William Schreiber from MIT's Advanced
Television Research Program for their views on filter design. We would
also like to thank Larry O'Gorman, Brace Naylor, Rob Pike, David Tho-
mas and Pamela Zave and the SIGGRAPH reviewers for their helpful
comments.
0.1
8. References
0.01
BRO69 Brown, Earl F., "Television: The Subjective Effects of
Filter Ringing Transients", Journal of the SMPTE, Vol.
0.001
78, No. 4, April 1969, pp. 249-255.
0,0001
I i CAT80 Catmnll, Edwin, Alvy Ray Smith, "3-D Transformations
0 1 2 of Images in Scardine Order", Computer Graphics, Vol.
14, No. 3, pp. 279-285.
COO86 Cook, Robert L., "Stochastic Sampling in Computer
Figure 17. Frequency Response of Cubic Notch Filter
Graphics", ACM Trans. Graphics, VoL 5, No. t, January
1986.
COO87 Cook, Robert L., personal communication, August, 1987.
OH m CRO77 Crow, Franklin C., "The Aliasing Problem in Computer-
Generated Shaded Images", Comm. ACM, Vol. 20, No. 1 l,
0.01 - November 1977, pp. 799-805.
0.~1 - DIP85 Dippe, Mark A. Z. and Erling Henry Wold, "Antialiasing
Through Stochastic Sampling", Computer Graphics, Vol.
0.0~1 19, No. 3, July 1985, pp. 69-78.
I I
1 2
DIJF861 Duff, Tom, "Splines in Animation and Modeling", State of
the Art in Image Synthesis, SIGGRAPH g6 Course Notes.
Figure 18. Frequency Response of Cubic B-Spline Filter HOU78 Hou, Hsieh S., HaJ'ry C. Andrews, "Cubic Splines for
Image Interpolation and Digital Filtering", IEEE Trans.
Acoustics, Speech, and Signal Processing, Vol. ASSP-26,
No. 6, December 1978, pp. 508-517.
6. Conclusions
Designing reconstruction filters for computer graphics applications
KEY81 Keys, Robert, G, "Cubic Convolution Interpolation for
requires a balanced analysis of formal quantitative properties and subjec-
Digital Image Processing", 1EEE Trans. Acoustics, Speech,
tive image quality. There are many trade-offs, arid it may be impossible
and Signal Processing, Vol. ASSP-29, No. 6, December
to find a filter that yields good image quality and has good antialiasing
1981, pp. 1153-1160.
properties.
225

--- Page 6 ---

SIGGRAPH '88, Atlanta, August 1-5, 1988
[MER84] Mettz, Pierre, and Frank Grey, "A Theory of Scanning and
its Relation to the Characteristics of the Transmitted Sig-
nal in Telephotography and Television," Bell System Tech.
J., Vol. 13, pp. 464--515, July 193,4.
[MIT87] Mitchell, Don P., "Generating Antialiased Images at Low
Sampling Densities", Computer Graphics, Vol. 21, No. 4,
July 1987, pp. 65-72.
[NETg8] Nelravali, Arun N., Barry G. Haskell, Digital Pictures:
Representation and Compression, New York, Plenum,
1988.
[PAR83] Park, Stephen K., Robert A. Schowengerdt, "Image
Reconstruction by Parametric Cubic Convolution", Com-
puter Vision, Graphics, and Image Processing, Vol. 23,
No. 3, September 1983, pp. 258-272.
[PET64] Petersen, Daniel P., David Middleton, "Reconsa'aetion of
Multidimensional Stochastic Fields from Discrete Meas-
urements of Amplitude and Gradient", Information and
Control, Vol. 7, pp. 445-476.
[SCH85] Schreiber, William F., Donald E. Troxel, "Transformation
Between Continuous and Discrete Representations of
Images: A Perceptual Approach", IEEE Trans. Pattern Figure 4. Prealiasing and Postaliasing Example
Analysis and Machine Intelligence, Vol. PAMI-7, No. 2,
March 1985, pp. 178-186.
[SHA49] Shannon, Claude E., "Communication in the Presence of
Noise.", Proc. IRE Vol. 37, 19,49, pp. 10-21.
[wrn80] Whitted, Turner, "An Improved Illumination Model for
Shaded Display", Comm. ACM, Vol. 23, No. 6, June 1980,
pp. 343-349.
Figure 5. Nearly Ideal Postfiltering
226

--- Page 7 ---

~ ComputerG raphics, Volume 22, Number 4, August 1988
Figure 6. Ringing Caused By Sinc Postfilter Figure 9. Anisotropic Artifacts
Figure 8. Sample-Frequency Ripple Figure 10. Excessive Ringing and Clamping Artifacts
227

--- Page 8 ---

¢
SIGGRAPH '88, Atlanta, August 1-5, 1988
Figure 11. Excessive Blumng Figure 15. Using Derivative Reconstruction
Figure 12. Best-Looking Cubic Reconstruction Figure 16, Using Notch-Filter Reconstruction
228```

---

## Section 1.5: layer1_compendium

Source File: layer1_compendium.txt

### Paper Content:

```
```

---

# COMPENDIUM STATISTICS

Target Directory: ./layer1/
Compendium Name: layer1_compendium.txt
Total Chapters: 0
Total Papers: 5
Total Size: 140K
Generated: Sat 19 Jul 17:55:27 NZST 2025

Ready for layer1 research analysis!
